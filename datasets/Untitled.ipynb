{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on 3/11/2021 11:56 AM\n",
    "\n",
    "@author: Tingfeng Li, <tl601@cs.rutgers.edu>, Rutgers University.\n",
    "\"\"\"\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "class MNIST_CoLoc(datasets.MNIST):\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None,\n",
    "                 download=False, digit=4, clutter=0, datapath=None):\n",
    "        super(MNIST_CoLoc, self).__init__(root, train=train, download=download,\n",
    "                                          transform=transform, target_transform=target_transform)\n",
    "        # make sure calling of transform, after which target [x,y,w,h]->[x1,y1,x2,y2]\n",
    "        assert (self.transform is not None)\n",
    "\n",
    "        self.digit = digit\n",
    "        self.datapath = datapath\n",
    "        self.totensor = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "        self.crop = transforms.RandomResizedCrop((84, 84), scale=(0.1, 1.0))\n",
    "        if self.datapath is None:\n",
    "            self.digit_data = [idx for idx, digit in enumerate(self.targets)\n",
    "                               if digit == self.digit]\n",
    "            print('total number of digit-{} image\\t{}'.format(self.digit, len(self.digit_data)))\n",
    "\n",
    "            # generate Translated images, put each 28*28 digit at random location in a 84*84\n",
    "            # black canvas\n",
    "            self.new_digit_data = np.zeros((len(self.digit_data), 84, 84), dtype=float)\n",
    "            # note! target style should be [x,y,w, h]\n",
    "            self.new_targets = torch.zeros((len(self.digit_data), 4), dtype=float)\n",
    "            for i, idx in enumerate(self.digit_data):\n",
    "                # sample a location\n",
    "                # x_d = random.randint(0, 84 - 28)\n",
    "                # y_d = random.randint(0, 84 - 28)\n",
    "                x_d = random.randint(14, 42) # at least 1/4 digit in in the center box\n",
    "                y_d = random.randint(14, 42)\n",
    "                data = self.data[idx]\n",
    "                self.new_digit_data[i, y_d:y_d + 28, x_d:x_d + 28] = data\n",
    "                self.new_targets[i] = torch.tensor([x_d, y_d, 28, 28])\n",
    "                # add clutter if possible\n",
    "                if clutter == 1:\n",
    "                    for _ in range(32): # 16\n",
    "                        # crop from noise data\n",
    "                        noise_data = self.data[random.randint(0,len(self.data)-1)]\n",
    "                        x0 = random.randint(0, 28 - 6)\n",
    "                        y0 = random.randint(0, 28 - 6)\n",
    "                        cropped = noise_data[y0:y0+6, x0:x0+6]\n",
    "                        # sample a location to put cropped noise data\n",
    "                        x = random.randint(0, 84 - 6)\n",
    "                        y = random.randint(0, 84 - 6)\n",
    "                        while np.sum(self.new_digit_data[i, y:y + 6, x:x + 6]) != 0:\n",
    "                            x = random.randint(0, 84 - 6)\n",
    "                            y = random.randint(0, 84 - 6)\n",
    "                        # Insert digit fragment, but not on top of digits\n",
    "                        if np.sum(self.new_digit_data[i, y:y + 6, x:x + 6]) == 0:\n",
    "                            self.new_digit_data[i, y:y + 6, x:x + 6] = cropped\n",
    "\n",
    "                        # Clip any over-saturated pixels\n",
    "                        self.new_digit_data[i] = np.clip(self.new_digit_data[i], 0, 255)\n",
    "\n",
    "            # keep 400 images\n",
    "            # inds = np.random.permutation(len(self.digit_data))\n",
    "            # keep = 400 if train else 100\n",
    "            # self.new_digit_data = self.new_digit_data[inds[:keep]]\n",
    "            # self.new_targets = self.new_targets[inds[:keep]]\n",
    "        else:\n",
    "            phase = 'train' if train else 'test'\n",
    "            datadir = os.path.join(self.datapath, phase)\n",
    "            if clutter == 1:\n",
    "                self.new_digit_data = np.load(os.path.join(datadir, 'moreclutter',\n",
    "                                                           str(digit) + '_moreclutter_data.npy'))\n",
    "                self.new_targets = np.load(os.path.join(datadir, 'moreclutter',\n",
    "                                                        str(digit) + '_moreclutter_label.npy'))\n",
    "            elif clutter == 0:\n",
    "                self.new_digit_data = np.load(os.path.join(datadir, 'clean',\n",
    "                                                           str(digit)+'_data.npy'))\n",
    "                self.new_targets = np.load(os.path.join(datadir, 'clean',\n",
    "                                                        str(digit) + '_label.npy'))\n",
    "                self.new_targets[self.new_targets == 84] -= 1\n",
    "                assert(np.max(self.new_targets) == 83)\n",
    "        self.new_targets = torch.from_numpy(self.new_targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.new_digit_data[index], self.new_targets[index]\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img, target = self.transform(img, target)\n",
    "\n",
    "        if DEBUG:\n",
    "            f, ax = plt.subplots()\n",
    "            x1, y1, x2, y2 = target\n",
    "            ax.imshow(np.asarray(img), cmap='gray', interpolation='none')\n",
    "            patch = Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=1,\n",
    "                              edgecolor='g', facecolor='none', fill=False)\n",
    "            ax.add_patch(patch)\n",
    "\n",
    "        img = self.totensor(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target_new = self.target_transform(target)\n",
    "            ti, tj, iou1, iou2 = target_new[0][0], target_new[0][1], \\\n",
    "                                 target_new[1][0], target_new[1][1]\n",
    "\n",
    "        if DEBUG:\n",
    "            print('ti ', ti, ' tj ', tj)\n",
    "            print('ious ', iou1, ' ', iou2)\n",
    "            patch = Rectangle((ti[0], ti[1]), ti[2]-ti[0], ti[3]-ti[1], linewidth=1,\n",
    "                              edgecolor='r', facecolor='none', fill=False)\n",
    "            ax.add_patch(patch)\n",
    "            patch = Rectangle((tj[0], tj[1]), tj[2] - tj[0], tj[3] - tj[1], linewidth=1,\n",
    "                              edgecolor='y', facecolor='none', fill=False)\n",
    "            ax.add_patch(patch)\n",
    "            plt.show()\n",
    "            exit()\n",
    "        #print('target new ', target)\n",
    "        return img, target, ti, tj, iou1, iou2\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.new_digit_data.shape[0]\n",
    "\n",
    "    @property\n",
    "    def raw_folder(self):\n",
    "        return os.path.join('/research/cbim/vast/tl601/Dataset', 'MNIST', 'raw')\n",
    "\n",
    "    @property\n",
    "    def processed_folder(self):\n",
    "        return os.path.join('/research/cbim/vast/tl601/Dataset', 'MNIST', 'processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ioui  (5842,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "from util.data_aug import *\n",
    "from util.augmentations import Compose\n",
    "from transform import MyBoxScaleTransform\n",
    "kwargs = {'num_workers': 8, 'pin_memory': True}\n",
    "\n",
    "train_transform = Compose([Resize(84)])\n",
    "test_transform = Compose([Resize(84)])\n",
    "trainset = MNIST_CoLoc(root='.', train=True, digit=4,\n",
    "                       datapath='/research/cbim/vast/tl601/Dataset/Synthesis_mnist',\n",
    "                       clutter=1, transform=train_transform,\n",
    "                       target_transform=MyBoxScaleTransform())\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=512, shuffle=True, **kwargs)\n",
    "\n",
    "iouis, ioujs = [], []\n",
    "for i, (data, target, ti, tj, iou1, iou2 ) in enumerate(train_loader):\n",
    "    iouis.append(iou1)\n",
    "    ioujs.append(iou2)\n",
    "\n",
    "iouis = torch.cat(iouis).numpy()\n",
    "ioujs = torch.cat(ioujs).numpy()\n",
    "print('ioui ', iouis.shape)\n",
    "f, ax = plt.subplots(2,1)\n",
    "ax[0].hist(iouis, label='iouis')\n",
    "ax[1].hist(ioujs, label='ioujs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
