nohup: ignoring input
wandb: Currently logged in as: amberberli (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.10.27 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.10.9
wandb: Syncing run ae_iou_pg_ent05_lr1e03_50_aug_2_noR3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/amberberli/selfpaced
wandb: üöÄ View run at https://wandb.ai/amberberli/selfpaced/runs/2wli45id
wandb: Run data is saved locally in wandb/run-20210422_150921-2wli45id
wandb: Run `wandb off` to turn off syncing.
total train image:  50  test image:  982
loaded pretained MNIST encoder  ae_50_lr1e03_step50_2/last.pth.tar
action_seq  tensor([[5, 6, 1, 9, 5, 6, 6, 8, 0, 4],
        [7, 8, 5, 3, 6, 5, 8, 8, 8, 3],
        [1, 4, 8, 6, 8, 3, 6, 7, 9, 5],
        [2, 5, 2, 8, 9, 6, 7, 2, 4, 2],
        [5, 3, 0, 7, 5, 1, 5, 8, 4, 9]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.],
        [-1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1.],
        [-1., -1., -1.,  1., -1., -1.,  1., -1.,  1., -1.],
        [ 1., -1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.],
        [-1.,  1., -1.,  1., -1., -1., -1., -1., -1.,  1.]])
adv  tensor([[-0.8039, -0.2051,  0.5596, -0.7274,  0.1136,  0.8012,  1.5769,  2.0783,
          2.7459,  1.4400],
        [-2.6691, -2.0899, -1.3427, -0.6297, -1.8073, -1.1392, -0.3830,  0.0978,
          0.7459,  1.4400],
        [-0.7678, -0.1690,  0.5967,  1.3303,  0.1712,  0.8608,  1.6365,  0.1183,
          0.7655, -0.5600],
        [ 3.0604,  1.6777,  2.4620,  1.1935,  2.0540,  2.7612,  3.5574,  4.0783,
          2.7459,  1.4400],
        [-0.6887, -0.0899, -1.3427, -0.6297, -1.8073, -1.1392, -0.3830,  0.0978,
          0.7459,  1.4400]], device='cuda:0')
pred_boxes  tensor([[ 5.,  5., 47., 46.],
        [15., 13., 69., 67.],
        [20., 18., 64., 61.],
        [14., 46., 42., 77.],
        [40., 17., 74., 50.]])
target_boxes  tensor([[19, 30, 46, 57],
        [45, 30, 72, 57],
        [12, 52, 39, 79],
        [15, 45, 42, 72],
        [50, 44, 77, 71]], dtype=torch.int32)


Train Epoch: 0 [0/50 (0%)]	Reward: -0.3280
action_seq  tensor([[3, 0, 6, 6, 4, 3, 7, 8, 6, 2],
        [1, 6, 6, 3, 0, 2, 0, 9, 8, 8],
        [2, 8, 6, 0, 8, 8, 9, 9, 8, 6],
        [6, 0, 8, 5, 6, 4, 8, 0, 9, 3],
        [6, 6, 6, 6, 2, 9, 0, 1, 6, 4]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.],
        [-1.,  1., -1., -1., -1.,  1., -1.,  1., -1., -1.],
        [-1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.],
        [-1.,  1., -1., -1., -1.,  1., -1., -1.,  1.,  1.],
        [-1., -1., -1., -1.,  1., -1.,  1., -1.,  1., -1.]])
adv  tensor([[ 4.0665,  4.9602,  3.6837,  2.3644,  2.9560,  1.6912,  2.0555,  2.4556,
          2.8594,  1.5938],
        [ 0.2794,  1.1330, -0.1805,  0.4797,  1.0537,  1.7899,  0.1356,  0.5152,
         -1.1210, -0.4062],
        [-3.5849, -2.7683, -2.1024, -1.4608, -0.9072, -0.1896,  0.1552, -1.4848,
         -1.1210, -0.4062],
        [ 2.0880,  2.9602,  1.6642,  2.3439,  2.9365,  3.6912,  2.0555,  2.4556,
          2.8594,  1.5938],
        [ 0.1817,  1.0364,  1.7404,  2.4220,  3.0137,  1.7508,  2.1151,  0.4956,
          0.8790, -0.4062]], device='cuda:0')
pred_boxes  tensor([[12., 28., 40., 56.],
        [13., 14., 41., 42.],
        [ 0.,  9., 52., 62.],
        [14., 16., 48., 50.],
        [ 5., 20., 38., 53.]])
target_boxes  tensor([[ 6, 40, 33, 67],
        [ 4, 37, 31, 64],
        [51, 29, 78, 56],
        [29, 35, 56, 62],
        [ 6, 42, 33, 69]], dtype=torch.int32)


Test Epoch: 0 [0/982 (0%)]	Reward: -0.4313
action_seq  tensor([[8, 3, 1, 2, 2, 6, 8, 9, 4, 2],
        [3, 3, 0, 1, 7, 7, 9, 4, 0, 4],
        [0, 0, 9, 1, 6, 4, 8, 3, 4, 4],
        [0, 0, 3, 9, 7, 2, 1, 2, 1, 0],
        [1, 0, 2, 5, 9, 9, 5, 2, 8, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1., -1.],
        [ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1., -1.,  1.,  1., -1., -1., -1.,  1., -1., -1.],
        [ 1.,  1.,  1., -1., -1., -1.,  1., -1., -1., -1.],
        [ 1., -1.,  1., -1.,  1.,  1., -1., -1., -1., -1.]])
adv  tensor([[ 3.8137,  4.5769,  3.2987,  4.0576,  2.7415,  1.4430,  0.0378,  0.6059,
         -0.8085, -0.4062],
        [-3.7947, -5.1272, -4.4845, -3.8038, -3.1794, -2.5170, -1.9427, -1.3941,
         -0.8085, -0.4062],
        [ 1.9699,  0.6960,  1.3983,  0.1171, -1.2389, -0.5570,  0.0378,  0.6059,
         -0.8085, -0.4062],
        [ 2.0285,  0.7556, -0.5636, -1.8633, -1.2194, -0.5365,  0.0573, -1.3941,
         -0.8085, -0.4062],
        [ 1.9885,  0.7146,  1.4159,  0.1367,  0.8011, -0.5170, -1.9427, -1.3941,
         -0.8085, -0.4062]], device='cuda:0')
pred_boxes  tensor([[25., 37., 53., 65.],
        [51., 38., 79., 66.],
        [ 9., 11., 38., 39.],
        [23., 26., 51., 54.],
        [16., 32., 44., 61.]])
target_boxes  tensor([[22, 52, 49, 79],
        [17, 55, 44, 82],
        [32, 31, 59, 58],
        [25, 15, 52, 42],
        [30, 44, 57, 71]], dtype=torch.int32)
action_seq  tensor([[8, 1, 4, 0, 0, 0, 1, 5, 5, 3],
        [5, 6, 0, 2, 6, 1, 5, 3, 1, 8],
        [9, 2, 4, 5, 9, 8, 4, 6, 0, 3],
        [3, 4, 3, 2, 4, 1, 7, 3, 7, 3],
        [3, 6, 7, 5, 6, 1, 1, 6, 0, 1]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1.,  1.,  1., -1.,  1., -1.,  1., -1., -1.],
        [-1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1., -1.],
        [ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1., -1.,  1.,  1., -1.,  1., -1., -1.]])
adv  tensor([[-3.4717, -2.6550, -3.9760, -3.1953, -2.6595, -2.1497, -1.6980, -1.1469,
         -0.6219, -0.3125],
        [ 2.2148,  3.0891,  3.8473,  2.6855,  1.2614,  1.8103,  0.2825,  0.8531,
         -0.6219, -0.3125],
        [ 4.1191,  5.0129,  3.7682,  2.6074,  3.2019,  3.7712,  2.2620,  0.8335,
          1.3781, -0.3125],
        [-3.4522, -4.6550, -3.9760, -3.1953, -2.6595, -2.1497, -1.6980, -1.1469,
         -0.6219, -0.3125],
        [ 4.2158,  3.0891,  1.8268,  2.6660,  3.2614,  1.8103,  0.2825,  0.8531,
         -0.6219, -0.3125]], device='cuda:0')
pred_boxes  tensor([[22.,  6., 50., 34.],
        [24., 15., 52., 43.],
        [ 6., 28., 35., 57.],
        [45., 43., 73., 72.],
        [20., 16., 50., 44.]])
target_boxes  tensor([[33, 44, 60, 71],
        [17, 27, 44, 54],
        [12, 19, 39, 46],
        [18, 16, 45, 43],
        [ 9, 33, 36, 60]], dtype=torch.int32)
action_seq  tensor([[2, 6, 5, 6, 4, 6, 1, 6, 1, 2],
        [3, 3, 5, 3, 6, 3, 8, 5, 7, 6],
        [6, 2, 1, 3, 0, 9, 0, 3, 8, 9],
        [4, 3, 2, 6, 3, 8, 6, 1, 1, 8],
        [3, 9, 3, 4, 8, 2, 2, 6, 1, 1]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1.,  1., -1.,  1., -1.,  1., -1.],
        [ 1., -1., -1., -1.,  1., -1.,  1., -1., -1.,  1.],
        [-1.,  1., -1., -1., -1.,  1., -1., -1., -1.,  1.],
        [ 1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.],
        [ 1., -1.,  1.,  1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[ 1.7889,  0.6712,  1.2137,  1.9848,  2.6980,  1.4321,  2.2983,  0.7438,
          1.0349, -0.3750],
        [ 1.7704,  0.6527,  1.1951,  1.9652,  2.6795,  1.4125,  2.2787,  0.7233,
          1.0154,  1.6250],
        [-0.1505,  0.7308, -0.7453,  0.0043,  0.7000,  1.4321,  0.2787,  0.7233,
          1.0154,  1.6250],
        [-1.9582, -3.1149, -2.6096, -1.8785, -1.2024, -0.4888, -1.6617, -1.2367,
         -0.9651, -0.3750],
        [ 0.0399, -1.0954, -0.5695, -1.8385, -3.1828, -2.4888, -1.6617, -1.2367,
         -0.9651, -0.3750]], device='cuda:0')
pred_boxes  tensor([[ 9., 28., 37., 56.],
        [37., 39., 73., 75.],
        [23., 31., 51., 59.],
        [19., 26., 47., 54.],
        [28., 39., 56., 68.]])
target_boxes  tensor([[17, 28, 44, 55],
        [20, 15, 47, 42],
        [ 2, 45, 29, 72],
        [49, 11, 76, 38],
        [55, 36, 82, 63]], dtype=torch.int32)
action_seq  tensor([[6, 4, 2, 8, 9, 3, 2, 7, 0, 5],
        [6, 6, 1, 6, 3, 3, 9, 6, 2, 4],
        [7, 8, 1, 7, 3, 0, 2, 1, 3, 8],
        [1, 6, 4, 8, 6, 2, 9, 0, 5, 7],
        [0, 6, 3, 6, 5, 1, 5, 6, 4, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.],
        [-1., -1.,  1., -1.,  1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1.,  1., -1.,  1., -1., -1., -1.],
        [-1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.],
        [-1., -1.,  1., -1., -1.,  1., -1., -1., -1., -1.]])
adv  tensor([[ 3.8256,  4.6543,  3.4689,  2.0848,  2.5781,  1.2792,  1.9545,  0.6176,
          1.1599, -0.3750],
        [-1.8833, -1.1123, -0.3348, -1.7580, -1.3028, -2.6417, -2.0055, -1.3629,
         -0.8401, -0.3750],
        [-1.9605, -1.1904, -0.4139,  0.1824,  0.6572, -0.6612, -0.0055, -1.3629,
         -0.8401, -0.3750],
        [ 3.7885,  4.6162,  3.4308,  2.0447,  2.5400,  3.2597,  1.9349,  0.5970,
          1.1404,  1.6250],
        [-1.9019, -1.1319, -0.3544, -1.7785, -1.3223, -0.6417, -2.0055, -1.3629,
         -0.8401, -0.3750]], device='cuda:0')
pred_boxes  tensor([[24., 38., 52., 67.],
        [19., 42., 47., 70.],
        [35., 15., 63., 43.],
        [ 6., 18., 40., 52.],
        [12., 22., 41., 50.]])
target_boxes  tensor([[ 6, 38, 33, 65],
        [29, 11, 56, 38],
        [32, 53, 59, 80],
        [10, 43, 37, 70],
        [49, 26, 76, 53]], dtype=torch.int32)
action_seq  tensor([[0, 3, 3, 2, 1, 5, 4, 9, 8, 8],
        [7, 4, 1, 9, 4, 8, 6, 8, 1, 8],
        [9, 3, 0, 2, 5, 6, 2, 8, 5, 6],
        [7, 4, 6, 0, 3, 9, 0, 2, 8, 0],
        [1, 9, 3, 1, 3, 6, 4, 6, 9, 7]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1., -1.,  1., -1., -1., -1.,  1.,  1.],
        [-1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.],
        [-1.,  1.,  1., -1., -1., -1., -1.,  1., -1., -1.],
        [-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.]])
adv  tensor([[ 2.1303,  2.8145,  1.5798,  2.1333,  2.9749,  1.7735,  2.3912,  2.8578,
          3.2026,  1.6562],
        [ 5.9917,  6.7149,  5.5193,  4.0913,  4.9535,  5.7930,  4.4312,  2.8979,
          1.2221, -0.3438],
        [ 0.3608,  1.0274, -0.2249, -1.7114, -0.9079, -0.1279,  0.4713,  0.9174,
         -0.7779, -0.3438],
        [-3.4634, -2.8359, -4.1272, -3.6323, -2.8483, -2.0878, -1.5092, -1.0826,
         -0.7779, -0.3438],
        [ 8.0307,  6.7549,  5.5603,  4.1333,  2.9749,  1.7735,  2.3912,  2.8578,
          3.2026,  1.6562]], device='cuda:0')
pred_boxes  tensor([[29., 24., 57., 52.],
        [25.,  0., 59., 32.],
        [ 0., 27., 33., 62.],
        [10., 25., 38., 53.],
        [41., 42., 70., 70.]])
target_boxes  tensor([[56, 12, 83, 39],
        [24,  7, 51, 34],
        [37, 16, 64, 43],
        [42,  6, 69, 33],
        [47, 43, 74, 70]], dtype=torch.int32)
action_seq  tensor([[7, 8, 2, 1, 6, 1, 9, 6, 9, 1],
        [1, 4, 8, 5, 0, 9, 1, 7, 6, 4],
        [8, 3, 6, 8, 8, 7, 0, 6, 7, 1],
        [3, 9, 7, 3, 2, 9, 6, 8, 4, 3],
        [6, 4, 3, 8, 3, 2, 6, 6, 5, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.],
        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1.,  1.,  1., -1., -1., -1., -1.,  1., -1., -1.],
        [ 1., -1., -1.,  1.,  1., -1., -1., -1., -1.,  1.],
        [-1.,  1., -1.,  1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[ 5.7575,  6.6059,  7.5246,  6.0541,  4.7253,  3.5112,  4.1781,  2.8948,
          1.4399, -0.2500],
        [-5.6565, -4.9244, -4.1219, -3.6900, -3.0960, -2.3697, -1.7624, -1.0857,
         -0.5601, -0.2500],
        [ 0.1482,  0.9389, -0.2195, -1.7691, -1.1556, -0.4097,  0.2181,  0.9143,
         -0.5601, -0.2500],
        [ 2.0320,  0.8217,  1.6828,  2.1733,  0.8064, -0.4488,  0.1781,  0.8743,
          1.4204,  1.7500],
        [-1.7356, -0.9644, -2.1414, -1.6900, -3.0960, -2.3697, -1.7624, -1.0857,
         -0.5601, -0.2500]], device='cuda:0')
pred_boxes  tensor([[11., 32., 46., 65.],
        [32., 10., 62., 38.],
        [24.,  0., 67., 42.],
        [30., 40., 58., 69.],
        [17., 34., 45., 63.]])
target_boxes  tensor([[10, 46, 37, 73],
        [ 9, 54, 36, 81],
        [ 8, 39, 35, 66],
        [38, 51, 65, 78],
        [40,  8, 67, 35]], dtype=torch.int32)
action_seq  tensor([[8, 8, 6, 7, 3, 0, 6, 9, 3, 1],
        [8, 5, 9, 8, 3, 6, 6, 0, 8, 8],
        [6, 1, 6, 1, 7, 7, 5, 8, 6, 0],
        [5, 9, 9, 0, 6, 2, 5, 6, 1, 0],
        [7, 7, 5, 9, 6, 5, 1, 4, 2, 7]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1.,  1., -1., -1.,  1.,  1., -1.],
        [-1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [-1.,  1., -1.,  1., -1., -1., -1., -1.,  1., -1.],
        [-1., -1., -1.,  1., -1.,  1., -1., -1.,  1., -1.],
        [-1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.]])
adv  tensor([[ 0.4351,  1.0389,  1.6809,  2.3298,  3.1732,  1.7216,  2.0868,  2.8026,
          1.2837, -0.2500],
        [-3.2749, -2.7081, -2.1042, -1.4934, -0.6882, -2.1788, -1.8536, -1.1779,
         -0.7163, -0.2500],
        [ 0.5708,  1.1756, -0.2009,  0.4285, -0.7673, -0.2384,  0.1064,  0.8026,
          1.2837, -0.2500],
        [ 0.4927,  1.0965,  1.7395,  2.3884,  1.2132,  1.7616,  0.1064,  0.8026,
          1.2837, -0.2500],
        [-3.3501, -2.7843, -2.1814, -1.5715, -0.7673, -0.2384,  0.1064,  0.8026,
          1.2837, -0.2500]], device='cuda:0')
pred_boxes  tensor([[23., 36., 58., 70.],
        [ 0.,  0., 53., 53.],
        [18.,  0., 61., 41.],
        [10., 13., 43., 46.],
        [30., 16., 73., 59.]])
target_boxes  tensor([[30, 52, 57, 79],
        [33, 50, 60, 77],
        [23, 26, 50, 53],
        [31, 10, 58, 37],
        [ 6, 51, 33, 78]], dtype=torch.int32)
action_seq  tensor([[2, 1, 7, 9, 9, 4, 4, 6, 7, 7],
        [6, 0, 3, 3, 5, 3, 0, 8, 0, 7],
        [9, 9, 7, 7, 9, 1, 7, 1, 6, 6],
        [6, 6, 6, 5, 0, 0, 7, 4, 4, 8],
        [5, 9, 3, 4, 2, 3, 0, 0, 9, 4]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1., -1.,  1., -1.,  1., -1.,  1., -1., -1.],
        [-1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.],
        [-1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.],
        [-1., -1., -1., -1.,  1., -1.,  1., -1., -1., -1.],
        [-1., -1.,  1.,  1., -1.,  1., -1., -1.,  1., -1.]])
adv  tensor([[ 3.1631,  1.9626,  0.7843,  1.7381,  0.4937,  1.1611, -0.0576,  0.6674,
         -0.7463, -0.3750],
        [ 3.1036,  3.9245,  2.7648,  1.7186,  0.4732,  1.1416,  1.9424,  0.6674,
         -0.7463, -0.3750],
        [-4.6220, -3.8802, -3.0985, -2.1828, -1.4467, -0.7988, -2.0380, -1.3326,
         -0.7463, -0.3750],
        [-2.7206, -1.9583, -1.1581, -0.2219,  0.5328, -0.8184, -0.0380, -1.3326,
         -0.7463, -0.3750],
        [ 1.1241,  1.9245,  2.7648,  1.7195,  0.4742,  1.1416, -0.0781,  0.6479,
          1.2537, -0.3750]], device='cuda:0')
pred_boxes  tensor([[37., 39., 70., 72.],
        [36., 25., 64., 53.],
        [ 7.,  0., 61., 52.],
        [19.,  2., 51., 34.],
        [30., 45., 58., 73.]])
target_boxes  tensor([[14, 44, 41, 71],
        [29, 21, 56, 48],
        [41, 43, 68, 70],
        [40, 22, 67, 49],
        [53, 49, 80, 76]], dtype=torch.int32)
action_seq  tensor([[4, 3, 7, 3, 1, 4, 8, 7, 8, 0],
        [1, 3, 8, 3, 0, 9, 9, 1, 4, 4],
        [7, 8, 8, 0, 2, 8, 8, 6, 7, 8],
        [6, 1, 6, 0, 7, 0, 7, 6, 8, 3],
        [2, 6, 0, 3, 3, 7, 4, 2, 6, 5]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1.,  1., -1.,  1.,  1., -1., -1., -1.],
        [-1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.],
        [-1.,  1., -1., -1.,  1., -1.,  1., -1., -1.,  1.],
        [ 1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.]])
adv  tensor([[-6.1048, -5.2509, -4.2622, -3.6108, -3.1422, -2.6689, -2.0961, -1.4861,
         -0.9645, -0.4375],
        [ 3.6013,  2.5323,  1.5796,  2.2896,  0.7982,  1.3116, -0.0961, -1.4861,
         -0.9645, -0.4375],
        [-0.3978,  0.5137,  1.5611,  2.2720,  0.7787, -0.7285, -0.1362,  0.4944,
          1.0355, -0.4375],
        [ 1.5065,  2.4375,  1.4829,  2.1929,  2.7201,  1.2325,  1.8443,  0.4739,
          1.0160,  1.5625],
        [ 5.5017,  4.4532,  5.5396,  4.2701,  2.7982,  1.3116, -0.0961, -1.4861,
         -0.9645, -0.4375]], device='cuda:0')
pred_boxes  tensor([[55., 22., 83., 50.],
        [45., 24., 74., 52.],
        [10.,  0., 62., 53.],
        [19.,  8., 53., 41.],
        [21., 37., 49., 65.]])
target_boxes  tensor([[ 2, 56, 29, 83],
        [54, 40, 81, 67],
        [32, 17, 59, 44],
        [42, 27, 69, 54],
        [28, 29, 55, 56]], dtype=torch.int32)
action_seq  tensor([[0, 0, 4, 8, 7, 7, 3, 6, 2, 4],
        [6, 3, 1, 6, 9, 6, 9, 1, 0, 4],
        [6, 7, 1, 7, 6, 9, 8, 0, 1, 4],
        [7, 6, 4, 3, 9, 7, 5, 8, 8, 6],
        [4, 3, 3, 1, 0, 0, 4, 6, 5, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1., -1., -1., -1.,  1.,  1., -1.],
        [-1.,  1., -1., -1.,  1., -1.,  1., -1., -1., -1.],
        [-1., -1.,  1., -1., -1., -1.,  1., -1.,  1., -1.],
        [-1., -1., -1.,  1.,  1.,  1., -1., -1., -1., -1.],
        [ 1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.]])
adv  tensor([[-0.0045, -1.2359, -0.5853,  0.0715,  0.9240,  1.6279,  2.2446,  2.7410,
          1.2215, -0.2812],
        [ 0.0697,  0.8598, -0.4896,  0.1691,  1.0226, -0.2921,  0.3042, -1.2395,
         -0.7785, -0.2812],
        [-0.0260,  0.7641,  1.4332,  0.0910,  0.9435,  1.6484,  2.2642,  0.7410,
          1.2215, -0.2812],
        [ 0.0492,  0.8383,  1.5104,  2.1887,  1.0431, -0.2725, -1.6958, -1.2395,
         -0.7785, -0.2812],
        [ 2.0511,  0.8402, -0.5082,  0.1496,  1.0031, -0.3126,  0.2847,  0.7605,
         -0.7785, -0.2812]], device='cuda:0')
pred_boxes  tensor([[22., 13., 50., 41.],
        [19., 32., 49., 60.],
        [16.,  4., 50., 36.],
        [19.,  8., 72., 61.],
        [33., 31., 61., 59.]])
target_boxes  tensor([[15, 38, 42, 65],
        [37, 55, 64, 82],
        [40,  5, 67, 32],
        [53, 54, 80, 81],
        [21, 16, 48, 43]], dtype=torch.int32)
Test Epoch: 0 [640/982 (62%)]	Reward: -0.4048
action_seq  tensor([[4, 8, 3, 1, 1, 3, 6, 8, 3, 0],
        [3, 9, 7, 7, 6, 1, 6, 0, 2, 5],
        [5, 5, 7, 3, 4, 6, 4, 8, 7, 1],
        [0, 5, 3, 3, 4, 3, 3, 8, 9, 6],
        [5, 7, 3, 5, 7, 2, 0, 1, 4, 9]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.],
        [-1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.],
        [ 1., -1., -1., -1., -1., -1., -1., -1., -1.,  1.],
        [-1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.]])
adv  tensor([[-3.5079, -4.6797, -3.9693, -3.3466, -2.7175, -2.1135, -1.6299, -1.2045,
         -0.9011, -0.5312],
        [-3.6056, -2.7588, -2.0289, -1.3866, -0.7371, -0.1135, -1.6299, -1.2045,
         -0.9011, -0.5312],
        [ 0.1991,  1.0849,  1.8539,  2.5363,  1.2034, -0.1731,  0.3301,  0.7760,
          1.0989, -0.5312],
        [-1.6808, -2.8340, -2.1051, -1.4637, -0.8152, -0.1926,  0.3106,  0.7555,
          1.0794,  1.4688],
        [ 5.7743,  6.7168,  7.5414,  6.2599,  6.9866,  7.6882,  6.2510,  4.7360,
          3.0794,  1.4688]], device='cuda:0')
pred_boxes  tensor([[38., 12., 68., 40.],
        [ 4., 24., 38., 58.],
        [32., 18., 67., 52.],
        [27., 32., 55., 60.],
        [27., 37., 55., 65.]])
target_boxes  tensor([[ 5, 19, 32, 46],
        [39,  4, 66, 31],
        [50, 39, 77, 66],
        [ 1,  8, 28, 35],
        [28, 42, 55, 69]], dtype=torch.int32)
action_seq  tensor([[1, 1, 4, 7, 6, 3, 5, 8, 5, 6],
        [4, 2, 6, 8, 0, 0, 1, 6, 8, 9],
        [8, 1, 2, 1, 1, 6, 8, 3, 2, 5],
        [2, 6, 7, 9, 3, 2, 1, 8, 4, 3],
        [8, 2, 2, 0, 4, 7, 4, 8, 8, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1.,  1., -1., -1., -1., -1.,  1.],
        [ 1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1.,  1.,  1., -1., -1.,  1., -1., -1., -1., -1.],
        [-1., -1.,  1., -1., -1., -1.,  1.,  1., -1., -1.],
        [-1.,  1., -1., -1., -1.,  1., -1.,  1.,  1., -1.]])
adv  tensor([[-2.6441, -1.8498, -0.7953, -0.1084,  0.4271, -1.0527, -0.4005,  0.1952,
          0.8922,  1.4375],
        [-2.4117, -3.6359, -4.6195, -3.9716, -3.4753, -2.9736, -2.3409, -1.7648,
         -1.0883, -0.5625],
        [-0.5494,  0.2655, -0.6791, -2.0117, -1.4948, -0.9736, -2.3409, -1.7648,
         -1.0883, -0.5625],
        [-0.6852,  0.1297,  1.2037, -0.1103,  0.4251,  0.9668,  1.6396,  0.2352,
         -1.0883, -0.5625],
        [ 1.2006,  2.0321,  1.1061,  1.8116,  2.3665,  2.9268,  1.5995,  2.2157,
          0.9117, -0.5625]], device='cuda:0')
pred_boxes  tensor([[32.,  6., 67., 39.],
        [ 0.,  9., 28., 37.],
        [32., 11., 62., 39.],
        [37., 35., 65., 63.],
        [12., 23., 40., 52.]])
target_boxes  tensor([[ 5, 24, 32, 51],
        [28, 47, 55, 74],
        [18, 42, 45, 69],
        [51, 19, 78, 46],
        [33, 11, 60, 38]], dtype=torch.int32)
action_seq  tensor([[2, 8, 1, 1, 9, 1, 7, 2, 9, 6],
        [0, 7, 2, 1, 1, 3, 7, 1, 9, 3],
        [2, 3, 1, 9, 8, 6, 4, 9, 0, 2],
        [4, 3, 5, 4, 8, 6, 6, 7, 4, 1],
        [3, 7, 7, 8, 2, 4, 1, 5, 3, 6]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1.,  1., -1., -1., -1.,  1.,  1.],
        [ 1., -1.,  1.,  1., -1., -1., -1., -1.,  1., -1.],
        [-1., -1.,  1., -1.,  1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1., -1.],
        [-1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.]])
adv  tensor([[ 1.5187e+00,  3.9789e-01,  1.2222e+00,  1.8668e+00,  2.6741e+00,
          1.4381e+00,  2.0524e+00,  2.6103e+00,  3.0788e+00,  1.5312e+00],
        [ 1.6711e+00,  5.5219e-01,  1.3784e+00,  3.5095e-03, -1.2282e+00,
         -4.8280e-01,  1.1195e-01,  6.5038e-01,  1.0983e+00, -4.6875e-01],
        [-2.1942e+00, -1.3316e+00, -5.2489e-01, -1.9184e+00, -1.1491e+00,
         -2.4232e+00, -1.8480e+00, -1.3301e+00, -9.0167e-01, -4.6875e-01],
        [ 5.4572e+00,  4.3754e+00,  3.2193e+00,  3.8844e+00,  4.7122e+00,
          3.4977e+00,  2.1120e+00,  6.5038e-01,  1.0983e+00, -4.6875e-01],
        [-4.1541e+00, -3.3121e+00, -2.5249e+00, -1.9184e+00, -1.1491e+00,
         -2.4232e+00, -1.8480e+00, -1.3301e+00, -9.0167e-01, -4.6875e-01]],
       device='cuda:0')
pred_boxes  tensor([[32., 20., 61., 48.],
        [41., 23., 70., 51.],
        [18., 38., 46., 66.],
        [25., 21., 53., 49.],
        [29., 26., 57., 54.]])
target_boxes  tensor([[34, 46, 61, 73],
        [28, 30, 55, 57],
        [53,  3, 80, 30],
        [15, 22, 42, 49],
        [ 0, 23, 27, 50]], dtype=torch.int32)
action_seq  tensor([[8, 6, 1, 7, 6, 5, 8, 4, 2, 5],
        [0, 5, 8, 2, 3, 8, 5, 8, 3, 0],
        [1, 7, 4, 5, 2, 6, 6, 0, 7, 0],
        [6, 9, 2, 6, 1, 6, 6, 3, 9, 1],
        [1, 3, 1, 4, 2, 8, 1, 6, 4, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1.,  1., -1.,  1., -1., -1.,  1., -1., -1.],
        [ 1., -1., -1.,  1.,  1.,  1., -1., -1.,  1., -1.],
        [ 1., -1.,  1., -1.,  1., -1., -1., -1.,  1., -1.],
        [-1., -1.,  1., -1., -1., -1., -1.,  1.,  1., -1.],
        [ 1.,  1.,  1.,  1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[-0.5754,  0.3979,  1.2858,  0.1309,  0.7948, -0.5861,  0.0084,  0.5761,
         -0.9648, -0.4062],
        [ 3.2888,  2.2797,  3.1872,  4.0723,  2.7557,  1.3944, -0.0121,  0.5566,
          1.0352, -0.4062],
        [ 1.4060,  0.3793,  1.2663,  0.1124,  0.7753, -0.6056, -0.0121,  0.5566,
          1.0352, -0.4062],
        [-0.6506,  0.3217,  1.2087,  0.0528,  0.7157,  1.3543,  1.9684,  2.5566,
          1.0352, -0.4062],
        [ 1.5603,  0.5346, -0.5960, -1.7704, -3.1456, -2.5461, -1.9721, -1.4239,
         -0.9648, -0.4062]], device='cuda:0')
pred_boxes  tensor([[ 8., 16., 51., 59.],
        [18., 13., 46., 41.],
        [10., 16., 38., 44.],
        [18., 34., 53., 68.],
        [37., 16., 66., 44.]])
target_boxes  tensor([[11,  3, 38, 30],
        [32, 22, 59, 49],
        [22, 33, 49, 60],
        [35, 54, 62, 81],
        [54, 24, 81, 51]], dtype=torch.int32)
action_seq  tensor([[8, 4, 6, 2, 9, 4, 3, 6, 4, 1],
        [8, 0, 0, 5, 6, 1, 9, 8, 0, 5],
        [2, 6, 3, 7, 0, 9, 6, 1, 2, 0],
        [1, 5, 5, 4, 6, 9, 4, 9, 3, 8],
        [1, 1, 3, 6, 1, 8, 8, 0, 2, 1]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1., -1.,  1., -1.,  1., -1., -1., -1.],
        [-1.,  1., -1., -1., -1.,  1., -1., -1., -1., -1.],
        [ 1., -1., -1., -1.,  1., -1., -1.,  1., -1., -1.],
        [ 1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1.],
        [ 1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.]])
adv  tensor([[-0.1452,  0.5882, -0.6003, -0.1462,  0.5862, -0.9682, -0.3357, -1.5328,
         -0.8137, -0.4545],
        [-2.0466, -1.3336, -2.5407, -2.1072, -1.3932, -0.9486, -2.3357, -1.5328,
         -0.8137, -0.4545],
        [-0.1442, -1.4313, -0.6189, -0.1657,  0.5667, -0.9887, -0.3552,  0.4672,
         -0.8137, -0.4545],
        [-0.1618, -1.4489, -0.6365, -0.1843, -1.4714, -1.0277, -0.3953,  0.4272,
          1.1667,  1.5455],
        [ 5.6214,  4.3920,  3.2425,  3.7346,  4.5071,  2.9918,  1.6448,  0.4672,
         -0.8137, -0.4545]], device='cuda:0')
pred_boxes  tensor([[ 8., 45., 36., 74.],
        [10.,  0., 43., 32.],
        [22., 43., 50., 71.],
        [24., 30., 59., 64.],
        [38.,  0., 68., 28.]])
target_boxes  tensor([[43, 56, 70, 83],
        [48, 13, 75, 40],
        [36, 15, 63, 42],
        [53, 18, 80, 45],
        [45,  0, 72, 27]], dtype=torch.int32)
action_seq  tensor([[3, 0, 2, 6, 3, 8, 7, 2, 3, 8],
        [5, 9, 1, 8, 6, 3, 0, 6, 3, 1],
        [8, 7, 0, 7, 7, 9, 6, 9, 8, 6],
        [9, 0, 4, 3, 6, 1, 9, 7, 6, 3],
        [2, 3, 8, 5, 9, 1, 1, 4, 0, 6]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1.,  1.,  1., -1., -1., -1.,  1., -1., -1.],
        [-1., -1., -1., -1., -1.,  1., -1., -1.,  1., -1.],
        [-1., -1., -1.,  1., -1.,  1., -1., -1., -1., -1.],
        [-1.,  1., -1.,  1., -1., -1.,  1.,  1., -1.,  1.],
        [ 1.,  1., -1., -1., -1.,  1., -1.,  1., -1., -1.]])
adv  tensor([[ 1.3612,  0.1229,  0.8926, -0.3924, -1.6892, -1.0597, -0.3830,  0.1378,
         -1.2749, -0.5200],
        [-2.6554, -1.9152, -1.1670, -0.4510,  0.2717,  0.9207, -0.4035,  0.1183,
          0.7251, -0.5200],
        [-2.5607, -1.8195, -1.0693, -0.3534, -1.6492, -1.0197, -2.3634, -1.8622,
         -1.2749, -0.5200],
        [ 3.0917,  3.8905,  2.6778,  3.4308,  2.1731,  2.8416,  3.5575,  2.0978,
          0.7055,  1.4800],
        [ 1.3436,  0.1034, -1.1474, -0.4325,  0.2913,  0.9403, -0.3830,  0.1378,
         -1.2749, -0.5200]], device='cuda:0')
pred_boxes  tensor([[21., 27., 49., 56.],
        [20., 21., 49., 49.],
        [ 0.,  3., 66., 69.],
        [21., 28., 50., 56.],
        [28., 31., 56., 59.]])
target_boxes  tensor([[ 8, 55, 35, 82],
        [25, 52, 52, 79],
        [50, 44, 77, 71],
        [45, 30, 72, 57],
        [34, 45, 61, 72]], dtype=torch.int32)


Train Epoch: 1 [0/50 (0%)]	Reward: -0.3320
action_seq  tensor([[0, 1, 4, 9, 3, 8, 3, 3, 3, 3],
        [9, 2, 1, 9, 3, 1, 1, 7, 0, 1],
        [2, 3, 6, 6, 3, 3, 0, 9, 4, 4],
        [1, 2, 6, 2, 8, 7, 9, 3, 2, 8],
        [1, 6, 6, 7, 9, 3, 5, 6, 0, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.],
        [-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1., -1., -1.,  1.,  1.,  1., -1., -1.],
        [-1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.]])
adv  tensor([[-1.8792, -3.3502, -2.4679, -1.9882, -3.2709, -2.6095, -2.0046, -1.3620,
         -0.9023, -0.4062],
        [-3.8392, -3.3101, -4.4483, -3.9882, -3.2709, -2.6095, -2.0046, -1.3620,
         -0.9023, -0.4062],
        [-3.8392, -3.3101, -4.4483, -3.9882, -3.2709, -2.6095, -2.0046, -1.3620,
         -0.9023, -0.4062],
        [ 3.8102,  2.3959,  1.3153,  1.8331,  2.6099,  3.3309,  1.9759,  0.6380,
         -0.9023, -0.4062],
        [ 3.6188,  4.2231,  3.1610,  3.6983,  4.4927,  3.2118,  3.8763,  4.5784,
          3.0782,  1.5938]], device='cuda:0')
pred_boxes  tensor([[31., 19., 60., 47.],
        [42., 36., 71., 64.],
        [18., 52., 46., 80.],
        [21., 30., 49., 59.],
        [15., 34., 49., 68.]])
target_boxes  tensor([[ 6, 40, 33, 67],
        [ 4, 37, 31, 64],
        [51, 29, 78, 56],
        [29, 35, 56, 62],
        [ 6, 42, 33, 69]], dtype=torch.int32)


Test Epoch: 1 [0/982 (0%)]	Reward: -0.3938
action_seq  tensor([[1, 8, 1, 0, 6, 0, 3, 3, 2, 2],
        [0, 4, 4, 8, 3, 6, 0, 0, 0, 3],
        [4, 4, 7, 0, 3, 8, 3, 4, 3, 8],
        [9, 5, 8, 7, 8, 1, 3, 6, 1, 1],
        [7, 8, 3, 8, 6, 6, 8, 1, 6, 1]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1.,  1.,  1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1.,  1.,  1.,  1.,  1., -1.],
        [-1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[-5.7419, -4.9791, -4.3349, -3.7789, -3.0280, -2.4904, -1.8211, -1.2398,
         -0.7157, -0.3125],
        [-5.7419, -4.9791, -4.3349, -3.7789, -3.0280, -2.4904, -1.8211, -1.2398,
         -0.7157, -0.3125],
        [ 2.0999,  0.9213, -0.3945,  0.2016, -1.0280, -2.4904, -1.8211, -1.2398,
         -0.7157, -0.3125],
        [ 1.7533,  2.5912,  3.3115,  3.9447,  4.7738,  5.3905,  4.1193,  2.7407,
          1.2843, -0.3125],
        [-3.7819, -2.9986, -2.3349, -3.7789, -3.0280, -2.4904, -1.8211, -1.2398,
         -0.7157, -0.3125]], device='cuda:0')
pred_boxes  tensor([[24.,  4., 54., 32.],
        [12., 10., 40., 38.],
        [38., 15., 66., 43.],
        [36., 13., 72., 46.],
        [12.,  0., 56., 42.]])
target_boxes  tensor([[22, 52, 49, 79],
        [17, 55, 44, 82],
        [32, 31, 59, 58],
        [25, 15, 52, 42],
        [30, 44, 57, 71]], dtype=torch.int32)
action_seq  tensor([[1, 6, 7, 2, 0, 3, 6, 6, 8, 0],
        [8, 8, 7, 3, 2, 6, 2, 8, 9, 1],
        [8, 7, 1, 4, 5, 6, 5, 4, 2, 4],
        [8, 4, 6, 2, 8, 6, 4, 9, 6, 7],
        [6, 4, 3, 0, 7, 8, 6, 3, 8, 1]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1.,  1., -1.,  1., -1., -1., -1., -1.],
        [-1., -1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.],
        [-1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.],
        [-1.,  1., -1.,  1.,  1., -1.,  1., -1., -1.,  1.],
        [-1.,  1., -1.,  1., -1., -1.,  1., -1., -1., -1.]])
adv  tensor([[ 0.2792, -0.8235, -0.1681,  0.3347, -0.9870, -0.2713, -1.6945, -1.1751,
         -0.8082, -0.4375],
        [ 1.9891,  2.9246,  3.6181,  4.1589,  2.8753,  1.6095,  2.2263,  2.7849,
          1.1722,  1.5625],
        [ 3.9491,  4.9041,  5.6171,  4.1580,  2.8743,  3.6291,  2.2459,  2.8054,
          1.1918, -0.4375],
        [ 3.9881,  4.9441,  3.6366,  4.1785,  2.8949,  1.6300,  2.2459,  0.7849,
          1.1722,  1.5625],
        [ 0.2401,  1.1580, -0.1876,  0.3152, -1.0075, -0.2909,  0.3055, -1.1751,
         -0.8082, -0.4375]], device='cuda:0')
pred_boxes  tensor([[ 9., 14., 37., 42.],
        [13., 38., 47., 73.],
        [19., 22., 47., 50.],
        [ 8., 23., 49., 65.],
        [34., 13., 62., 41.]])
target_boxes  tensor([[33, 44, 60, 71],
        [17, 27, 44, 54],
        [12, 19, 39, 46],
        [18, 16, 45, 43],
        [ 9, 33, 36, 60]], dtype=torch.int32)
action_seq  tensor([[8, 2, 0, 3, 0, 4, 8, 6, 1, 4],
        [0, 0, 2, 3, 6, 0, 7, 5, 6, 3],
        [3, 6, 3, 6, 5, 8, 5, 8, 0, 0],
        [5, 0, 9, 4, 9, 6, 7, 6, 9, 0],
        [1, 4, 9, 0, 8, 5, 7, 4, 6, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.],
        [ 1.,  1.,  1.,  1., -1., -1.,  1., -1., -1., -1.],
        [-1.,  1., -1.,  1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.],
        [ 1., -1.,  1., -1., -1., -1.,  1., -1., -1.,  1.]])
adv  tensor([[ 4.3630,  5.2905,  4.1448,  2.7979,  1.5638,  0.1903, -1.4176, -0.9585,
         -0.6526, -0.3750],
        [ 4.4225,  3.3315,  2.1653,  0.7979, -0.4567,  0.1708,  0.5824, -0.9585,
         -0.6526, -0.3750],
        [-1.4202, -0.5513, -1.7556, -1.1425, -2.4167, -1.8097, -1.4176, -0.9585,
         -0.6526, -0.3750],
        [-3.4583, -2.6089, -1.8152, -1.2021, -0.4567,  0.1708,  0.5824, -0.9585,
         -0.6526, -0.3750],
        [ 2.3288,  1.2173,  2.0491,  0.6808,  1.4456,  2.0917,  2.5228,  1.0015,
          1.3279,  1.6250]], device='cuda:0')
pred_boxes  tensor([[ 6., 22., 34., 51.],
        [ 0., 18., 28., 46.],
        [ 4.,  7., 38., 41.],
        [ 0., 30., 42., 72.],
        [32., 16., 61., 44.]])
target_boxes  tensor([[17, 28, 44, 55],
        [20, 15, 47, 42],
        [ 2, 45, 29, 72],
        [49, 11, 76, 38],
        [55, 36, 82, 63]], dtype=torch.int32)
action_seq  tensor([[6, 4, 3, 0, 7, 6, 2, 0, 6, 3],
        [5, 0, 1, 6, 0, 8, 8, 9, 5, 6],
        [0, 6, 0, 0, 3, 3, 3, 4, 6, 4],
        [3, 8, 7, 8, 1, 3, 4, 2, 1, 3],
        [3, 0, 5, 4, 2, 8, 6, 1, 0, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1., -1.],
        [-1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1.,  1., -1.,  1., -1., -1., -1., -1.]])
adv  tensor([[ 2.5101,  3.4818,  2.4436,  3.3523,  2.3128,  3.0627,  1.9251,  0.5563,
          1.0980, -0.4375],
        [-3.1012, -2.1852, -3.2810, -4.4504, -3.5485, -2.8582, -2.0349, -1.4242,
         -0.9020, -0.4375],
        [-7.0416, -6.1657, -5.2810, -4.4504, -3.5485, -2.8582, -2.0349, -1.4242,
         -0.9020, -0.4375],
        [-5.0416, -6.1657, -5.2810, -4.4504, -3.5485, -2.8582, -2.0349, -1.4242,
         -0.9020, -0.4375],
        [ 0.7816, -0.2848, -1.3601, -0.4905, -1.5681, -0.8582, -2.0349, -1.4242,
         -0.9020, -0.4375]], device='cuda:0')
pred_boxes  tensor([[14., 29., 42., 57.],
        [ 0.,  8., 42., 49.],
        [ 7., 13., 35., 41.],
        [43., 20., 71., 48.],
        [19., 22., 47., 50.]])
target_boxes  tensor([[ 6, 38, 33, 65],
        [29, 11, 56, 38],
        [32, 53, 59, 80],
        [10, 43, 37, 70],
        [49, 26, 76, 53]], dtype=torch.int32)
action_seq  tensor([[3, 5, 2, 0, 0, 6, 3, 5, 9, 9],
        [6, 2, 6, 2, 5, 7, 7, 9, 7, 2],
        [9, 4, 4, 2, 7, 0, 8, 0, 9, 9],
        [5, 4, 1, 3, 1, 6, 9, 9, 8, 3],
        [4, 3, 6, 8, 7, 9, 6, 6, 2, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1.,  1.,  1., -1.,  1., -1.,  1., -1., -1., -1.],
        [-1.,  1.,  1., -1.,  1., -1., -1., -1.,  1., -1.],
        [ 1.,  1., -1., -1.,  1.,  1., -1., -1., -1., -1.]])
adv  tensor([[-3.4913, -4.9153, -4.1442, -3.6494, -3.0867, -2.4548, -1.7221, -1.3291,
         -0.9323, -0.5312],
        [-5.4913, -4.9153, -4.1442, -3.6494, -3.0867, -2.4548, -1.7221, -1.3291,
         -0.9323, -0.5312],
        [ 2.2529,  2.9080,  1.7366,  0.2715,  0.8733, -0.4743,  0.2779, -1.3291,
         -0.9323, -0.5312],
        [ 2.2157,  2.8699,  1.6986,  0.2334,  0.8342, -0.5144,  0.2379,  0.6513,
          1.0677, -0.5312],
        [ 2.3124,  0.9461, -0.2438,  0.2910,  0.8938, -0.4548, -1.7221, -1.3291,
         -0.9323, -0.5312]], device='cuda:0')
pred_boxes  tensor([[14., 44., 42., 73.],
        [30., 39., 71., 83.],
        [22., 27., 50., 55.],
        [37., 28., 67., 56.],
        [ 0., 38., 33., 73.]])
target_boxes  tensor([[56, 12, 83, 39],
        [24,  7, 51, 34],
        [37, 16, 64, 43],
        [42,  6, 69, 33],
        [47, 43, 74, 70]], dtype=torch.int32)
action_seq  tensor([[8, 6, 7, 7, 0, 9, 6, 6, 4, 9],
        [0, 6, 7, 2, 8, 7, 7, 7, 0, 6],
        [2, 7, 9, 3, 8, 5, 4, 1, 3, 4],
        [3, 0, 4, 0, 3, 1, 7, 7, 4, 4],
        [6, 7, 9, 4, 0, 4, 6, 0, 2, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.],
        [-1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.],
        [ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1., -1., -1., -1.,  1., -1.,  1.,  1., -1., -1.],
        [-1., -1., -1.,  1.,  1., -1., -1., -1., -1., -1.]])
adv  tensor([[ 1.5387,  2.5007,  3.1570,  3.9158,  4.5551,  3.3375,  2.1718,  2.8572,
          3.2966,  1.6250],
        [-4.0170, -3.1107, -2.5100, -1.8098, -3.2487, -2.5238, -1.7286, -1.0832,
         -0.6838, -0.3750],
        [-3.9574, -5.0706, -4.4904, -3.8098, -3.2487, -2.5238, -1.7286, -1.0832,
         -0.6838, -0.3750],
        [ 1.7105,  0.6550,  1.2928,  2.0320,  2.6517,  1.4166,  2.2519,  0.9168,
         -0.6838, -0.3750],
        [-2.0961, -1.1702, -0.5500,  0.1707, -1.2487, -2.5238, -1.7286, -1.0832,
         -0.6838, -0.3750]], device='cuda:0')
pred_boxes  tensor([[ 6., 29., 59., 82.],
        [22.,  2., 63., 44.],
        [45., 29., 73., 57.],
        [36., 26., 64., 54.],
        [ 4., 17., 32., 45.]])
target_boxes  tensor([[10, 46, 37, 73],
        [ 9, 54, 36, 81],
        [ 8, 39, 35, 66],
        [38, 51, 65, 78],
        [40,  8, 67, 35]], dtype=torch.int32)
action_seq  tensor([[2, 8, 3, 6, 9, 3, 2, 3, 2, 6],
        [2, 6, 2, 8, 3, 7, 5, 6, 0, 8],
        [3, 9, 2, 6, 7, 0, 0, 8, 3, 7],
        [6, 3, 3, 9, 4, 0, 3, 3, 8, 1],
        [1, 4, 8, 6, 7, 0, 3, 6, 3, 9]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1.,  1., -1.,  1.,  1., -1.,  1., -1., -1.],
        [ 1., -1.,  1., -1.,  1.,  1., -1., -1., -1., -1.],
        [ 1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.],
        [-1.,  1., -1., -1., -1.,  1., -1., -1.,  1., -1.],
        [-1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[ 3.4856,  2.3528,  3.0080,  1.7441,  2.6460,  1.4411,  0.0675,  0.6989,
         -0.8407, -0.3125],
        [ 1.6214,  0.4700,  1.1056, -0.1768,  0.7056, -0.5188, -1.9130, -1.3011,
         -0.8407, -0.3125],
        [ 5.2932,  4.1790,  4.8517,  3.6064,  4.5269,  5.3620,  4.0275,  2.6794,
          1.1593, -0.3125],
        [-0.4333,  0.4133, -0.9715, -0.2549,  0.6265,  1.4216,  0.0470,  0.6794,
          1.1593, -0.3125],
        [-4.2214, -3.4119, -2.8143, -2.1172, -3.2749, -2.5188, -1.9130, -1.3011,
         -0.8407, -0.3125]], device='cuda:0')
pred_boxes  tensor([[12., 49., 40., 79.],
        [ 9., 21., 42., 56.],
        [25., 27., 53., 56.],
        [40., 34., 68., 62.],
        [28., 19., 57., 47.]])
target_boxes  tensor([[30, 52, 57, 79],
        [33, 50, 60, 77],
        [23, 26, 50, 53],
        [31, 10, 58, 37],
        [ 6, 51, 33, 78]], dtype=torch.int32)
action_seq  tensor([[9, 7, 2, 7, 6, 0, 2, 3, 9, 2],
        [3, 3, 6, 3, 1, 1, 6, 6, 6, 9],
        [5, 7, 2, 7, 2, 4, 9, 4, 0, 8],
        [4, 7, 0, 8, 8, 4, 5, 6, 2, 7],
        [2, 7, 8, 3, 9, 8, 0, 9, 5, 7]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.],
        [ 1.,  1., -1., -1., -1., -1.,  1.,  1., -1., -1.],
        [-1., -1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.],
        [ 1., -1.,  1., -1., -1.,  1., -1., -1., -1.,  1.],
        [-1.,  1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.]])
adv  tensor([[ 2.9491e+00,  4.1471e+00,  5.1036e+00,  3.8925e+00,  4.6263e+00,
          5.3680e+00,  4.0018e+00,  2.4325e+00,  1.0046e+00, -4.6875e-01],
        [ 1.2215e+00,  3.8147e-01, -7.1962e-01,  3.0182e-02,  7.2498e-01,
          1.4275e+00,  2.0418e+00,  4.5207e-01, -9.9542e-01, -4.6875e-01],
        [ 1.2176e+00,  2.3981e+00,  3.3380e+00,  2.1093e+00,  8.0505e-01,
         -5.1291e-01, -1.9387e+00, -1.5479e+00, -9.9542e-01, -4.6875e-01],
        [ 1.1835e+00,  3.4338e-01,  1.2618e+00,  1.1627e-02,  7.0740e-01,
          1.4080e+00,  1.7700e-03,  4.1203e-01,  9.8505e-01,  1.5312e+00],
        [ 3.0272e+00,  4.2252e+00,  3.1642e+00,  3.9530e+00,  2.6674e+00,
          1.3680e+00,  1.9822e+00,  2.4120e+00,  9.8505e-01,  1.5312e+00]],
       device='cuda:0')
pred_boxes  tensor([[ 8., 46., 36., 76.],
        [25., 44., 54., 72.],
        [22., 38., 50., 67.],
        [19., 13., 51., 46.],
        [34., 22., 76., 65.]])
target_boxes  tensor([[14, 44, 41, 71],
        [29, 21, 56, 48],
        [41, 43, 68, 70],
        [40, 22, 67, 49],
        [53, 49, 80, 76]], dtype=torch.int32)
action_seq  tensor([[2, 4, 7, 8, 2, 2, 8, 3, 9, 3],
        [2, 7, 1, 6, 8, 5, 5, 9, 3, 3],
        [0, 7, 6, 0, 6, 0, 2, 3, 5, 3],
        [7, 5, 5, 3, 5, 7, 8, 3, 6, 5],
        [3, 6, 8, 4, 8, 8, 8, 6, 0, 8]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1.,  1.,  1., -1., -1.,  1., -1.],
        [-1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.],
        [ 1., -1., -1.,  1., -1., -1., -1.,  1., -1., -1.],
        [-1., -1., -1.,  1., -1., -1., -1.,  1., -1., -1.],
        [ 1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[ 2.1413,  0.9313,  1.6349,  2.3156,  3.0330,  1.6113,  0.0807,  0.5241,
          1.1602, -0.4062],
        [ 3.9499,  4.7790,  3.5011,  2.1788,  2.8953,  3.4922,  4.0016,  4.4841,
          3.1407,  1.5938],
        [ 0.2771, -0.9515, -0.2655,  0.3937, -0.9280, -0.3692,  0.1012,  0.5437,
         -0.8398, -0.4062],
        [-1.7229, -0.9515, -0.2655,  0.3937, -0.9280, -0.3692,  0.1012,  0.5437,
         -0.8398, -0.4062],
        [-1.5872, -2.8343, -2.1678, -1.5272, -2.8684, -2.3291, -1.8793, -1.4563,
         -0.8398, -0.4062]], device='cuda:0')
pred_boxes  tensor([[21., 32., 49., 63.],
        [33., 33., 68., 68.],
        [ 4., 12., 32., 41.],
        [18., 15., 72., 69.],
        [ 0.,  0., 43., 43.]])
target_boxes  tensor([[ 2, 56, 29, 83],
        [54, 40, 81, 67],
        [32, 17, 59, 44],
        [42, 27, 69, 54],
        [28, 29, 55, 56]], dtype=torch.int32)
action_seq  tensor([[0, 7, 0, 2, 8, 2, 2, 3, 3, 7],
        [0, 4, 3, 6, 4, 6, 0, 0, 0, 2],
        [4, 6, 6, 6, 4, 6, 8, 3, 5, 2],
        [3, 3, 5, 2, 4, 4, 3, 6, 3, 7],
        [0, 7, 7, 9, 8, 7, 2, 4, 1, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1.,  1., -1.,  1.,  1., -1., -1., -1.],
        [-1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.],
        [ 1.,  1., -1., -1., -1., -1., -1., -1., -1.,  1.],
        [ 1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1.]])
adv  tensor([[ 2.0332,  0.9171,  1.7790,  2.6804,  1.2244,  1.7422,  0.3389, -1.1729,
         -0.9008, -0.5625],
        [-3.7324, -2.8856, -2.0628, -3.2200, -2.7160, -2.2383, -1.6611, -1.1729,
         -0.9008, -0.5625],
        [-1.8096, -2.9637, -2.1419, -1.2795, -0.7560, -0.2578,  0.3389, -1.1729,
         -0.9008, -0.5625],
        [ 0.1152, -1.0204, -2.1985, -1.3372, -0.8137, -0.3174,  0.2793,  0.7871,
          1.0797,  1.4375],
        [ 0.0547, -1.0809, -0.2395,  0.6414,  1.1844,  1.7022,  2.3194,  0.8271,
         -0.9008, -0.5625]], device='cuda:0')
pred_boxes  tensor([[18., 13., 46., 43.],
        [ 4., 20., 32., 48.],
        [10., 21., 44., 56.],
        [35., 46., 63., 74.],
        [35., 23., 63., 51.]])
target_boxes  tensor([[15, 38, 42, 65],
        [37, 55, 64, 82],
        [40,  5, 67, 32],
        [53, 54, 80, 81],
        [21, 16, 48, 43]], dtype=torch.int32)
Test Epoch: 1 [640/982 (62%)]	Reward: -0.3875
action_seq  tensor([[7, 8, 0, 6, 3, 1, 6, 2, 6, 4],
        [0, 0, 5, 9, 6, 9, 5, 6, 1, 2],
        [3, 8, 3, 8, 6, 5, 7, 6, 2, 1],
        [0, 3, 3, 1, 3, 4, 1, 7, 7, 0],
        [0, 6, 5, 3, 4, 9, 0, 7, 0, 4]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.],
        [ 1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.],
        [ 1., -1.,  1., -1., -1., -1.,  1., -1., -1., -1.],
        [ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1., -1., -1.,  1.,  1.,  1., -1.,  1., -1., -1.]])
adv  tensor([[ 3.4333,  4.3214,  5.0900,  3.7217,  4.5157,  3.2049,  4.0581,  2.6788,
          1.2218, -0.3125],
        [-2.1947, -3.3847, -2.6932, -2.1201, -1.3847, -0.7356,  0.0776,  0.6788,
          1.2218, -0.3125],
        [-0.1976, -1.3661, -0.6551, -2.0820, -1.3456, -0.6955,  0.1176, -1.3017,
         -0.7782, -0.3125],
        [-4.0404, -5.2490, -4.5760, -4.0224, -3.3056, -2.6760, -1.8824, -1.3017,
         -0.7782, -0.3125],
        [ 3.5876,  2.4551,  3.2072,  3.8389,  2.6153,  1.2840,  0.0981,  0.6983,
         -0.7782, -0.3125]], device='cuda:0')
pred_boxes  tensor([[10., 24., 38., 52.],
        [10., 28., 43., 61.],
        [25., 14., 60., 49.],
        [47., 29., 76., 57.],
        [24., 26., 52., 54.]])
target_boxes  tensor([[ 5, 19, 32, 46],
        [39,  4, 66, 31],
        [50, 39, 77, 66],
        [ 1,  8, 28, 35],
        [28, 42, 55, 69]], dtype=torch.int32)
action_seq  tensor([[1, 7, 3, 4, 8, 6, 4, 5, 0, 6],
        [7, 9, 3, 3, 0, 2, 6, 4, 4, 4],
        [3, 3, 3, 1, 1, 0, 7, 7, 4, 6],
        [1, 0, 8, 0, 9, 6, 2, 0, 9, 7],
        [1, 0, 5, 0, 1, 0, 8, 6, 4, 5]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1., -1.,  1., -1., -1., -1.,  1.],
        [-1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.],
        [ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1.,  1.,  1., -1., -1., -1., -1., -1.]])
adv  tensor([[-2.1375, -1.1180, -0.4664,  0.1600,  0.9834,  1.4658,  0.0287,  0.6602,
          1.1725,  1.5312],
        [ 3.7394,  4.8195,  5.5307,  4.1981,  3.0411,  1.5254,  0.0882, -1.2998,
         -0.8079, -0.4688],
        [-3.8670, -4.8846, -4.2711, -3.6828, -2.8994, -2.4551, -1.9118, -1.2998,
         -0.8079, -0.4688],
        [-1.9461, -2.9442, -2.3111, -1.7023, -0.8994, -2.4551, -1.9118, -1.2998,
         -0.8079, -0.4688],
        [ 1.9748,  1.0158, -0.3307,  0.2977, -0.8994, -2.4551, -1.9118, -1.2998,
         -0.8079, -0.4688]], device='cuda:0')
pred_boxes  tensor([[23., 13., 51., 41.],
        [25., 40., 53., 68.],
        [48., 39., 77., 67.],
        [12., 21., 40., 49.],
        [18.,  0., 47., 28.]])
target_boxes  tensor([[ 5, 24, 32, 51],
        [28, 47, 55, 74],
        [18, 42, 45, 69],
        [51, 19, 78, 46],
        [33, 11, 60, 38]], dtype=torch.int32)
action_seq  tensor([[0, 9, 2, 8, 6, 6, 0, 0, 5, 5],
        [6, 4, 9, 9, 0, 8, 9, 7, 7, 6],
        [4, 9, 0, 8, 2, 9, 3, 8, 6, 4],
        [3, 1, 5, 2, 8, 6, 6, 2, 9, 9],
        [1, 0, 0, 4, 0, 6, 5, 1, 3, 7]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [-1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.],
        [ 1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.],
        [-1.,  1., -1., -1., -1.,  1., -1., -1., -1., -1.]])
adv  tensor([[-1.6375, -2.8224, -3.8610, -3.1740, -2.4800, -1.8106, -1.4186, -1.0226,
         -0.5910, -0.2812],
        [-1.7166, -0.8820, -1.9011, -1.1935, -0.4800, -1.8106, -1.4186, -1.0226,
         -0.5910, -0.2812],
        [-3.6776, -2.8625, -1.8806, -1.1740, -2.4800, -1.8106, -1.4186, -1.0226,
         -0.5910, -0.2812],
        [ 5.8927,  4.7840,  5.8431,  6.6277,  5.4008,  4.1298,  2.5619,  0.9774,
         -0.5910, -0.2812],
        [-1.7352, -0.9015, -1.9206, -1.2141, -0.4996,  0.1894, -1.4186, -1.0226,
         -0.5910, -0.2812]], device='cuda:0')
pred_boxes  tensor([[ 0., 15., 32., 48.],
        [17., 16., 69., 68.],
        [11., 27., 39., 56.],
        [11., 39., 45., 74.],
        [19.,  4., 47., 32.]])
target_boxes  tensor([[34, 46, 61, 73],
        [28, 30, 55, 57],
        [53,  3, 80, 30],
        [15, 22, 42, 49],
        [ 0, 23, 27, 50]], dtype=torch.int32)
action_seq  tensor([[2, 6, 2, 4, 4, 8, 0, 2, 8, 8],
        [3, 0, 7, 7, 1, 9, 3, 3, 1, 6],
        [6, 2, 5, 5, 6, 6, 4, 6, 8, 9],
        [3, 7, 0, 0, 5, 9, 9, 9, 7, 2],
        [7, 9, 6, 1, 3, 0, 6, 0, 9, 0]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1., -1., -1., -1., -1.,  1.,  1.],
        [ 1.,  1., -1., -1., -1., -1., -1., -1., -1.,  1.],
        [-1.,  1., -1., -1., -1., -1.,  1., -1., -1., -1.],
        [ 1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.],
        [-1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.]])
adv  tensor([[-2.4601, -1.6010, -0.7652, -0.2045,  0.4245,  1.1859,  1.9871,  2.6707,
          3.2029,  1.6250],
        [-0.3253, -1.4652, -2.6480, -2.1068, -1.4964, -0.7545,  0.0271,  0.6902,
          1.2029,  1.6250],
        [-2.2697, -1.4086, -2.5913, -2.0492, -1.4388, -0.6949,  0.0867, -1.2698,
         -0.7776, -0.3750],
        [ 5.1893,  4.1051,  4.9985,  5.6168,  6.3054,  7.1264,  5.9675,  4.6707,
          3.2029,  1.6250],
        [-0.4259,  0.4537,  1.3110,  1.8932,  0.5222, -0.7350,  0.0466,  0.7107,
          1.2224, -0.3750]], device='cuda:0')
pred_boxes  tensor([[ 9., 19., 37., 48.],
        [48., 38., 77., 66.],
        [ 0., 21., 53., 75.],
        [24., 48., 57., 82.],
        [20., 19., 48., 47.]])
target_boxes  tensor([[11,  3, 38, 30],
        [32, 22, 59, 49],
        [22, 33, 49, 60],
        [35, 54, 62, 81],
        [54, 24, 81, 51]], dtype=torch.int32)
action_seq  tensor([[8, 3, 3, 3, 6, 1, 1, 9, 0, 9],
        [0, 3, 5, 0, 9, 5, 2, 3, 4, 4],
        [2, 8, 0, 3, 8, 9, 8, 2, 9, 4],
        [1, 2, 8, 3, 4, 0, 8, 6, 4, 2],
        [7, 2, 9, 2, 9, 6, 3, 4, 6, 8]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1.,  1.,  1., -1., -1., -1.,  1., -1.,  1.],
        [ 1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1.,  1., -1., -1., -1., -1., -1., -1.],
        [ 1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[ 3.9721,  4.7468,  3.6017,  2.4430,  1.1827,  1.7450,  2.1307,  2.6108,
          1.0767,  1.4545],
        [-1.6197, -2.9221, -4.1454, -3.3607, -2.6601, -2.1359, -1.7902, -1.3492,
         -0.9038, -0.5455],
        [ 0.3208, -0.9622, -2.1649, -1.3607, -2.6601, -2.1359, -1.7902, -1.3492,
         -0.9038, -0.5455],
        [-1.6597, -2.9622, -2.1649, -1.3607, -2.6601, -2.1359, -1.7902, -1.3492,
         -0.9038, -0.5455],
        [-5.6001, -4.9221, -4.1454, -3.3607, -2.6601, -2.1359, -1.7902, -1.3492,
         -0.9038, -0.5455]], device='cuda:0')
pred_boxes  tensor([[45., 49., 74., 77.],
        [18., 34., 46., 63.],
        [12., 19., 40., 49.],
        [24., 10., 52., 38.],
        [ 7., 36., 40., 71.]])
target_boxes  tensor([[43, 56, 70, 83],
        [48, 13, 75, 40],
        [36, 15, 63, 42],
        [53, 18, 80, 45],
        [45,  0, 72, 27]], dtype=torch.int32)
action_seq  tensor([[1, 3, 9, 4, 9, 7, 7, 4, 7, 3],
        [6, 1, 2, 0, 6, 2, 6, 4, 9, 2],
        [2, 2, 8, 6, 4, 4, 5, 8, 3, 7],
        [6, 3, 8, 3, 9, 7, 6, 9, 7, 3],
        [1, 5, 3, 2, 6, 0, 6, 7, 2, 0]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1., -1.,  1., -1., -1., -1.,  1., -1., -1.],
        [-1.,  1.,  1.,  1., -1., -1., -1., -1.,  1., -1.],
        [ 1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.],
        [-1.,  1., -1., -1., -1., -1.,  1., -1., -1., -1.],
        [ 1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1.]])
adv  tensor([[ 2.3470,  1.2387, -0.0404,  0.6045, -0.7631, -0.3264,  0.4792,  1.0491,
         -0.6777, -0.2400],
        [ 2.2884,  3.2006,  1.9401,  0.5860, -0.7826, -0.3459,  0.4587,  1.0296,
          1.3223, -0.2400],
        [ 7.9603,  6.9096,  5.6862,  4.3701,  5.0602,  3.5350,  4.3796,  4.9895,
          3.3028,  1.7600],
        [-1.5748, -0.7017, -2.0023, -1.3760, -0.7436, -0.3059,  0.4987, -0.9509,
         -0.6777, -0.2400],
        [ 6.0541,  4.9838,  5.7613,  6.4668,  5.1578,  3.6346,  2.4587,  1.0296,
          1.3223, -0.2400]], device='cuda:0')
pred_boxes  tensor([[54., 45., 83., 73.],
        [ 2., 28., 30., 57.],
        [18., 24., 46., 54.],
        [38., 39., 82., 83.],
        [19., 29., 47., 57.]])
target_boxes  tensor([[43, 35, 70, 62],
        [23, 34, 50, 61],
        [24, 21, 51, 48],
        [19, 30, 46, 57],
        [ 9, 26, 36, 53]], dtype=torch.int32)


Train Epoch: 2 [0/50 (0%)]	Reward: -0.4360
action_seq  tensor([[2, 0, 0, 0, 2, 6, 2, 7, 7, 8],
        [4, 8, 9, 8, 9, 2, 4, 3, 3, 4],
        [7, 0, 7, 1, 8, 3, 1, 2, 0, 3],
        [3, 0, 5, 8, 1, 2, 0, 7, 2, 0],
        [8, 9, 3, 7, 7, 5, 3, 6, 9, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1., -1., -1., -1., -1., -1.,  1., -1., -1.],
        [ 1., -1., -1., -1., -1.,  1.,  1., -1., -1., -1.],
        [-1., -1.,  1.,  1., -1.,  1., -1., -1., -1., -1.],
        [ 1.,  1., -1., -1., -1.,  1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1., -1., -1.,  1., -1.,  1.]])
adv  tensor([[-0.2793, -1.3245, -2.6947, -2.0596, -1.5123, -0.8961, -0.1154,  0.5459,
         -0.8692, -0.5938],
        [-0.3389, -1.3841, -0.7357, -0.0801,  0.4877,  1.1244, -0.0959, -1.4541,
         -0.8692, -0.5938],
        [-0.3213,  0.6540,  1.3239, -0.0205, -1.4722, -0.8561, -2.0959, -1.4541,
         -0.8692, -0.5938],
        [-0.2413, -1.2864, -2.6566, -2.0205, -1.4722, -0.8561, -2.0959, -1.4541,
         -0.8692, -0.5938],
        [-2.4327, -1.4788, -0.8304, -0.1767,  0.3901,  1.0248,  1.8250,  2.5058,
          1.1113,  1.4062]], device='cuda:0')
pred_boxes  tensor([[10., 14., 38., 43.],
        [26., 44., 54., 73.],
        [44., 15., 73., 43.],
        [31., 13., 59., 41.],
        [18., 39., 61., 83.]])
target_boxes  tensor([[ 6, 40, 33, 67],
        [ 4, 37, 31, 64],
        [51, 29, 78, 56],
        [29, 35, 56, 62],
        [ 6, 42, 33, 69]], dtype=torch.int32)


Test Epoch: 2 [0/982 (0%)]	Reward: -0.3625
action_seq  tensor([[4, 2, 9, 6, 1, 8, 8, 3, 2, 1],
        [2, 8, 0, 2, 9, 7, 5, 3, 6, 7],
        [7, 3, 6, 8, 0, 6, 2, 0, 2, 0],
        [3, 8, 4, 0, 1, 5, 1, 5, 2, 3],
        [9, 8, 6, 1, 8, 2, 9, 1, 2, 4]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1., -1.],
        [ 1., -1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.],
        [-1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [ 1.,  1.,  1.,  1.,  1., -1., -1., -1., -1., -1.],
        [-1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.]])
adv  tensor([[ 5.5812,  4.5644,  3.3160,  2.0874,  2.8651,  1.6631,  2.2487,  2.6188,
          1.0349, -0.3750],
        [ 5.4650,  4.4462,  5.2184,  6.0278,  4.8270,  3.6436,  2.2292,  2.5983,
          1.0154,  1.6250],
        [-2.0887, -1.1631, -2.4691, -1.7359, -0.9962, -2.2372, -1.6917, -1.3617,
         -0.9651, -0.3750],
        [ 3.8117,  2.7773,  1.5113,  0.2641, -0.9962, -2.2372, -1.6917, -1.3617,
         -0.9651, -0.3750],
        [ 5.2726,  6.2724,  7.0621,  7.8901,  6.7079,  7.5645,  6.1891,  4.5787,
          3.0154,  1.6250]], device='cuda:0')
pred_boxes  tensor([[18., 26., 46., 54.],
        [15., 28., 48., 63.],
        [ 0., 17., 28., 46.],
        [36.,  8., 65., 36.],
        [29., 34., 57., 62.]])
target_boxes  tensor([[22, 52, 49, 79],
        [17, 55, 44, 82],
        [32, 31, 59, 58],
        [25, 15, 52, 42],
        [30, 44, 57, 71]], dtype=torch.int32)
action_seq  tensor([[4, 1, 2, 0, 0, 4, 7, 5, 6, 7],
        [0, 0, 8, 4, 6, 6, 4, 5, 9, 2],
        [8, 2, 8, 9, 5, 7, 6, 7, 1, 0],
        [8, 2, 2, 3, 0, 2, 0, 6, 2, 4],
        [8, 9, 0, 8, 9, 1, 0, 1, 2, 0]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1.,  1., -1., -1., -1.,  1., -1., -1.,  1.],
        [ 1.,  1., -1.,  1., -1., -1., -1., -1.,  1., -1.],
        [-1.,  1., -1., -1., -1., -1.,  1., -1., -1.,  1.],
        [-1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [-1., -1.,  1., -1., -1.,  1.,  1., -1.,  1., -1.]])
adv  tensor([[ 1.6196,  0.5955,  1.4212,  0.3622,  0.9029,  1.5434,  2.0005,  0.5686,
          1.0169,  1.4688],
        [ 1.7163,  0.6912, -0.5007,  0.4413, -1.0385, -0.4175,  0.0201,  0.5891,
          1.0364, -0.5312],
        [-0.3599,  0.6150, -0.5788,  0.3622,  0.9029,  1.5434,  2.0005,  0.5686,
          1.0169,  1.4688],
        [-2.1490, -1.1926, -2.4040, -1.4806, -0.9594, -2.3580, -1.9399, -1.3913,
         -0.9636, -0.5312],
        [ 1.5405,  2.5350,  3.3802,  2.3416,  2.9019,  3.5629,  2.0201,  0.5891,
          1.0364, -0.5312]], device='cuda:0')
pred_boxes  tensor([[25., 18., 53., 46.],
        [ 4., 19., 32., 47.],
        [26., 15., 68., 57.],
        [ 4., 44., 32., 74.],
        [21., 17., 50., 45.]])
target_boxes  tensor([[33, 44, 60, 71],
        [17, 27, 44, 54],
        [12, 19, 39, 46],
        [18, 16, 45, 43],
        [ 9, 33, 36, 60]], dtype=torch.int32)
action_seq  tensor([[8, 0, 6, 9, 8, 3, 1, 7, 7, 6],
        [6, 2, 0, 3, 8, 3, 1, 1, 0, 1],
        [8, 5, 9, 4, 0, 9, 2, 7, 2, 0],
        [5, 2, 2, 3, 5, 6, 9, 6, 6, 6],
        [5, 0, 1, 6, 1, 9, 3, 5, 6, 7]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,  1.],
        [-1.,  1.,  1., -1.,  1., -1.,  1., -1., -1., -1.],
        [-1., -1., -1.,  1., -1.,  1.,  1., -1.,  1., -1.],
        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1.,  1.,  1., -1., -1.,  1.]])
adv  tensor([[ 2.1469,  2.8625,  1.7545,  2.4034,  3.0916,  3.7222,  2.2759,  0.8468,
          1.2347,  1.5625],
        [ 2.2982,  3.0168,  1.9098,  0.5411,  1.2088, -0.1987,  0.3354, -1.1132,
         -0.7457, -0.4375],
        [ 2.1254,  2.8410,  3.7535,  4.4229,  3.1102,  3.7418,  2.2954,  0.8673,
          1.2543, -0.4375],
        [-5.4459, -4.8064, -3.9711, -3.3798, -2.7512, -2.1791, -1.6646, -1.1132,
         -0.7457, -0.4375],
        [ 0.1664,  0.8625,  1.7545,  2.4034,  3.0916,  3.7222,  2.2759,  0.8468,
          1.2347,  1.5625]], device='cuda:0')
pred_boxes  tensor([[30., 13., 73., 55.],
        [24., 25., 52., 53.],
        [16., 36., 44., 65.],
        [ 0., 39., 42., 83.],
        [20., 16., 55., 49.]])
target_boxes  tensor([[17, 28, 44, 55],
        [20, 15, 47, 42],
        [ 2, 45, 29, 72],
        [49, 11, 76, 38],
        [55, 36, 82, 63]], dtype=torch.int32)
action_seq  tensor([[5, 3, 4, 7, 7, 0, 7, 1, 7, 5],
        [0, 6, 1, 1, 2, 6, 3, 0, 3, 7],
        [0, 2, 7, 4, 7, 8, 4, 6, 8, 6],
        [0, 7, 1, 3, 9, 3, 2, 7, 0, 1],
        [4, 8, 3, 0, 3, 1, 8, 0, 7, 0]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.],
        [ 1., -1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1.],
        [-1.,  1.,  1., -1.,  1., -1., -1., -1., -1., -1.],
        [ 1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [ 1., -1.,  1., -1.,  1.,  1., -1., -1.,  1., -1.]])
adv  tensor([[-3.8111, -3.0926, -2.3345, -1.6322, -1.0166, -0.3013, -1.7880, -1.3642,
         -0.8729, -0.2188],
        [ 5.8179,  4.6154,  5.4507,  4.2115,  2.8653,  1.6001,  2.1525,  0.5957,
          1.1076,  1.7812],
        [ 0.1479,  0.9074, -0.3150, -1.6117, -0.9970, -2.3013, -1.7880, -1.3642,
         -0.8729, -0.2188],
        [-1.7925, -3.0730, -2.3150, -1.6117, -0.9970, -2.3013, -1.7880, -1.3642,
         -0.8729, -0.2188],
        [ 3.9155,  2.6926,  3.5083,  2.2506,  2.9043,  1.6392,  0.1720,  0.6163,
          1.1271, -0.2188]], device='cuda:0')
pred_boxes  tensor([[48., 22., 83., 56.],
        [26., 13., 55., 41.],
        [13.,  6., 45., 39.],
        [49., 32., 77., 60.],
        [40., 15., 68., 43.]])
target_boxes  tensor([[ 6, 38, 33, 65],
        [29, 11, 56, 38],
        [32, 53, 59, 80],
        [10, 43, 37, 70],
        [49, 26, 76, 53]], dtype=torch.int32)
action_seq  tensor([[0, 1, 5, 6, 8, 2, 3, 0, 1, 9],
        [0, 3, 0, 4, 6, 0, 3, 9, 4, 7],
        [3, 7, 9, 1, 5, 9, 8, 1, 2, 4],
        [4, 8, 1, 6, 0, 1, 9, 6, 0, 8],
        [3, 6, 6, 8, 4, 0, 6, 7, 8, 0]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1.,  1.,  1., -1., -1., -1., -1., -1.,  1.],
        [ 1., -1., -1.,  1., -1., -1.,  1.,  1., -1., -1.],
        [ 1.,  1.,  1., -1., -1.,  1.,  1., -1., -1., -1.],
        [ 1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.]])
adv  tensor([[-3.7334, -2.8562, -4.2106, -3.4640, -2.9940, -2.4876, -1.8814, -1.2376,
         -0.8082, -0.4375],
        [ 3.9942,  2.9299,  1.6341,  0.4188, -1.0917, -0.5667,  0.0590,  0.7224,
          1.1722,  1.5625],
        [ 1.9737,  0.8889,  1.5931,  2.3973,  0.9064,  1.4528,  2.0990,  0.7624,
         -0.8082, -0.4375],
        [ 4.0117,  2.9475,  1.6507,  0.4364,  0.9464,  1.4929,  0.1186, -1.2376,
         -0.8082, -0.4375],
        [-1.8496, -2.9734, -2.3083, -1.5431, -1.0536, -0.5276,  0.0990,  0.7624,
         -0.8082, -0.4375]], device='cuda:0')
pred_boxes  tensor([[10., 23., 38., 51.],
        [15., 22., 43., 50.],
        [42., 26., 70., 54.],
        [11.,  0., 40., 28.],
        [ 8.,  0., 42., 34.]])
target_boxes  tensor([[56, 12, 83, 39],
        [24,  7, 51, 34],
        [37, 16, 64, 43],
        [42,  6, 69, 33],
        [47, 43, 74, 70]], dtype=torch.int32)
action_seq  tensor([[9, 2, 1, 2, 1, 6, 7, 6, 5, 7],
        [0, 8, 3, 4, 2, 7, 7, 7, 0, 0],
        [4, 9, 3, 8, 0, 6, 1, 0, 7, 6],
        [7, 4, 0, 2, 8, 3, 1, 7, 3, 4],
        [2, 8, 2, 2, 6, 2, 2, 0, 8, 9]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1., -1.],
        [-1., -1.,  1., -1.,  1., -1., -1., -1., -1., -1.],
        [ 1., -1., -1., -1.,  1.,  1., -1., -1., -1.,  1.],
        [-1.,  1., -1., -1., -1.,  1., -1., -1., -1., -1.],
        [ 1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[ 3.7115,  4.6005,  3.4801,  2.3776,  0.9504,  1.6224,  0.3453,  0.9480,
         -0.7154, -0.3438],
        [-2.0551, -1.2227, -0.3832, -1.5228, -0.9705, -2.3376, -1.6351, -1.0520,
         -0.7154, -0.3438],
        [ 1.7145,  0.5634,  1.4215,  2.3200,  2.9123,  1.5833,  0.3053,  0.9080,
          1.2651,  1.6562],
        [-2.0531, -1.2227, -2.4027, -1.5433, -0.9900, -0.3376, -1.6351, -1.0520,
         -0.7154, -0.3438],
        [-1.9555, -3.1436, -4.3431, -3.5032, -2.9705, -2.3376, -1.6351, -1.0520,
         -0.7154, -0.3438]], device='cuda:0')
pred_boxes  tensor([[19., 26., 53., 60.],
        [36., 26., 64., 54.],
        [19., 19., 47., 47.],
        [26., 17., 54., 45.],
        [ 0., 36., 28., 68.]])
target_boxes  tensor([[10, 46, 37, 73],
        [ 9, 54, 36, 81],
        [ 8, 39, 35, 66],
        [38, 51, 65, 78],
        [40,  8, 67, 35]], dtype=torch.int32)
action_seq  tensor([[0, 1, 7, 0, 6, 4, 6, 8, 9, 3],
        [2, 2, 7, 9, 6, 7, 0, 2, 0, 7],
        [2, 1, 2, 9, 0, 7, 9, 1, 2, 6],
        [7, 6, 2, 2, 6, 5, 3, 2, 9, 6],
        [6, 5, 2, 8, 5, 0, 8, 6, 6, 6]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1.,  1., -1., -1.,  1., -1., -1., -1.,  1.],
        [ 1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1., -1.],
        [-1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[-5.9571, -5.2282, -4.5549, -3.6223, -3.0277, -2.4585, -1.8837, -1.3029,
         -0.6532, -0.3125],
        [ 3.7128,  2.5188,  1.2497,  0.2204,  0.8551,  1.4624,  0.0568,  0.6571,
          1.3273,  1.6875],
        [ 5.6708,  4.4964,  3.2478,  2.2390,  2.8932,  1.5015,  0.0968,  0.6971,
         -0.6532, -0.3125],
        [-3.9972, -3.2478, -2.5549, -3.6223, -3.0277, -2.4585, -1.8837, -1.3029,
         -0.6532, -0.3125],
        [-3.9972, -3.2478, -2.5549, -3.6223, -3.0277, -2.4585, -1.8837, -1.3029,
         -0.6532, -0.3125]], device='cuda:0')
pred_boxes  tensor([[15., 10., 44., 38.],
        [15., 37., 43., 67.],
        [18., 40., 46., 68.],
        [ 3., 47., 36., 83.],
        [ 0.,  0., 52., 53.]])
target_boxes  tensor([[30, 52, 57, 79],
        [33, 50, 60, 77],
        [23, 26, 50, 53],
        [31, 10, 58, 37],
        [ 6, 51, 33, 78]], dtype=torch.int32)
action_seq  tensor([[3, 5, 3, 1, 6, 7, 2, 3, 1, 3],
        [4, 8, 0, 3, 3, 6, 4, 7, 6, 3],
        [1, 8, 7, 0, 5, 0, 8, 6, 7, 4],
        [8, 0, 7, 3, 8, 8, 6, 1, 4, 3],
        [8, 7, 3, 0, 2, 5, 3, 0, 8, 1]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1.,  1., -1.,  1., -1., -1., -1.],
        [ 1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.],
        [ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1.,  1.,  1.,  1., -1., -1., -1.,  1., -1.,  1.],
        [-1., -1.,  1., -1., -1., -1.,  1., -1., -1., -1.]])
adv  tensor([[ 0.0923, -1.1372, -0.3602,  0.4261,  0.9981, -0.3800,  0.0892, -1.3304,
         -0.9335, -0.4062],
        [ 5.8569,  4.6860,  5.5227,  4.3470,  2.9386,  1.5800,  2.0697,  0.6696,
         -0.9335, -0.4062],
        [-3.7114, -4.9800, -4.2410, -3.4948, -2.9618, -2.3604, -1.9108, -1.3304,
         -0.9335, -0.4062],
        [ 3.8609,  4.6889,  3.5061,  2.3089,  0.8809,  1.5204,  2.0101,  2.6295,
          1.0469,  1.5938],
        [-1.8686, -1.0972, -0.3201, -1.5543, -1.0019, -0.3800,  0.0892, -1.3304,
         -0.9335, -0.4062]], device='cuda:0')
pred_boxes  tensor([[45., 44., 73., 72.],
        [21., 21., 49., 49.],
        [19.,  4., 52., 36.],
        [34.,  9., 63., 37.],
        [24., 28., 52., 56.]])
target_boxes  tensor([[14, 44, 41, 71],
        [29, 21, 56, 48],
        [41, 43, 68, 70],
        [40, 22, 67, 49],
        [53, 49, 80, 76]], dtype=torch.int32)
action_seq  tensor([[6, 0, 1, 7, 8, 9, 8, 3, 3, 2],
        [8, 1, 3, 7, 3, 3, 8, 7, 1, 6],
        [0, 7, 7, 6, 6, 8, 0, 9, 1, 8],
        [1, 6, 6, 0, 1, 2, 2, 1, 4, 8],
        [0, 8, 1, 0, 3, 2, 2, 4, 2, 4]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.],
        [-1.,  1.,  1., -1.,  1.,  1., -1., -1., -1., -1.],
        [ 1., -1., -1., -1., -1., -1.,  1., -1.,  1., -1.],
        [ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1., -1.,  1., -1.,  1., -1., -1., -1., -1., -1.]])
adv  tensor([[-4.0528, -3.2737, -2.7069, -2.0714, -1.1763, -0.3994, -1.6977, -1.1151,
         -0.6844, -0.3125],
        [ 1.8085,  2.6472,  1.2531, -0.0909,  0.8237, -0.3994, -1.6977, -1.1151,
         -0.6844, -0.3125],
        [-0.2266, -1.4280, -0.8436, -0.1886,  0.7241,  1.5215,  2.2623,  0.8654,
          1.3156, -0.3125],
        [-3.9552, -5.1946, -4.6473, -4.0314, -3.1567, -2.3994, -1.6977, -1.1151,
         -0.6844, -0.3125],
        [-0.0743, -1.2737, -0.6874, -2.0509, -1.1567, -2.3994, -1.6977, -1.1151,
         -0.6844, -0.3125]], device='cuda:0')
pred_boxes  tensor([[41., 24., 69., 52.],
        [48., 24., 77., 52.],
        [10.,  1., 52., 42.],
        [10.,  7., 38., 35.],
        [21., 13., 49., 41.]])
target_boxes  tensor([[ 2, 56, 29, 83],
        [54, 40, 81, 67],
        [32, 17, 59, 44],
        [42, 27, 69, 54],
        [28, 29, 55, 56]], dtype=torch.int32)
action_seq  tensor([[3, 3, 8, 5, 7, 8, 0, 7, 3, 9],
        [6, 8, 9, 9, 7, 8, 2, 6, 1, 4],
        [2, 7, 3, 8, 4, 8, 5, 4, 6, 7],
        [7, 3, 4, 3, 6, 3, 8, 7, 8, 9],
        [5, 0, 2, 3, 8, 1, 3, 1, 0, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.],
        [-1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.],
        [-1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.],
        [-1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.]])
adv  tensor([[-3.8646, -5.1032, -4.3655, -3.4310, -2.9607, -2.3907, -1.8783, -1.3607,
         -0.9326, -0.5000],
        [-3.9818, -3.2009, -2.4446, -1.4906, -1.0007, -0.4103,  0.1217, -1.3607,
         -0.9326, -0.5000],
        [ 3.6500,  4.5061,  3.3220,  4.3326,  2.8626,  3.4901,  2.0426,  2.5992,
          1.0479,  1.5000],
        [ 3.6500,  4.5061,  3.3220,  4.3326,  2.8626,  3.4901,  2.0426,  2.5992,
          1.0479,  1.5000],
        [ 3.8395,  4.6985,  3.5154,  2.5094,  1.0198, -0.3907, -1.8783, -1.3607,
         -0.9326, -0.5000]], device='cuda:0')
pred_boxes  tensor([[45., 22., 80., 57.],
        [18., 21., 60., 63.],
        [34., 18., 67., 52.],
        [38., 31., 74., 67.],
        [24., 20., 52., 48.]])
target_boxes  tensor([[15, 38, 42, 65],
        [37, 55, 64, 82],
        [40,  5, 67, 32],
        [53, 54, 80, 81],
        [21, 16, 48, 43]], dtype=torch.int32)
Test Epoch: 2 [640/982 (62%)]	Reward: -0.3912
action_seq  tensor([[3, 8, 0, 8, 0, 2, 0, 8, 2, 0],
        [0, 8, 1, 2, 8, 3, 6, 2, 6, 9],
        [0, 1, 6, 3, 2, 0, 7, 0, 9, 2],
        [9, 8, 2, 1, 7, 0, 9, 8, 4, 4],
        [8, 6, 5, 3, 5, 3, 4, 9, 8, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1.,  1., -1.,  1.,  1., -1., -1., -1., -1.],
        [ 1., -1.,  1., -1.,  1.,  1., -1., -1., -1., -1.],
        [-1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.],
        [-1., -1.,  1., -1., -1.,  1., -1.,  1., -1., -1.],
        [-1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.]])
adv  tensor([[ 5.4153e-02,  9.3884e-01,  1.5161e+00,  4.8523e-02,  5.5414e-01,
         -7.6634e-01, -1.9421e+00, -1.3935e+00, -8.0792e-01, -4.6875e-01],
        [ 2.0542e+00,  9.3884e-01,  1.5161e+00,  4.8523e-02,  5.5414e-01,
         -7.6634e-01, -1.9421e+00, -1.3935e+00, -8.0792e-01, -4.6875e-01],
        [-3.7886e+00, -2.9430e+00, -2.4038e+00, -1.8919e+00, -3.4263e+00,
         -2.7663e+00, -1.9421e+00, -1.3935e+00, -8.0792e-01, -4.6875e-01],
        [-2.4872e-03,  8.8123e-01,  1.4585e+00, -1.1047e-02,  4.9457e-01,
          1.1936e+00,  3.8361e-02,  6.0649e-01, -8.0792e-01, -4.6875e-01],
        [ 1.8237e+00,  2.7260e+00,  3.3218e+00,  3.8913e+00,  2.4164e+00,
          3.1350e+00,  1.9983e+00,  5.6645e-01,  1.1725e+00,  1.5312e+00]],
       device='cuda:0')
pred_boxes  tensor([[16.,  2., 44., 30.],
        [ 8., 20., 36., 48.],
        [17., 23., 45., 51.],
        [29., 21., 57., 49.],
        [34., 39., 68., 74.]])
target_boxes  tensor([[ 5, 19, 32, 46],
        [39,  4, 66, 31],
        [50, 39, 77, 66],
        [ 1,  8, 28, 35],
        [28, 42, 55, 69]], dtype=torch.int32)
action_seq  tensor([[4, 5, 9, 6, 8, 2, 6, 1, 3, 7],
        [1, 7, 2, 1, 6, 8, 5, 3, 1, 7],
        [2, 8, 2, 4, 3, 9, 0, 6, 8, 3],
        [7, 0, 8, 1, 0, 8, 7, 4, 9, 4],
        [4, 2, 7, 7, 7, 8, 2, 8, 1, 6]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1.,  1., -1.,  1., -1.,  1., -1., -1.],
        [ 1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1., -1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.],
        [-1., -1., -1.,  1., -1., -1.,  1., -1.,  1., -1.],
        [ 1., -1., -1., -1., -1.,  1., -1.,  1.,  1.,  1.]])
adv  tensor([[ 2.0402e+00,  9.5505e-01,  1.7236e+00,  2.4343e+00,  1.1655e+00,
          1.8081e+00,  3.7497e-01,  8.8338e-01, -5.5975e-01, -2.8125e-01],
        [-1.7069e+00, -2.8282e+00, -2.0997e+00, -3.4465e+00, -2.7554e+00,
         -2.1519e+00, -1.6055e+00, -1.1166e+00, -5.5975e-01, -2.8125e-01],
        [ 4.0568e+00,  2.9931e+00,  3.7812e+00,  2.4939e+00,  1.2251e+00,
         -1.5186e-01, -1.6055e+00, -1.1166e+00, -5.5975e-01, -2.8125e-01],
        [ 2.1057e-03,  9.1794e-01,  1.6845e+00,  2.3962e+00,  1.1255e+00,
          1.7690e+00,  2.3545e+00,  8.6385e-01,  1.4402e+00, -2.8125e-01],
        [ 3.7726e+00,  2.7050e+00,  3.4902e+00,  4.2195e+00,  4.9888e+00,
          5.6694e+00,  4.2754e+00,  4.8238e+00,  3.4207e+00,  1.7188e+00]],
       device='cuda:0')
pred_boxes  tensor([[24., 24., 58., 58.],
        [36., 12., 65., 40.],
        [ 7., 29., 35., 58.],
        [27., 12., 55., 40.],
        [32., 11., 65., 45.]])
target_boxes  tensor([[ 5, 24, 32, 51],
        [28, 47, 55, 74],
        [18, 42, 45, 69],
        [51, 19, 78, 46],
        [33, 11, 60, 38]], dtype=torch.int32)
action_seq  tensor([[6, 1, 4, 7, 9, 7, 2, 6, 9, 3],
        [0, 6, 7, 6, 0, 5, 7, 9, 7, 4],
        [8, 6, 7, 5, 5, 2, 8, 4, 3, 7],
        [0, 4, 4, 7, 1, 6, 7, 6, 3, 2],
        [2, 3, 8, 0, 2, 6, 1, 5, 1, 7]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1., -1.,  1., -1.,  1., -1.,  1.,  1.],
        [ 1., -1., -1., -1.,  1., -1.,  1.,  1., -1.,  1.],
        [-1., -1., -1., -1., -1., -1.,  1., -1., -1.,  1.],
        [ 1.,  1.,  1., -1., -1.,  1., -1.,  1., -1., -1.],
        [ 1., -1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.]])
adv  tensor([[ 3.3639,  4.3450,  2.9674,  3.7245,  4.3295,  3.2688,  3.9011,  2.4260,
          2.9872,  1.3125],
        [ 3.4020,  2.3636,  2.9870,  3.7430,  4.3490,  3.2883,  3.9216,  2.4455,
          0.9872,  1.3125],
        [-2.3831, -1.4597, -0.8753, -0.1583,  0.4086,  1.3284,  1.9411,  0.4455,
          0.9872,  1.3125],
        [ 3.6139,  2.5765,  1.1823, -0.1007,  0.4672,  1.3870, -0.0189,  0.4856,
         -0.9933, -0.6875],
        [ 3.6305,  2.5941,  3.2204,  1.9589,  0.5268, -0.5730, -1.9993, -1.5144,
         -0.9933, -0.6875]], device='cuda:0')
pred_boxes  tensor([[28., 42., 63., 77.],
        [25., 15., 66., 56.],
        [24., 18., 67., 62.],
        [24., 16., 53., 44.],
        [16., 26., 44., 55.]])
target_boxes  tensor([[34, 46, 61, 73],
        [28, 30, 55, 57],
        [53,  3, 80, 30],
        [15, 22, 42, 49],
        [ 0, 23, 27, 50]], dtype=torch.int32)
action_seq  tensor([[7, 0, 1, 0, 4, 2, 5, 6, 1, 8],
        [0, 7, 4, 6, 1, 2, 4, 0, 8, 3],
        [0, 0, 7, 6, 2, 4, 8, 6, 8, 9],
        [1, 6, 3, 7, 2, 6, 1, 0, 9, 6],
        [7, 6, 3, 2, 0, 5, 6, 2, 0, 8]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1.],
        [ 1., -1.,  1., -1.,  1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1., -1., -1., -1., -1., -1., -1.,  1.],
        [-1., -1.,  1., -1.,  1., -1., -1., -1.,  1., -1.],
        [-1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[ 5.1776,  5.9559,  4.9751,  3.9514,  2.7605,  1.5566,  1.8888,  2.4755,
          0.9229,  1.5000],
        [-0.4347, -1.7326, -0.7720, -1.8523, -1.0822, -2.3242, -2.0321, -1.4845,
         -1.0576, -0.5000],
        [-0.5080, -1.8078, -2.8677, -1.9500, -1.1799, -0.4033, -0.0916,  0.4755,
          0.9229,  1.5000],
        [-0.5890,  0.1317,  1.1109,  0.0500,  0.8387, -0.3838, -0.0721,  0.4960,
          0.9424, -0.5000],
        [-4.3556, -3.6730, -2.7319, -3.8328, -3.0822, -2.3242, -2.0321, -1.4845,
         -1.0576, -0.5000]], device='cuda:0')
pred_boxes  tensor([[11.,  2., 39., 30.],
        [21., 11., 49., 39.],
        [ 0.,  6., 32., 39.],
        [18., 28., 46., 56.],
        [ 7., 31., 35., 60.]])
target_boxes  tensor([[11,  3, 38, 30],
        [32, 22, 59, 49],
        [22, 33, 49, 60],
        [35, 54, 62, 81],
        [54, 24, 81, 51]], dtype=torch.int32)
action_seq  tensor([[6, 0, 2, 8, 9, 1, 8, 8, 3, 1],
        [7, 6, 3, 7, 2, 8, 2, 7, 9, 9],
        [1, 8, 7, 7, 5, 2, 0, 5, 7, 0],
        [8, 6, 7, 5, 6, 8, 6, 7, 4, 2],
        [2, 0, 5, 0, 3, 7, 3, 8, 6, 8]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [-1., -1.,  1., -1., -1.,  1., -1.,  1., -1., -1.],
        [ 1., -1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.],
        [-1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.],
        [-1., -1., -1., -1., -1.,  1., -1.,  1., -1., -1.]])
adv  tensor([[-3.8212, -3.2169, -2.6984, -2.1741, -1.8291, -2.8577, -2.2439, -1.6238,
         -0.9055, -0.3636],
        [-0.0156,  0.6269,  1.1844, -0.2737,  0.0918,  1.1023, -0.2634,  0.3762,
         -0.9055, -0.3636],
        [ 3.7159,  2.3759,  2.9501,  3.5310,  3.9345,  4.9841,  3.6565,  2.3167,
          3.0749,  1.6364],
        [-3.8964, -3.2931, -2.7755, -2.2522, -1.9082, -0.9173, -0.2839,  0.3567,
          1.0945, -0.3636],
        [-1.9755, -1.3536, -0.8156, -0.2737,  0.0918,  1.1023, -0.2634,  0.3762,
         -0.9055, -0.3636]], device='cuda:0')
pred_boxes  tensor([[24.,  8., 52., 36.],
        [24., 39., 66., 83.],
        [24., 13., 57., 46.],
        [ 8., 21., 60., 74.],
        [13., 17., 41., 46.]])
target_boxes  tensor([[43, 56, 70, 83],
        [48, 13, 75, 40],
        [36, 15, 63, 42],
        [53, 18, 80, 45],
        [45,  0, 72, 27]], dtype=torch.int32)
action_seq  tensor([[4, 7, 1, 6, 3, 0, 3, 3, 4, 7],
        [8, 4, 7, 5, 2, 0, 2, 6, 5, 5],
        [2, 2, 9, 4, 8, 8, 5, 0, 4, 8],
        [0, 4, 5, 2, 0, 0, 1, 7, 1, 5],
        [0, 2, 0, 8, 4, 2, 0, 0, 6, 0]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [-1.,  1., -1., -1.,  1., -1.,  1.,  1., -1., -1.],
        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1.,  1., -1., -1., -1.,  1., -1., -1.],
        [-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[-2.5215, -1.8604, -2.8489, -2.0284, -1.3221, -2.7900, -2.2122, -1.5881,
         -0.8365, -0.3600],
        [ 1.2255,  1.9247,  0.9743,  1.8329,  2.5783,  1.1504,  1.7682,  0.4119,
         -0.8365, -0.3600],
        [-6.4229, -5.8008, -4.8089, -4.0089, -3.3221, -2.7900, -2.2122, -1.5881,
         -0.8365, -0.3600],
        [ 1.3622,  0.0419, -0.9261, -0.0880, -1.3817, -0.8300, -0.2318,  0.4119,
         -0.8365, -0.3600],
        [-4.4424, -3.8008, -4.8089, -4.0089, -3.3221, -2.7900, -2.2122, -1.5881,
         -0.8365, -0.3600]], device='cuda:0')
pred_boxes  tensor([[39., 23., 68., 51.],
        [10., 29., 42., 63.],
        [ 7., 12., 35., 41.],
        [11., 16., 39., 44.],
        [ 0., 12., 28., 41.]])
target_boxes  tensor([[55, 54, 82, 81],
        [10, 55, 37, 82],
        [56, 36, 83, 63],
        [20, 36, 47, 63],
        [ 8, 55, 35, 82]], dtype=torch.int32)


Train Epoch: 3 [0/50 (0%)]	Reward: -0.3320
action_seq  tensor([[4, 7, 8, 0, 6, 6, 7, 6, 7, 4],
        [8, 3, 3, 6, 2, 3, 7, 8, 2, 2],
        [8, 3, 9, 9, 8, 3, 6, 2, 4, 6],
        [5, 2, 3, 0, 6, 0, 0, 2, 6, 7],
        [5, 6, 1, 7, 3, 5, 8, 8, 2, 1]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1.,  1., -1., -1.,  1., -1., -1.],
        [-1., -1., -1.,  1.,  1., -1., -1., -1., -1., -1.],
        [-1.,  1., -1., -1., -1.,  1., -1., -1., -1., -1.],
        [-1.,  1.,  1.,  1., -1., -1., -1., -1., -1.,  1.],
        [-1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.]])
adv  tensor([[-0.5768, -1.9716, -1.1703, -0.3298,  0.4241, -0.8027, -0.0525,  0.5461,
         -1.0582, -0.4375],
        [-2.5006, -1.8945, -1.0921, -0.2507, -1.5164, -2.7626, -2.0330, -1.4539,
         -1.0582, -0.4375],
        [-2.4791, -1.8739, -3.0921, -2.2712, -1.5359, -0.7626, -2.0330, -1.4539,
         -1.0582, -0.4375],
        [ 1.3461,  1.9913,  0.8122, -0.3484, -1.6140, -0.8418, -0.0926,  0.5061,
          0.9222,  1.5625],
        [-4.5162, -3.9306, -3.1497, -2.3289, -1.5955, -0.8222, -0.0730,  0.5266,
          0.9418, -0.4375]], device='cuda:0')
pred_boxes  tensor([[15.,  5., 56., 46.],
        [33., 46., 61., 75.],
        [15., 29., 49., 64.],
        [ 5., 29., 33., 57.],
        [37., 10., 72., 44.]])
target_boxes  tensor([[ 6, 40, 33, 67],
        [ 4, 37, 31, 64],
        [51, 29, 78, 56],
        [29, 35, 56, 62],
        [ 6, 42, 33, 69]], dtype=torch.int32)


Test Epoch: 3 [0/982 (0%)]	Reward: -0.3375
action_seq  tensor([[3, 0, 4, 0, 3, 1, 7, 8, 9, 5],
        [5, 3, 2, 7, 3, 3, 0, 0, 8, 5],
        [7, 6, 4, 2, 6, 6, 4, 8, 3, 4],
        [2, 0, 7, 1, 8, 3, 2, 9, 5, 6],
        [7, 4, 3, 0, 7, 7, 6, 3, 2, 8]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1.,  1., -1., -1., -1.,  1., -1.],
        [-1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1.,  1.,  1., -1., -1.,  1., -1.,  1., -1.],
        [ 1.,  1., -1.,  1.,  1.,  1., -1., -1., -1.,  1.],
        [-1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1.]])
adv  tensor([[-0.4167, -1.6204, -0.7848, -0.0654,  0.7219, -0.7226, -0.1934,  0.3735,
          0.8502, -0.6562],
        [-2.2429, -1.4446, -2.6276, -3.9482, -3.1990, -2.6630, -2.1534, -1.6070,
         -1.1498, -0.6562],
        [ 1.4456,  2.2820,  3.1566,  1.8946,  0.6818,  1.2579,  1.8066,  0.3735,
          0.8502, -0.6562],
        [ 5.3879,  4.2419,  3.1176,  3.8750,  2.6838,  1.2579, -0.2129,  0.3530,
          0.8306,  1.3438],
        [ 5.2903,  6.1648,  5.0590,  3.8155,  2.6223,  3.2178,  3.7871,  2.3735,
          0.8502, -0.6562]], device='cuda:0')
pred_boxes  tensor([[31., 25., 59., 53.],
        [44., 41., 72., 69.],
        [15., 27., 43., 56.],
        [22., 26., 50., 54.],
        [36., 29., 64., 57.]])
target_boxes  tensor([[22, 52, 49, 79],
        [17, 55, 44, 82],
        [32, 31, 59, 58],
        [25, 15, 52, 42],
        [30, 44, 57, 71]], dtype=torch.int32)
action_seq  tensor([[1, 0, 6, 1, 2, 7, 0, 6, 4, 0],
        [8, 5, 2, 3, 8, 5, 2, 8, 1, 0],
        [9, 6, 9, 0, 9, 0, 2, 4, 1, 5],
        [3, 3, 7, 1, 9, 4, 0, 3, 7, 3],
        [7, 1, 2, 5, 8, 2, 1, 6, 2, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.],
        [-1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1.],
        [ 1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.],
        [-1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1.]])
adv  tensor([[-4.4876, -5.7009, -5.0008, -4.1044, -3.3882, -2.7280, -2.2505, -1.6104,
         -1.0270, -0.4375],
        [ 4.9265,  5.8293,  6.6456,  5.6398,  4.4331,  3.1529,  3.6899,  2.3700,
          0.9730, -0.4375],
        [ 2.9480,  3.8293,  4.6261,  5.6193,  4.4136,  5.1529,  3.6899,  2.3700,
          0.9730, -0.4375],
        [-2.6048, -3.7986, -3.0799, -2.1639, -1.4282, -0.7475, -0.2505, -1.6104,
         -1.0270, -0.4375],
        [ 3.0651,  3.9475,  2.7247,  1.6788,  2.4536,  3.1724,  1.6899,  2.3700,
          0.9730, -0.4375]], device='cuda:0')
pred_boxes  tensor([[15.,  8., 43., 36.],
        [21., 19., 49., 47.],
        [ 8., 27., 36., 55.],
        [48., 41., 76., 69.],
        [17., 18., 45., 46.]])
target_boxes  tensor([[33, 44, 60, 71],
        [17, 27, 44, 54],
        [12, 19, 39, 46],
        [18, 16, 45, 43],
        [ 9, 33, 36, 60]], dtype=torch.int32)
action_seq  tensor([[0, 4, 0, 8, 9, 2, 6, 3, 5, 8],
        [7, 4, 3, 7, 3, 7, 3, 7, 3, 1],
        [9, 9, 6, 6, 2, 6, 2, 7, 0, 9],
        [7, 0, 2, 5, 3, 6, 1, 3, 1, 2],
        [1, 0, 3, 8, 2, 4, 4, 3, 3, 8]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1., -1.],
        [-1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1.,  1., -1.,  1., -1.,  1., -1.],
        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[ 5.3756,  4.1984,  3.0730,  1.7466,  2.5222,  1.3161,  0.0675,  0.6674,
         -0.8410, -0.2812],
        [-2.3119, -1.5458, -2.7298, -4.1147, -3.3987, -2.6438, -1.9130, -1.3326,
         -0.8410, -0.2812],
        [-0.6029,  0.1808,  1.0339,  1.7085,  2.4822,  1.2771,  2.0470,  0.6478,
          1.1590, -0.2812],
        [-6.2523, -5.5262, -4.7298, -4.1147, -3.3987, -2.6438, -1.9130, -1.3326,
         -0.8410, -0.2812],
        [-2.2924, -3.5458, -2.7298, -4.1147, -3.3987, -2.6438, -1.9130, -1.3326,
         -0.8410, -0.2812]], device='cuda:0')
pred_boxes  tensor([[ 4., 15., 33., 44.],
        [55., 46., 83., 74.],
        [10., 37., 51., 80.],
        [15., 29., 43., 57.],
        [29.,  6., 57., 34.]])
target_boxes  tensor([[17, 28, 44, 55],
        [20, 15, 47, 42],
        [ 2, 45, 29, 72],
        [49, 11, 76, 38],
        [55, 36, 82, 63]], dtype=torch.int32)
action_seq  tensor([[1, 2, 0, 3, 2, 6, 2, 2, 4, 5],
        [2, 7, 7, 2, 3, 0, 3, 3, 3, 5],
        [0, 8, 8, 8, 3, 2, 2, 7, 2, 0],
        [6, 8, 5, 4, 3, 4, 3, 8, 3, 8],
        [1, 4, 1, 8, 2, 4, 8, 3, 3, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1., -1.,  1.,  1., -1., -1., -1., -1.],
        [ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1.,  1.,  1., -1.,  1., -1., -1.],
        [-1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[ 0.4438,  1.2365,  0.1127,  0.8090,  1.4171, -0.0842, -1.6633, -1.1435,
         -0.8079, -0.4688],
        [-3.3599, -4.6249, -3.7877, -3.1314, -2.5634, -2.0842, -1.6633, -1.1435,
         -0.8079, -0.4688],
        [ 0.3276,  1.1193,  2.0151,  2.7299,  3.3575,  1.8758,  0.3172,  0.8565,
         -0.8079, -0.4688],
        [-3.4194, -2.6649, -1.8072, -1.1314, -2.5634, -2.0842, -1.6633, -1.1435,
         -0.8079, -0.4688],
        [ 0.5806, -0.6444, -1.7877, -3.1314, -2.5634, -2.0842, -1.6633, -1.1435,
         -0.8079, -0.4688]], device='cuda:0')
pred_boxes  tensor([[18., 27., 46., 55.],
        [32., 44., 60., 74.],
        [19., 36., 47., 66.],
        [40., 27., 68., 55.],
        [35.,  5., 63., 33.]])
target_boxes  tensor([[ 6, 38, 33, 65],
        [29, 11, 56, 38],
        [32, 53, 59, 80],
        [10, 43, 37, 70],
        [49, 26, 76, 53]], dtype=torch.int32)
action_seq  tensor([[5, 3, 6, 2, 0, 5, 8, 2, 4, 4],
        [0, 2, 2, 8, 3, 5, 0, 8, 7, 2],
        [7, 1, 8, 9, 6, 7, 7, 0, 9, 7],
        [0, 6, 2, 3, 1, 1, 6, 6, 0, 5],
        [3, 1, 4, 3, 8, 0, 5, 7, 2, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1.,  1., -1., -1., -1.,  1.,  1., -1.],
        [-1.,  1., -1., -1., -1., -1., -1.,  1., -1., -1.],
        [ 1., -1., -1., -1.,  1.,  1., -1., -1., -1., -1.],
        [ 1.,  1.,  1.,  1., -1., -1., -1.,  1., -1., -1.]])
adv  tensor([[-4.3093, -3.5010, -4.9252, -4.3436, -3.6299, -3.0983, -2.3721, -1.7648,
         -1.1198, -0.5312],
        [ 3.3411,  2.2061,  0.8404,  1.4797,  0.2314,  0.8021,  1.5683,  2.2157,
          0.8802, -0.5312],
        [-2.4451, -1.6181, -3.0229, -2.4227, -1.6895, -1.1384, -0.3917,  0.2352,
         -1.1198, -0.5312],
        [-0.4666, -1.6396, -1.0248, -0.4031,  0.3505, -1.0983, -2.3721, -1.7648,
         -1.1198, -0.5312],
        [ 3.4553,  2.3223,  0.9576, -0.4227, -1.6895, -1.1384, -0.3917,  0.2352,
         -1.1198, -0.5312]], device='cuda:0')
pred_boxes  tensor([[ 4., 30., 32., 60.],
        [13., 16., 41., 45.],
        [26., 23., 79., 75.],
        [12., 23., 40., 51.],
        [47., 22., 75., 50.]])
target_boxes  tensor([[56, 12, 83, 39],
        [24,  7, 51, 34],
        [37, 16, 64, 43],
        [42,  6, 69, 33],
        [47, 43, 74, 70]], dtype=torch.int32)
action_seq  tensor([[4, 0, 4, 5, 0, 3, 9, 9, 7, 8],
        [8, 4, 8, 6, 8, 4, 3, 2, 2, 8],
        [3, 0, 4, 7, 7, 4, 7, 9, 0, 0],
        [7, 7, 4, 3, 7, 4, 2, 7, 2, 3],
        [9, 9, 9, 0, 4, 3, 7, 6, 8, 6]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1.],
        [-1.,  1., -1., -1., -1., -1.,  1.,  1.,  1., -1.],
        [ 1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.],
        [-1., -1., -1.,  1.,  1., -1.,  1., -1.,  1., -1.]])
adv  tensor([[-1.0002, -1.9886, -1.1565, -0.6005,  0.0880,  0.8155,  1.2974,  0.1105,
         -1.1195, -0.5625],
        [ 0.8259,  1.8756,  0.7263,  1.3018,  2.0089,  2.7559,  3.2573,  2.0910,
          0.8805, -0.5625],
        [-2.7668, -3.7738, -4.9798, -4.4618, -3.8124, -3.1249, -2.6831, -1.8895,
         -1.1195, -0.5625],
        [ 2.7839,  3.8542,  4.7448,  3.3409,  2.0489,  2.7960,  1.2769,  0.0910,
          0.8805, -0.5625],
        [ 0.8425,  1.8932,  2.7644,  3.3614,  2.0684,  0.7960,  1.2769,  0.0910,
          0.8805, -0.5625]], device='cuda:0')
pred_boxes  tensor([[22., 21., 50., 49.],
        [16., 24., 44., 53.],
        [47., 31., 75., 59.],
        [41., 39., 69., 68.],
        [ 6.,  7., 49., 50.]])
target_boxes  tensor([[10, 46, 37, 73],
        [ 9, 54, 36, 81],
        [ 8, 39, 35, 66],
        [38, 51, 65, 78],
        [40,  8, 67, 35]], dtype=torch.int32)
action_seq  tensor([[3, 3, 0, 9, 6, 9, 6, 1, 1, 3],
        [5, 6, 4, 3, 2, 5, 6, 1, 4, 3],
        [1, 1, 4, 8, 9, 0, 8, 8, 8, 8],
        [1, 1, 7, 8, 7, 4, 0, 9, 2, 0],
        [8, 9, 7, 8, 5, 8, 8, 8, 6, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1.,  1.,  1., -1., -1., -1.,  1., -1., -1.],
        [-1., -1.,  1.,  1.,  1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1., -1., -1.,  1.,  1., -1., -1., -1.],
        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[ 2.8765,  1.9270,  0.7792, -0.3820, -1.4589, -0.4951,  0.1319,  0.6061,
         -0.9029, -0.3438],
        [-1.0473, -0.0154,  0.8368, -0.3225, -1.3993, -2.4551, -1.8486, -1.3939,
         -0.9029, -0.3438],
        [-0.9672, -1.9559, -3.1436, -2.3225, -1.3993, -2.4551, -1.8486, -1.3939,
         -0.9029, -0.3438],
        [ 0.8970, -0.0730, -1.2423, -0.4025,  0.5411,  1.5254,  0.1514, -1.3939,
         -0.9029, -0.3438],
        [-6.8686, -5.8963, -5.1036, -4.3029, -3.3993, -2.4551, -1.8486, -1.3939,
         -0.9029, -0.3438]], device='cuda:0')
pred_boxes  tensor([[25., 40., 54., 68.],
        [23., 34., 51., 62.],
        [34.,  0., 68., 32.],
        [34., 15., 63., 43.],
        [16., 16., 83., 83.]])
target_boxes  tensor([[30, 52, 57, 79],
        [33, 50, 60, 77],
        [23, 26, 50, 53],
        [31, 10, 58, 37],
        [ 6, 51, 33, 78]], dtype=torch.int32)
action_seq  tensor([[0, 1, 0, 2, 4, 8, 2, 4, 7, 2],
        [2, 0, 1, 0, 1, 7, 0, 7, 0, 0],
        [8, 4, 6, 1, 4, 4, 2, 8, 5, 6],
        [2, 3, 2, 8, 3, 3, 2, 3, 6, 9],
        [3, 3, 3, 7, 8, 6, 1, 7, 3, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1., -1.],
        [-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1.,  1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1.,  1., -1., -1., -1., -1.,  1.,  1., -1.]])
adv  tensor([[-4.4548, -5.4151, -4.4281, -3.6838, -3.1211, -2.2688, -1.8815, -1.4586,
         -0.7788, -0.2500],
        [ 5.1732,  4.3095,  3.3746,  2.1776,  2.7998,  1.6912,  0.0990,  0.5414,
         -0.7788, -0.2500],
        [-4.4743, -3.4151, -4.4281, -3.6838, -3.1211, -2.2688, -1.8815, -1.4586,
         -0.7788, -0.2500],
        [-0.5339, -1.4552, -2.4476, -1.6838, -3.1211, -2.2688, -1.8815, -1.4586,
         -0.7788, -0.2500],
        [ 3.1956,  2.3124,  1.3570,  0.1395,  0.7402,  1.6316,  2.0590,  2.5219,
          1.2212, -0.2500]], device='cuda:0')
pred_boxes  tensor([[20.,  4., 48., 32.],
        [25., 16., 53., 44.],
        [16., 15., 44., 43.],
        [21., 50., 49., 80.],
        [52., 37., 81., 65.]])
target_boxes  tensor([[14, 44, 41, 71],
        [29, 21, 56, 48],
        [41, 43, 68, 70],
        [40, 22, 67, 49],
        [53, 49, 80, 76]], dtype=torch.int32)
action_seq  tensor([[7, 7, 6, 8, 0, 7, 8, 7, 3, 2],
        [3, 1, 1, 7, 2, 8, 4, 2, 7, 2],
        [6, 0, 7, 6, 7, 6, 9, 9, 7, 5],
        [3, 6, 0, 3, 3, 3, 8, 8, 5, 9],
        [7, 8, 7, 4, 1, 2, 7, 7, 0, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1., -1., -1., -1., -1., -1.,  1., -1.],
        [-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1., -1., -1.,  1., -1., -1.,  1.,  1., -1., -1.],
        [-1., -1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1.]])
adv  tensor([[-5.8696, -5.0451, -4.3069, -3.5928, -2.8399, -2.3320, -1.8505, -1.2379,
         -0.8401, -0.3750],
        [-0.0435, -1.1809, -2.4241, -1.6904, -0.9190, -0.3915,  0.1095,  0.7426,
          1.1599, -0.3750],
        [-3.8892, -3.0451, -4.3069, -3.5928, -2.8399, -2.3320, -1.8505, -1.2379,
         -0.8401, -0.3750],
        [ 1.8179,  0.7000,  1.4968,  2.2686,  1.0605,  1.6085,  2.1300,  0.7621,
         -0.8401, -0.3750],
        [ 3.5669,  4.4861,  5.3211,  6.1328,  4.9638,  3.5294,  2.0499,  2.7025,
          3.1404,  1.6250]], device='cuda:0')
pred_boxes  tensor([[30., 23., 72., 66.],
        [47., 20., 75., 48.],
        [13., 17., 79., 83.],
        [27., 34., 55., 62.],
        [37., 23., 65., 51.]])
target_boxes  tensor([[ 2, 56, 29, 83],
        [54, 40, 81, 67],
        [32, 17, 59, 44],
        [42, 27, 69, 54],
        [28, 29, 55, 56]], dtype=torch.int32)
action_seq  tensor([[6, 2, 4, 9, 6, 3, 0, 9, 8, 4],
        [6, 8, 1, 1, 1, 6, 7, 1, 4, 7],
        [9, 9, 2, 3, 6, 3, 8, 4, 0, 6],
        [3, 8, 6, 2, 7, 3, 4, 1, 3, 5],
        [7, 0, 4, 2, 8, 6, 7, 7, 3, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.],
        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.],
        [ 1., -1., -1., -1.,  1.,  1., -1., -1., -1., -1.],
        [-1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1.]])
adv  tensor([[ 5.3983e+00,  6.1159e+00,  4.8822e+00,  3.7007e+00,  4.4014e+00,
          5.0770e+00,  3.8968e+00,  2.5163e+00,  3.0469e+00,  1.5938e+00],
        [-6.0001e+00, -5.3978e+00, -4.7262e+00, -3.9848e+00, -3.3622e+00,
         -2.7648e+00, -2.0036e+00, -1.4242e+00, -9.3353e-01, -4.0625e-01],
        [-4.1173e+00, -3.4954e+00, -2.8053e+00, -2.0444e+00, -1.4023e+00,
         -7.8433e-01, -3.6316e-03, -1.4242e+00, -9.3353e-01, -4.0625e-01],
        [-1.7686e-01, -1.5365e+00, -8.2582e-01, -4.4373e-02,  6.1823e-01,
         -7.6480e-01, -2.0036e+00, -1.4242e+00, -9.3353e-01, -4.0625e-01],
        [ 5.4364e+00,  6.1550e+00,  4.9222e+00,  3.7408e+00,  2.4210e+00,
          3.0770e+00,  3.8968e+00,  2.5163e+00,  3.0469e+00,  1.5938e+00]],
       device='cuda:0')
pred_boxes  tensor([[13., 42., 41., 70.],
        [52.,  2., 83., 30.],
        [10., 34., 38., 62.],
        [32., 29., 60., 57.],
        [24., 21., 52., 50.]])
target_boxes  tensor([[15, 38, 42, 65],
        [37, 55, 64, 82],
        [40,  5, 67, 32],
        [53, 54, 80, 81],
        [21, 16, 48, 43]], dtype=torch.int32)
Test Epoch: 3 [640/982 (62%)]	Reward: -0.3489
action_seq  tensor([[2, 4, 6, 6, 2, 0, 1, 6, 8, 0],
        [1, 8, 0, 8, 9, 3, 3, 6, 3, 9],
        [0, 7, 6, 4, 4, 7, 3, 0, 9, 7],
        [7, 0, 6, 5, 5, 3, 7, 8, 5, 6],
        [8, 0, 2, 7, 5, 4, 5, 3, 8, 4]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1., -1.],
        [ 1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [-1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.],
        [-1.,  1., -1., -1., -1., -1., -1.,  1., -1.,  1.],
        [-1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1., -1.]])
adv  tensor([[ 5.3410,  4.3218,  3.0700,  1.9338,  2.7738,  3.3389,  2.1095,  0.7110,
          1.2227, -0.4062],
        [-2.2703, -3.3657, -2.6741, -3.8690, -3.0875, -2.5820, -1.8505, -1.2695,
         -0.7773, -0.4062],
        [ 3.2082,  4.1870,  2.9342,  3.8166,  4.6762,  5.2598,  4.0499,  2.6710,
          3.2032,  1.5938],
        [-0.5584,  0.3823, -0.9075, -0.0653,  0.7553,  1.2989,  2.0704,  2.6905,
          1.2032,  1.5938],
        [ 3.4172,  4.3980,  3.1491,  2.0119,  0.8334,  1.3780,  0.1300,  0.7305,
         -0.7773, -0.4062]], device='cuda:0')
pred_boxes  tensor([[ 0., 26., 28., 54.],
        [33., 39., 62., 67.],
        [32., 24., 60., 52.],
        [12.,  2., 65., 55.],
        [25., 21., 53., 50.]])
target_boxes  tensor([[ 5, 19, 32, 46],
        [39,  4, 66, 31],
        [50, 39, 77, 66],
        [ 1,  8, 28, 35],
        [28, 42, 55, 69]], dtype=torch.int32)
action_seq  tensor([[1, 8, 6, 8, 6, 7, 1, 1, 2, 6],
        [3, 3, 2, 1, 2, 9, 8, 1, 5, 1],
        [2, 0, 7, 5, 0, 3, 2, 2, 9, 0],
        [8, 0, 7, 8, 7, 8, 0, 8, 5, 5],
        [8, 4, 6, 4, 3, 3, 6, 7, 4, 6]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1.,  1., -1., -1., -1., -1., -1., -1.,  1.],
        [ 1.,  1.,  1., -1.,  1., -1.,  1., -1., -1., -1.],
        [ 1.,  1., -1., -1., -1.,  1.,  1., -1.,  1., -1.],
        [-1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [-1.,  1., -1.,  1., -1., -1., -1.,  1., -1., -1.]])
adv  tensor([[-2.3882, -1.5591, -0.6915, -1.9298, -1.1282, -0.5088,  0.3068,  0.8149,
          1.2026,  1.6562],
        [ 3.5689,  2.4380,  1.3251,  0.1082,  0.9294, -0.4493,  0.3664, -1.1451,
         -0.7779, -0.3438],
        [ 3.4361,  2.3022,  1.1883,  1.9901,  2.8308,  3.4912,  2.3264,  0.8354,
          1.2221, -0.3438],
        [-4.2153, -3.4048, -2.5558, -3.8127, -3.0305, -2.4297, -1.6336, -1.1451,
         -0.7779, -0.3438],
        [-0.3901,  0.4575, -0.6730,  0.1082, -1.0901, -0.4698,  0.3469,  0.8549,
         -0.7779, -0.3438]], device='cuda:0')
pred_boxes  tensor([[29.,  8., 64., 41.],
        [37., 45., 65., 73.],
        [18., 34., 46., 63.],
        [17.,  0., 69., 52.],
        [21., 35., 49., 63.]])
target_boxes  tensor([[ 5, 24, 32, 51],
        [28, 47, 55, 74],
        [18, 42, 45, 69],
        [51, 19, 78, 46],
        [33, 11, 60, 38]], dtype=torch.int32)
action_seq  tensor([[9, 3, 7, 8, 2, 1, 1, 8, 9, 8],
        [7, 1, 8, 2, 3, 2, 3, 0, 0, 2],
        [0, 9, 4, 6, 3, 8, 2, 6, 2, 0],
        [6, 4, 1, 2, 2, 1, 0, 6, 8, 8],
        [8, 8, 7, 8, 0, 7, 8, 6, 4, 4]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1., -1.,  1., -1., -1., -1.,  1., -1.],
        [-1.,  1., -1.,  1.,  1.,  1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.],
        [-1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.],
        [-1., -1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.]])
adv  tensor([[-0.1483,  0.5442, -0.5870,  0.2290,  1.0510, -0.3272,  0.0482,  0.6491,
          1.0971, -0.3438],
        [ 1.8488,  2.5608,  1.4511,  2.2866,  1.1106, -0.2676, -1.9117, -1.3314,
         -0.9029, -0.3438],
        [-3.9930, -3.3396, -2.4893, -1.6938, -0.8894, -0.2676, -1.9117, -1.3314,
         -0.9029, -0.3438],
        [ 5.6163,  6.3674,  5.2958,  4.1499,  2.9914,  1.6328,  2.0287,  2.6491,
          1.0971, -0.3438],
        [ 1.5626,  2.2727,  3.1796,  4.0327,  4.8938,  3.5537,  3.9691,  4.6091,
          3.0776,  1.6562]], device='cuda:0')
pred_boxes  tensor([[34.,  7., 69., 41.],
        [32., 37., 60., 66.],
        [ 3., 34., 31., 63.],
        [20., 14., 48., 42.],
        [11., 11., 53., 53.]])
target_boxes  tensor([[34, 46, 61, 73],
        [28, 30, 55, 57],
        [53,  3, 80, 30],
        [15, 22, 42, 49],
        [ 0, 23, 27, 50]], dtype=torch.int32)
action_seq  tensor([[7, 6, 8, 4, 7, 4, 0, 6, 0, 7],
        [3, 4, 6, 6, 8, 6, 6, 9, 7, 2],
        [7, 5, 2, 9, 0, 2, 8, 7, 8, 5],
        [2, 2, 1, 7, 8, 9, 3, 0, 8, 3],
        [2, 8, 3, 7, 5, 9, 0, 8, 3, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1.,  1., -1., -1.,  1.,  1.,  1., -1.],
        [ 1.,  1., -1., -1., -1., -1., -1., -1.,  1., -1.],
        [-1., -1.,  1., -1.,  1., -1., -1.,  1., -1., -1.],
        [ 1., -1., -1.,  1., -1.,  1.,  1., -1., -1., -1.],
        [-1., -1.,  1.,  1., -1., -1., -1.,  1.,  1., -1.]])
adv  tensor([[ 1.6647,  2.3761,  3.2526,  4.0742,  2.9469,  3.5140,  4.0862,  2.7388,
          1.3771, -0.2188],
        [-0.0423, -1.3690, -2.5511, -1.7871, -0.9535, -0.4265,  0.1057,  0.7388,
          1.3771, -0.2188],
        [-0.1234,  0.5704,  1.4284,  0.2119,  1.0660, -0.4069,  0.1262,  0.7583,
         -0.6229, -0.2188],
        [ 1.8571,  0.5499,  1.4079,  2.2110,  1.0660,  1.6136,  0.1458, -1.2417,
         -0.6229, -0.2188],
        [ 1.7419,  2.4542,  3.3317,  2.1338,  0.9869,  1.5335,  2.0862,  2.7388,
          1.3771, -0.2188]], device='cuda:0')
pred_boxes  tensor([[20., 14., 53., 47.],
        [10., 31., 53., 75.],
        [ 8.,  8., 49., 51.],
        [26., 30., 54., 58.],
        [37., 30., 65., 59.]])
target_boxes  tensor([[11,  3, 38, 30],
        [32, 22, 59, 49],
        [22, 33, 49, 60],
        [35, 54, 62, 81],
        [54, 24, 81, 51]], dtype=torch.int32)
action_seq  tensor([[6, 2, 5, 1, 4, 6, 1, 7, 7, 3],
        [5, 3, 3, 6, 3, 5, 0, 9, 1, 2],
        [6, 3, 3, 9, 9, 7, 7, 2, 6, 2],
        [4, 3, 5, 0, 5, 3, 6, 0, 6, 7],
        [8, 4, 8, 2, 1, 7, 4, 3, 9, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1.,  1.,  1., -1.,  1.,  1., -1., -1., -1., -1.]])
adv  tensor([[-3.3539, -2.8372, -3.8760, -3.4559, -2.7563, -2.2331, -1.7966, -1.0800,
         -0.6319, -0.4545],
        [-3.3539, -2.8372, -3.8760, -3.4559, -2.7563, -2.2331, -1.7966, -1.0800,
         -0.6319, -0.4545],
        [-3.3539, -2.8372, -3.8760, -3.4559, -2.7563, -2.2331, -1.7966, -1.0800,
         -0.6319, -0.4545],
        [-1.3539, -2.8372, -3.8760, -3.4559, -2.7563, -2.2331, -1.7966, -1.0800,
         -0.6319, -0.4545],
        [ 2.4293,  3.0046,  2.0244,  0.4846,  1.2242, -0.2331, -1.7966, -1.0800,
         -0.6319, -0.4545]], device='cuda:0')
pred_boxes  tensor([[34., 26., 63., 54.],
        [35., 46., 63., 74.],
        [20., 47., 54., 83.],
        [21., 29., 49., 57.],
        [35., 27., 63., 55.]])
target_boxes  tensor([[43, 56, 70, 83],
        [48, 13, 75, 40],
        [36, 15, 63, 42],
        [53, 18, 80, 45],
        [45,  0, 72, 27]], dtype=torch.int32)
action_seq  tensor([[1, 4, 2, 2, 8, 3, 1, 7, 6, 9],
        [5, 7, 3, 8, 2, 2, 5, 2, 0, 1],
        [4, 0, 0, 7, 7, 7, 3, 2, 9, 2],
        [7, 8, 1, 7, 1, 5, 2, 1, 8, 0],
        [7, 5, 3, 7, 8, 7, 4, 0, 3, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1., -1.],
        [-1., -1.,  1., -1.,  1.,  1., -1.,  1., -1., -1.],
        [ 1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1.],
        [-1., -1.,  1., -1., -1., -1.,  1., -1., -1., -1.],
        [-1., -1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.]])
adv  tensor([[ 5.1321,  3.8507,  2.5564,  1.4516,  0.0106, -1.2417, -0.5675,  0.2355,
          0.9243, -0.4400],
        [ 1.1321,  1.8302,  2.5359,  1.4301,  2.0106,  0.7779, -0.5470,  0.2551,
         -1.0757, -0.4400],
        [ 4.9768,  3.6935,  4.4177,  5.3520,  3.9510,  2.7388,  1.4325,  0.2355,
          0.9243, -0.4400],
        [-2.6726, -2.0116, -1.3460, -2.4908, -1.9503, -1.2016, -0.5274, -1.7449,
         -1.0757, -0.4400],
        [ 1.0188,  1.7170,  2.4206,  1.3129,  1.8924,  2.6792,  3.3935,  2.2150,
          0.9048,  1.5600]], device='cuda:0')
pred_boxes  tensor([[27., 28., 55., 57.],
        [16., 33., 44., 63.],
        [40., 26., 68., 54.],
        [37.,  3., 66., 31.],
        [30., 23., 58., 51.]])
target_boxes  tensor([[24, 21, 51, 48],
        [10, 55, 37, 82],
        [54, 28, 81, 55],
        [21, 33, 48, 60],
        [12, 25, 39, 52]], dtype=torch.int32)


Train Epoch: 4 [0/50 (0%)]	Reward: -0.3200
action_seq  tensor([[0, 3, 8, 8, 6, 3, 7, 7, 3, 7],
        [2, 7, 2, 1, 7, 3, 8, 8, 6, 7],
        [4, 7, 2, 8, 7, 9, 9, 7, 9, 3],
        [3, 0, 7, 5, 1, 1, 2, 5, 2, 4],
        [7, 3, 2, 2, 0, 4, 9, 8, 5, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1., -1., -1.,  1.,  1., -1., -1., -1., -1.],
        [ 1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1., -1., -1., -1.,  1., -1., -1., -1.],
        [-1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.]])
adv  tensor([[ 1.3626,  0.3969, -0.7669, -0.1112,  0.5507, -0.5489, -1.8486, -1.2676,
         -0.8386, -0.5312],
        [-2.4812, -3.4840, -2.6673, -4.0516, -3.4298, -2.5489, -1.8486, -1.2676,
         -0.8386, -0.5312],
        [-0.5398, -1.5240, -2.7074, -2.0712, -1.4298, -2.5489, -1.8486, -1.2676,
         -0.8386, -0.5312],
        [-0.5779, -1.5621, -2.7464, -2.1112, -1.4698, -0.5684,  0.1514, -1.2676,
         -0.8386, -0.5312],
        [ 3.1468,  4.2201,  5.1159,  3.8097,  2.4911,  1.4111,  0.1318,  0.7324,
         -0.8386, -0.5312]], device='cuda:0')
pred_boxes  tensor([[43., 18., 78., 53.],
        [38., 23., 72., 58.],
        [41., 40., 83., 83.],
        [44., 21., 73., 49.],
        [18., 41., 46., 71.]])
target_boxes  tensor([[ 6, 40, 33, 67],
        [ 4, 37, 31, 64],
        [51, 29, 78, 56],
        [29, 35, 56, 62],
        [ 6, 42, 33, 69]], dtype=torch.int32)


Test Epoch: 4 [0/982 (0%)]	Reward: -0.3313
action_seq  tensor([[7, 2, 3, 9, 6, 0, 0, 9, 7, 6],
        [8, 2, 8, 2, 2, 8, 3, 4, 5, 0],
        [3, 8, 3, 2, 0, 3, 9, 7, 3, 2],
        [2, 2, 0, 7, 1, 5, 2, 1, 3, 1],
        [2, 2, 2, 0, 3, 8, 2, 2, 0, 0]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1.,  1., -1., -1., -1., -1.,  1.,  1., -1.],
        [-1.,  1., -1.,  1.,  1., -1.,  1., -1., -1., -1.],
        [ 1., -1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.],
        [ 1., -1., -1.,  1.,  1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1.]])
adv  tensor([[ 1.5487,  2.3217,  1.1455,  0.0522,  0.8098,  1.3862,  1.9059,  2.5566,
          1.0668, -0.4375],
        [ 1.6229,  2.3969,  1.2217,  2.1498,  0.9084, -0.5337, -0.0346, -1.4239,
         -0.9332, -0.4375],
        [ 3.6219,  2.3959,  3.2412,  2.1694,  0.9289, -0.5142, -2.0346, -1.4239,
         -0.9332, -0.4375],
        [-0.2404, -1.5055, -0.6992,  0.2094, -1.0516, -2.5142, -2.0346, -1.4239,
         -0.9332, -0.4375],
        [-0.2004, -1.4654, -2.6797, -1.7906, -1.0516, -2.5142, -2.0346, -1.4239,
         -0.9332, -0.4375]], device='cuda:0')
pred_boxes  tensor([[ 1., 35., 34., 69.],
        [10., 26., 38., 57.],
        [40., 36., 68., 65.],
        [16., 34., 44., 63.],
        [ 4., 36., 32., 67.]])
target_boxes  tensor([[22, 52, 49, 79],
        [17, 55, 44, 82],
        [32, 31, 59, 58],
        [25, 15, 52, 42],
        [30, 44, 57, 71]], dtype=torch.int32)
action_seq  tensor([[1, 7, 7, 1, 3, 2, 1, 7, 7, 8],
        [3, 0, 2, 2, 3, 7, 7, 7, 3, 8],
        [9, 0, 7, 3, 0, 0, 6, 9, 0, 8],
        [8, 7, 1, 6, 9, 6, 0, 3, 8, 2],
        [0, 4, 7, 1, 0, 6, 2, 7, 3, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1.,  1.,  1., -1., -1., -1., -1.],
        [ 1.,  1.,  1., -1., -1., -1., -1., -1., -1.,  1.],
        [-1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1., -1.],
        [-1., -1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.],
        [ 1.,  1., -1., -1., -1.,  1.,  1., -1., -1., -1.]])
adv  tensor([[-0.4667, -1.7976, -1.1212, -0.3428,  0.2537, -1.0698, -2.2487, -1.7348,
         -1.1210, -0.4062],
        [ 1.4776,  0.1672, -1.1573, -2.4004, -1.8244, -1.1489, -0.3082,  0.2251,
          0.8594,  1.5938],
        [ 3.2423,  3.9690,  2.6825,  3.5000,  4.1346,  2.8511,  1.7113,  0.2456,
          0.8790, -0.4062],
        [ 3.0899,  3.8166,  4.5487,  3.3633,  3.9969,  4.7319,  5.6322,  4.2056,
          2.8594,  1.5938],
        [ 1.4757,  0.1643, -1.1603, -0.3828,  0.2137,  0.9106, -0.2487, -1.7348,
         -1.1210, -0.4062]], device='cuda:0')
pred_boxes  tensor([[54., 12., 83., 40.],
        [36., 33., 64., 63.],
        [19., 13., 47., 41.],
        [10., 22., 44., 56.],
        [24., 11., 52., 39.]])
target_boxes  tensor([[33, 44, 60, 71],
        [17, 27, 44, 54],
        [12, 19, 39, 46],
        [18, 16, 45, 43],
        [ 9, 33, 36, 60]], dtype=torch.int32)
action_seq  tensor([[0, 7, 3, 9, 8, 0, 0, 3, 2, 9],
        [3, 8, 7, 1, 3, 8, 5, 3, 3, 6],
        [6, 8, 8, 7, 3, 3, 2, 8, 6, 8],
        [2, 5, 3, 6, 7, 9, 3, 2, 2, 0],
        [2, 3, 8, 3, 7, 7, 3, 5, 6, 6]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1., -1.,  1., -1., -1., -1.,  1.],
        [ 1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1., -1.,  1., -1.,  1., -1.],
        [-1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [-1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.]])
adv  tensor([[-0.3475, -1.6142, -0.8097, -0.0606,  0.7923,  1.5567,  0.1521,  0.7533,
          1.1719,  1.5938],
        [-2.0965, -3.3808, -4.6144, -3.9034, -3.0906, -2.3642, -1.7883, -1.2066,
         -0.8085, -0.4062],
        [-2.3484, -1.6142, -0.8107, -0.0606,  0.7903,  1.5567,  2.1717,  0.7738,
          1.1915, -0.4062],
        [-4.1561, -3.4403, -2.6544, -1.9229, -1.0906, -2.3642, -1.7883, -1.2066,
         -0.8085, -0.4062],
        [ 3.5500,  4.3429,  3.1874,  3.9775,  2.8499,  1.6163,  0.2117, -1.2066,
         -0.8085, -0.4062]], device='cuda:0')
pred_boxes  tensor([[31., 22., 59., 50.],
        [48., 18., 77., 46.],
        [20., 21., 63., 65.],
        [22., 53., 50., 83.],
        [33., 36., 68., 72.]])
target_boxes  tensor([[17, 28, 44, 55],
        [20, 15, 47, 42],
        [ 2, 45, 29, 72],
        [49, 11, 76, 38],
        [55, 36, 82, 63]], dtype=torch.int32)
action_seq  tensor([[9, 0, 8, 4, 3, 7, 0, 3, 7, 3],
        [9, 1, 3, 0, 4, 8, 2, 4, 1, 0],
        [9, 4, 2, 8, 0, 8, 3, 0, 8, 6],
        [8, 2, 9, 3, 9, 7, 4, 4, 3, 7],
        [4, 0, 9, 7, 0, 5, 8, 3, 5, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1.,  1., -1., -1., -1., -1., -1., -1.],
        [-1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1., -1.],
        [-1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [-1.,  1., -1.,  1., -1., -1., -1., -1., -1., -1.],
        [ 1., -1., -1.,  1., -1., -1., -1.,  1., -1., -1.]])
adv  tensor([[-2.0396, -1.4610, -2.8007, -2.1350, -3.3877, -2.7274, -2.1868, -1.5776,
         -1.0886, -0.5312],
        [ 3.7055,  4.3427,  3.0606,  1.7654,  0.5528,  1.2531, -0.1868, -1.5776,
         -1.0886, -0.5312],
        [-2.0201, -1.4405, -2.7812, -4.1350, -3.3877, -2.7274, -2.1868, -1.5776,
         -1.0886, -0.5312],
        [-2.0396, -1.4610, -2.8007, -2.1350, -3.3877, -2.7274, -2.1868, -1.5776,
         -1.0886, -0.5312],
        [-0.1558, -1.5782, -0.8984, -0.2141, -1.4472, -0.7674, -0.2063,  0.4224,
         -1.0886, -0.5312]], device='cuda:0')
pred_boxes  tensor([[35., 22., 63., 50.],
        [33., 15., 61., 43.],
        [10.,  3., 38., 31.],
        [42., 43., 70., 72.],
        [26., 22., 54., 50.]])
target_boxes  tensor([[ 6, 38, 33, 65],
        [29, 11, 56, 38],
        [32, 53, 59, 80],
        [10, 43, 37, 70],
        [49, 26, 76, 53]], dtype=torch.int32)
action_seq  tensor([[4, 4, 8, 3, 2, 8, 8, 3, 7, 8],
        [5, 7, 3, 7, 2, 3, 4, 9, 2, 2],
        [4, 7, 3, 3, 2, 9, 7, 5, 9, 5],
        [9, 7, 2, 9, 1, 8, 4, 3, 0, 5],
        [4, 7, 3, 3, 7, 3, 1, 3, 2, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.],
        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1.,  1.,  1., -1., -1., -1., -1.],
        [ 1., -1.,  1.,  1., -1.,  1., -1., -1., -1., -1.]])
adv  tensor([[ 7.1186,  6.1490,  6.9686,  5.6497,  4.4126,  5.0889,  3.7830,  2.4010,
          1.0358, -0.4688],
        [-6.2769, -5.3617, -4.6583, -4.0740, -3.3892, -2.7920, -2.1574, -1.5795,
         -0.9642, -0.4688],
        [-2.3170, -3.3813, -2.6583, -4.0740, -3.3892, -2.7920, -2.1574, -1.5795,
         -0.9642, -0.4688],
        [-2.4537, -1.5004, -0.7579, -0.1335,  0.5913, -0.7920, -2.1574, -1.5795,
         -0.9642, -0.4688],
        [ 1.5258,  0.4996,  1.2626, -0.1140, -1.4087, -0.7920, -2.1574, -1.5795,
         -0.9642, -0.4688]], device='cuda:0')
pred_boxes  tensor([[35.,  7., 63., 36.],
        [30., 54., 58., 83.],
        [46., 48., 80., 83.],
        [26., 18., 54., 46.],
        [55., 39., 83., 67.]])
target_boxes  tensor([[56, 12, 83, 39],
        [24,  7, 51, 34],
        [37, 16, 64, 43],
        [42,  6, 69, 33],
        [47, 43, 74, 70]], dtype=torch.int32)
action_seq  tensor([[4, 9, 7, 4, 4, 3, 9, 8, 3, 2],
        [8, 4, 8, 1, 9, 1, 0, 4, 1, 8],
        [6, 4, 6, 3, 4, 1, 1, 6, 1, 6],
        [8, 8, 7, 3, 7, 5, 7, 7, 1, 8],
        [3, 3, 3, 1, 6, 7, 1, 7, 7, 5]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1.,  1., -1., -1.,  1., -1., -1., -1.],
        [-1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [-1.,  1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.],
        [-1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.],
        [ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[-0.7170, -1.9547, -1.1222, -0.5025, -1.5178, -0.9325, -0.2480, -1.6395,
         -1.1195, -0.5625],
        [-2.6389, -1.8766, -3.0636, -2.4624, -1.4777, -2.9130, -2.2480, -1.6395,
         -1.1195, -0.5625],
        [ 2.9930,  3.8119,  2.6835,  3.3413,  2.3650,  0.9678,  1.6729,  2.3205,
          0.8610,  1.4375],
        [-4.5998, -3.8571, -3.0431, -2.4429, -3.4777, -2.9130, -2.2480, -1.6395,
         -1.1195, -0.5625],
        [-4.5402, -5.8170, -5.0236, -4.4429, -3.4777, -2.9130, -2.2480, -1.6395,
         -1.1195, -0.5625]], device='cuda:0')
pred_boxes  tensor([[42., 41., 70., 69.],
        [33.,  6., 62., 34.],
        [19., 26., 48., 54.],
        [29.,  5., 83., 58.],
        [54., 39., 83., 67.]])
target_boxes  tensor([[10, 46, 37, 73],
        [ 9, 54, 36, 81],
        [ 8, 39, 35, 66],
        [38, 51, 65, 78],
        [40,  8, 67, 35]], dtype=torch.int32)
action_seq  tensor([[8, 0, 8, 2, 0, 7, 0, 3, 8, 9],
        [3, 9, 7, 0, 0, 2, 8, 6, 3, 0],
        [3, 4, 3, 5, 6, 3, 4, 3, 9, 5],
        [6, 8, 3, 1, 6, 4, 3, 8, 0, 0],
        [9, 2, 7, 6, 7, 0, 3, 0, 2, 4]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1.,  1., -1.,  1., -1., -1., -1., -1.],
        [ 1., -1., -1.,  1., -1., -1., -1., -1.,  1., -1.],
        [ 1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [-1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.],
        [-1.,  1., -1.,  1., -1., -1., -1., -1.,  1., -1.]])
adv  tensor([[-2.2761, -1.2895, -0.4812,  0.1132, -0.9582, -0.2106, -1.5702, -1.3020,
         -0.7785, -0.2812],
        [-0.3327, -1.3462, -0.5388,  0.0556, -1.0177, -0.2702,  0.3898,  0.6785,
          1.2215, -0.2812],
        [-0.2175, -1.2300, -2.4421, -1.8663, -0.9386, -2.2106, -1.5702, -1.3020,
         -0.7785, -0.2812],
        [ 3.3938,  4.4380,  5.3040,  3.9364,  2.9032,  3.6898,  2.3703,  2.6785,
          1.2215, -0.2812],
        [-0.3523,  0.6538, -0.5388,  0.0556, -1.0177, -0.2702,  0.3898,  0.6785,
          1.2215, -0.2812]], device='cuda:0')
pred_boxes  tensor([[12., 16., 40., 45.],
        [14., 22., 42., 51.],
        [35., 49., 63., 77.],
        [31., 22., 59., 50.],
        [23., 31., 51., 60.]])
target_boxes  tensor([[30, 52, 57, 79],
        [33, 50, 60, 77],
        [23, 26, 50, 53],
        [31, 10, 58, 37],
        [ 6, 51, 33, 78]], dtype=torch.int32)
action_seq  tensor([[4, 6, 3, 2, 4, 0, 9, 9, 8, 4],
        [6, 0, 3, 3, 2, 7, 9, 7, 8, 6],
        [1, 3, 6, 3, 6, 7, 3, 1, 9, 1],
        [0, 4, 7, 2, 3, 7, 6, 3, 3, 2],
        [6, 5, 4, 7, 7, 8, 9, 9, 6, 5]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.],
        [-1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.],
        [ 1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1., -1.],
        [ 1.,  1.,  1., -1.,  1.,  1., -1., -1., -1., -1.],
        [-1., -1.,  1.,  1., -1., -1.,  1., -1., -1., -1.]])
adv  tensor([[ 5.0612e+00,  3.8191e+00,  4.4259e+00,  3.4287e+00,  2.2319e+00,
          1.0240e+00,  1.7606e+00,  3.8893e-01, -9.9603e-01, -4.0625e-01],
        [ 3.0466e+00,  3.8035e+00,  2.3898e+00,  1.3721e+00,  1.5471e-01,
          9.4495e-01,  1.6805e+00,  2.3294e+00,  2.9844e+00,  1.5938e+00],
        [ 5.0446e+00,  3.8005e+00,  2.3869e+00,  3.3896e+00,  2.1928e+00,
          3.0045e+00,  1.7401e+00,  3.6940e-01,  1.0040e+00, -4.0625e-01],
        [ 3.2565e+00,  1.9949e+00,  5.6267e-01, -4.7267e-01,  3.1194e-01,
         -9.1638e-01, -2.2199e+00, -1.6111e+00, -9.9603e-01, -4.0625e-01],
        [-7.2394e-01, -4.1504e-03,  5.6364e-01, -4.7267e-01, -1.7086e+00,
         -9.3591e-01, -2.1991e-01, -1.6111e+00, -9.9603e-01, -4.0625e-01]],
       device='cuda:0')
pred_boxes  tensor([[17., 39., 45., 67.],
        [28., 31., 62., 66.],
        [42., 36., 71., 64.],
        [29., 30., 57., 59.],
        [ 3., 17., 69., 83.]])
target_boxes  tensor([[14, 44, 41, 71],
        [29, 21, 56, 48],
        [41, 43, 68, 70],
        [40, 22, 67, 49],
        [53, 49, 80, 76]], dtype=torch.int32)
action_seq  tensor([[3, 6, 8, 0, 4, 8, 8, 1, 1, 6],
        [5, 6, 5, 9, 1, 7, 0, 0, 2, 9],
        [6, 8, 2, 9, 3, 3, 3, 8, 8, 2],
        [1, 1, 1, 3, 9, 2, 5, 8, 2, 4],
        [4, 2, 1, 9, 7, 3, 5, 8, 1, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [-1., -1.,  1., -1., -1., -1., -1.,  1.,  1., -1.],
        [ 1.,  1., -1.,  1.,  1.,  1., -1., -1., -1., -1.],
        [ 1.,  1.,  1., -1., -1., -1., -1.,  1., -1., -1.]])
adv  tensor([[-4.4718, -3.4441, -4.4890, -3.8399, -3.2473, -2.4279, -1.8527, -1.2401,
         -0.6844, -0.3125],
        [-4.5314, -3.5037, -2.5290, -1.8594, -1.2473, -2.4279, -1.8527, -1.2401,
         -0.6844, -0.3125],
        [-0.7823,  0.2834,  1.2962, -0.0166,  0.6140,  1.4725,  2.0877,  2.7404,
          1.3156, -0.3125],
        [ 3.2919,  2.3772,  1.3919,  2.1005,  0.7331, -0.4279, -1.8527, -1.2401,
         -0.6844, -0.3125],
        [ 1.3524,  0.4192, -0.5866, -1.9190, -1.3069, -0.4679,  0.1278,  0.7599,
         -0.6844, -0.3125]], device='cuda:0')
pred_boxes  tensor([[14.,  0., 43., 28.],
        [16., 14., 49., 47.],
        [31., 38., 59., 67.],
        [47., 13., 77., 41.],
        [40., 30., 68., 58.]])
target_boxes  tensor([[ 2, 56, 29, 83],
        [54, 40, 81, 67],
        [32, 17, 59, 44],
        [42, 27, 69, 54],
        [28, 29, 55, 56]], dtype=torch.int32)
action_seq  tensor([[6, 8, 9, 2, 9, 8, 2, 4, 7, 2],
        [9, 4, 9, 3, 7, 4, 3, 4, 6, 9],
        [0, 2, 4, 4, 0, 4, 5, 1, 9, 8],
        [3, 3, 8, 0, 5, 3, 4, 8, 7, 2],
        [8, 0, 8, 0, 8, 8, 7, 9, 2, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1.,  1., -1., -1.,  1.,  1., -1.,  1.],
        [-1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.],
        [ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1., -1., -1.,  1., -1., -1., -1., -1.],
        [-1.,  1., -1.,  1., -1., -1., -1., -1.,  1., -1.]])
adv  tensor([[ 0.9136,  1.7123,  2.6139,  3.4914,  2.3909,  2.9518,  3.6447,  2.1658,
          0.7363,  1.4062],
        [ 6.7378,  7.5951,  6.5348,  5.4328,  4.3518,  4.9322,  3.6242,  2.1462,
          2.7363,  1.4062],
        [-4.6010, -5.8785, -5.0540, -4.2527, -3.4119, -2.9096, -2.2762, -1.7942,
         -1.2442, -0.5938],
        [-0.7182, -1.9576, -3.1136, -2.2927, -1.4314, -0.9096, -2.2762, -1.7942,
         -1.2442, -0.5938],
        [-0.8344, -0.0543, -1.1908, -0.3504, -1.4910, -0.9691, -0.3162,  0.1863,
          0.7558, -0.5938]], device='cuda:0')
pred_boxes  tensor([[13., 28., 45., 63.],
        [40., 51., 68., 79.],
        [ 9., 21., 37., 49.],
        [45., 23., 73., 51.],
        [18., 28., 51., 62.]])
target_boxes  tensor([[15, 38, 42, 65],
        [37, 55, 64, 82],
        [40,  5, 67, 32],
        [53, 54, 80, 81],
        [21, 16, 48, 43]], dtype=torch.int32)
Test Epoch: 4 [640/982 (62%)]	Reward: -0.3440
action_seq  tensor([[4, 7, 5, 7, 6, 3, 0, 4, 7, 9],
        [5, 8, 8, 5, 4, 8, 2, 4, 6, 2],
        [7, 2, 8, 8, 3, 0, 3, 6, 3, 3],
        [7, 9, 8, 0, 8, 0, 6, 8, 0, 1],
        [3, 6, 4, 8, 4, 7, 3, 6, 0, 8]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1.,  1., -1.,  1., -1., -1., -1.],
        [-1., -1., -1., -1.,  1.,  1., -1., -1., -1., -1.],
        [-1., -1., -1., -1.,  1., -1.,  1., -1., -1., -1.],
        [-1., -1., -1.,  1., -1.,  1., -1., -1.,  1., -1.],
        [ 1., -1.,  1., -1.,  1., -1.,  1.,  1., -1., -1.]])
adv  tensor([[-0.4474, -1.6508, -0.9420, -0.0670,  0.4053, -0.6946,  0.0870, -1.2695,
         -0.8404, -0.3438],
        [-2.4278, -1.6322, -0.9224, -0.0474,  0.4258, -0.6751, -1.9130, -1.2695,
         -0.8404, -0.3438],
        [-2.4474, -1.6508, -0.9420, -0.0670,  0.4053, -0.6946,  0.0870, -1.2695,
         -0.8404, -0.3438],
        [-0.5626,  0.2516,  0.9809,  1.8745,  0.3467,  1.2653,  0.0470,  0.7110,
          1.1596, -0.3438],
        [ 3.3768,  2.2125,  2.9604,  1.8539,  2.3457,  1.2653,  2.0675,  0.7305,
         -0.8404, -0.3438]], device='cuda:0')
pred_boxes  tensor([[26., 31., 59., 64.],
        [ 4., 26., 36., 60.],
        [20., 27., 48., 56.],
        [ 8.,  0., 41., 32.],
        [22., 18., 50., 46.]])
target_boxes  tensor([[ 5, 19, 32, 46],
        [39,  4, 66, 31],
        [50, 39, 77, 66],
        [ 1,  8, 28, 35],
        [28, 42, 55, 69]], dtype=torch.int32)
action_seq  tensor([[6, 3, 4, 8, 0, 5, 3, 7, 8, 2],
        [3, 5, 7, 4, 8, 4, 3, 2, 4, 6],
        [3, 4, 3, 5, 2, 4, 2, 5, 8, 4],
        [8, 2, 6, 7, 3, 0, 7, 4, 3, 3],
        [0, 6, 1, 3, 1, 2, 4, 0, 1, 5]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [ 1., -1., -1.,  1., -1., -1., -1.,  1., -1.,  1.],
        [ 1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [-1., -1., -1.,  1., -1., -1.,  1., -1., -1., -1.],
        [ 1., -1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.]])
adv  tensor([[-4.1828, -3.4357, -2.6182, -1.9494, -1.2436, -2.5819, -1.9452, -1.3651,
         -0.7160, -0.2812],
        [ 1.5281,  0.3123,  1.1689,  1.8738,  0.5992,  1.2990,  1.9757,  2.5949,
          1.2645,  1.7188],
        [-0.2023, -1.4357, -2.6182, -1.9494, -1.2436, -2.5819, -1.9452, -1.3651,
         -0.7160, -0.2812],
        [-2.2805, -1.5138, -0.6768,  0.0105, -1.2837, -0.6014,  0.0548, -1.3651,
         -0.7160, -0.2812],
        [ 3.6199,  2.4256,  3.3027,  2.0105,  0.7368, -0.5819, -1.9452, -1.3651,
         -0.7160, -0.2812]], device='cuda:0')
pred_boxes  tensor([[37., 19., 65., 47.],
        [29., 31., 57., 59.],
        [35., 37., 63., 66.],
        [43., 38., 71., 67.],
        [31., 15., 60., 43.]])
target_boxes  tensor([[ 5, 24, 32, 51],
        [28, 47, 55, 74],
        [18, 42, 45, 69],
        [51, 19, 78, 46],
        [33, 11, 60, 38]], dtype=torch.int32)
action_seq  tensor([[2, 7, 8, 7, 7, 8, 1, 8, 3, 6],
        [0, 3, 0, 4, 9, 3, 6, 0, 3, 6],
        [8, 4, 7, 7, 4, 1, 6, 3, 8, 1],
        [2, 8, 3, 0, 3, 0, 0, 0, 9, 6],
        [6, 7, 8, 2, 4, 9, 0, 6, 2, 7]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1., -1., -1., -1., -1.,  1.,  1.],
        [ 1.,  1.,  1., -1.,  1.,  1., -1., -1., -1., -1.],
        [-1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.],
        [ 1., -1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.],
        [-1., -1., -1.,  1.,  1., -1.,  1.,  1., -1., -1.]])
adv  tensor([[-9.5363e-01, -1.8155e+00, -1.0450e+00, -2.6614e-01,  5.5165e-01,
          1.1881e+00,  1.9577e+00,  2.6725e+00,  3.0785e+00,  1.5625e+00],
        [ 3.1372e+00,  2.3163e+00,  1.1083e+00, -1.1087e-01,  7.0888e-01,
         -6.7326e-01, -1.9427e+00, -1.2679e+00, -9.0198e-01, -4.3750e-01],
        [ 9.0868e-01,  2.0859e+00,  2.8954e+00,  1.6938e+00,  2.5321e+00,
          3.1881e+00,  1.9577e+00,  2.6725e+00,  3.0785e+00,  1.5625e+00],
        [ 3.0034e+00,  2.1816e+00,  2.9931e+00,  1.7915e+00,  6.1122e-01,
          1.2476e+00, -2.2430e-03,  6.9205e-01,  1.0785e+00,  1.5625e+00],
        [ 9.8192e-01,  2.1601e+00,  2.9716e+00,  3.7905e+00,  2.6288e+00,
          1.2672e+00,  2.0378e+00,  7.3209e-01, -9.0198e-01, -4.3750e-01]],
       device='cuda:0')
pred_boxes  tensor([[31., 10., 74., 53.],
        [10., 28., 38., 56.],
        [38., 15., 67., 43.],
        [15., 28., 43., 56.],
        [ 6., 37., 39., 72.]])
target_boxes  tensor([[34, 46, 61, 73],
        [28, 30, 55, 57],
        [53,  3, 80, 30],
        [15, 22, 42, 49],
        [ 0, 23, 27, 50]], dtype=torch.int32)
action_seq  tensor([[3, 7, 7, 7, 0, 5, 9, 4, 6, 3],
        [0, 6, 1, 2, 6, 9, 3, 9, 7, 8],
        [0, 3, 8, 2, 8, 7, 3, 9, 0, 9],
        [3, 8, 2, 4, 6, 3, 9, 8, 4, 7],
        [0, 7, 9, 0, 4, 1, 8, 7, 3, 0]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [ 1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1.],
        [ 1.,  1., -1.,  1., -1., -1., -1.,  1., -1.,  1.],
        [ 1., -1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.],
        [-1.,  1., -1., -1., -1.,  1., -1.,  1.,  1., -1.]])
adv  tensor([[-4.5475, -3.7094, -2.8630, -2.0074, -1.3337, -2.7361, -2.0061, -1.3004,
         -0.9032, -0.3125],
        [ 4.9877,  3.9029,  4.8255,  3.7377,  2.4495,  3.1057,  3.8943,  2.6400,
          3.0773,  1.6875],
        [ 3.1439,  2.0386,  0.9241,  1.8159,  0.5091,  1.1448,  1.9148,  2.6595,
          1.0773,  1.6875],
        [ 3.1039,  1.9996,  2.9027,  1.7953,  2.5091,  3.1653,  1.9343,  0.6595,
          1.0773,  1.6875],
        [ 1.1244,  2.0181,  0.9027,  1.7953,  2.5081,  3.1643,  1.9343,  2.6800,
          1.0968, -0.3125]], device='cuda:0')
pred_boxes  tensor([[20., 39., 54., 73.],
        [18., 25., 52., 59.],
        [29., 23., 57., 51.],
        [28., 31., 56., 59.],
        [36., 15., 65., 43.]])
target_boxes  tensor([[11,  3, 38, 30],
        [32, 22, 59, 49],
        [22, 33, 49, 60],
        [35, 54, 62, 81],
        [54, 24, 81, 51]], dtype=torch.int32)
action_seq  tensor([[5, 1, 3, 6, 3, 3, 0, 3, 2, 7],
        [5, 9, 9, 3, 7, 7, 8, 7, 9, 3],
        [5, 6, 3, 7, 7, 9, 3, 8, 3, 6],
        [9, 6, 4, 8, 8, 0, 7, 2, 7, 4],
        [6, 3, 0, 0, 3, 9, 1, 0, 8, 8]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.],
        [-1., -1., -1.,  1., -1., -1.,  1., -1., -1., -1.],
        [-1., -1.,  1., -1., -1., -1., -1.,  1., -1.,  1.],
        [-1., -1.,  1., -1., -1., -1.,  1., -1.,  1., -1.],
        [-1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.]])
adv  tensor([[ 1.0562,  1.8934,  2.8306,  1.9411,  2.4207,  1.3422, -0.2971,  0.2508,
          0.8049,  1.3636],
        [-2.7309, -1.9318, -1.0327,  0.0583, -1.5021, -0.5982, -0.2375, -1.7092,
         -1.1756, -0.6364],
        [-0.9028, -0.0851,  0.8325, -0.0784,  0.3807,  1.3022,  1.6834,  2.2508,
          0.8049,  1.3636],
        [-0.8657, -0.0470,  0.8696, -0.0393,  0.4188,  1.3422,  1.7224,  0.2713,
          0.8244, -0.6364],
        [-0.9213, -0.1036,  0.8130, -0.0969,  0.3612,  1.2826,  1.6629,  2.2312,
          2.8049,  1.3636]], device='cuda:0')
pred_boxes  tensor([[41., 31., 69., 59.],
        [29., 28., 83., 82.],
        [30., 28., 74., 72.],
        [30., 14., 62., 47.],
        [30., 18., 58., 46.]])
target_boxes  tensor([[43, 56, 70, 83],
        [48, 13, 75, 40],
        [36, 15, 63, 42],
        [53, 18, 80, 45],
        [45,  0, 72, 27]], dtype=torch.int32)
action_seq  tensor([[9, 7, 8, 1, 8, 2, 8, 9, 6, 2],
        [0, 7, 0, 7, 4, 7, 2, 6, 8, 9],
        [6, 9, 8, 5, 5, 2, 7, 6, 6, 6],
        [5, 3, 3, 2, 0, 5, 7, 8, 8, 3],
        [5, 3, 3, 8, 7, 8, 3, 6, 9, 5]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.],
        [ 1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.],
        [-1., -1., -1., -1., -1.,  1., -1.,  1., -1., -1.],
        [-1.,  1., -1.,  1.,  1., -1., -1.,  1., -1., -1.],
        [-1., -1., -1.,  1., -1.,  1., -1.,  1., -1., -1.]])
adv  tensor([[ 1.9855,  2.6512,  3.1236,  3.6789,  2.3842,  3.2152,  1.7535,  2.2554,
          0.8648,  1.5600],
        [ 5.9064,  4.5935,  5.0836,  3.6398,  4.3637,  3.1957,  3.7535,  2.2554,
          0.8648,  1.5600],
        [-1.7821, -1.1545, -0.7211, -0.2039,  0.4818,  1.2943, -0.1870,  0.2954,
         -1.1157, -0.4400],
        [ 2.1574,  2.8250,  1.2789,  1.8166,  0.5014, -0.7057, -0.1870,  0.2954,
         -1.1157, -0.4400],
        [ 0.1584,  0.8054,  1.2594,  1.7961,  0.4818,  1.2943, -0.1870,  0.2954,
         -1.1157, -0.4400]], device='cuda:0')
pred_boxes  tensor([[ 5., 22., 47., 65.],
        [29., 12., 61., 45.],
        [ 0., 16., 66., 83.],
        [41., 31., 69., 60.],
        [30., 25., 74., 69.]])
target_boxes  tensor([[21, 33, 48, 60],
        [30, 22, 57, 49],
        [12, 25, 39, 52],
        [10, 32, 37, 59],
        [ 9,  4, 36, 31]], dtype=torch.int32)


Train Epoch: 5 [0/50 (0%)]	Reward: -0.4200
action_seq  tensor([[6, 4, 2, 4, 2, 0, 6, 7, 2, 2],
        [9, 9, 5, 7, 3, 3, 9, 7, 3, 9],
        [8, 0, 7, 2, 6, 6, 8, 4, 7, 3],
        [6, 0, 9, 7, 0, 1, 4, 9, 3, 7],
        [1, 3, 6, 1, 3, 1, 9, 3, 9, 4]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.],
        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.],
        [-1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1., -1.],
        [-1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[ 5.9084,  6.6626,  5.4038,  4.2593,  3.0714,  1.6191,  0.1829, -1.3620,
         -0.9023, -0.4062],
        [-5.6786, -5.0415, -4.3979, -3.6216, -2.8690, -2.3613, -1.8171, -1.3620,
         -0.9023, -0.4062],
        [-0.0457,  0.6490,  1.3491,  0.1636,  0.9542,  1.5000,  2.0833,  2.5784,
          3.0782,  1.5938],
        [ 3.8156,  4.5484,  3.2681,  4.1226,  4.9522,  3.5195,  4.1234,  2.6185,
          1.0977, -0.4062],
        [-3.7186, -3.0610, -2.3979, -3.6216, -2.8690, -2.3613, -1.8171, -1.3620,
         -0.9023, -0.4062]], device='cuda:0')
pred_boxes  tensor([[12., 34., 40., 63.],
        [39., 39., 83., 83.],
        [21., 15., 54., 49.],
        [36., 27., 65., 55.],
        [42., 31., 72., 59.]])
target_boxes  tensor([[ 6, 40, 33, 67],
        [ 4, 37, 31, 64],
        [51, 29, 78, 56],
        [29, 35, 56, 62],
        [ 6, 42, 33, 69]], dtype=torch.int32)


Test Epoch: 5 [0/982 (0%)]	Reward: -0.4094
action_seq  tensor([[5, 0, 7, 3, 0, 9, 0, 6, 4, 8],
        [6, 7, 5, 4, 3, 7, 3, 8, 1, 6],
        [0, 4, 0, 8, 2, 6, 3, 8, 3, 6],
        [7, 9, 7, 5, 9, 0, 4, 2, 9, 4],
        [1, 9, 0, 6, 4, 3, 9, 7, 9, 8]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1.,  1., -1.,  1., -1.,  1., -1., -1.],
        [-1., -1., -1.,  1.,  1., -1., -1., -1., -1.,  1.],
        [ 1.,  1., -1., -1., -1., -1.,  1., -1., -1., -1.],
        [-1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1.],
        [ 1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.]])
adv  tensor([[-0.4128,  0.2765,  0.9119,  1.6776,  0.4958,  1.3211,  0.0093,  0.5771,
         -0.9323, -0.5312],
        [-0.4314,  0.2589,  0.8934,  1.6600,  0.4772, -0.7180, -0.0307,  0.5371,
          1.0482,  1.4688],
        [-0.2565, -1.5849, -2.9904, -2.2629, -1.4652, -0.6584,  0.0288, -1.4229,
         -0.9323, -0.5312],
        [-0.4704,  0.2189,  0.8524,  1.6180,  2.4557,  3.3015,  2.0093,  0.5771,
         -0.9323, -0.5312],
        [ 7.3157,  6.0636,  4.7352,  3.5203,  4.3766,  5.2420,  3.9693,  2.5576,
          1.0677, -0.5312]], device='cuda:0')
pred_boxes  tensor([[21., 17., 49., 45.],
        [41., 22., 76., 56.],
        [ 0.,  7., 29., 36.],
        [10., 28., 43., 62.],
        [24., 31., 58., 64.]])
target_boxes  tensor([[22, 52, 49, 79],
        [17, 55, 44, 82],
        [32, 31, 59, 58],
        [25, 15, 52, 42],
        [30, 44, 57, 71]], dtype=torch.int32)
action_seq  tensor([[3, 4, 3, 1, 9, 7, 8, 3, 8, 1],
        [4, 1, 8, 5, 9, 8, 2, 2, 8, 9],
        [3, 0, 2, 8, 4, 0, 4, 4, 4, 1],
        [0, 3, 1, 0, 6, 8, 8, 7, 1, 3],
        [3, 6, 1, 3, 3, 7, 8, 3, 8, 7]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1.,  1., -1.,  1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1., -1.,  1., -1.,  1.,  1., -1.,  1.],
        [ 1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.],
        [ 1.,  1.,  1.,  1.,  1., -1., -1., -1., -1., -1.],
        [ 1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[ 1.3478,  0.3517, -0.5922, -1.8285, -1.1846, -2.3329, -1.8830, -1.2391,
         -0.7151, -0.3750],
        [ 4.9621,  4.0021,  3.0953,  3.9156,  4.6182,  3.5284,  4.0379,  2.7208,
          1.2654,  1.6250],
        [ 5.1906,  4.2326,  3.3287,  2.1314,  0.7959, -0.3329, -1.8830, -1.2391,
         -0.7151, -0.3750],
        [ 3.2883,  2.3117,  1.3883,  0.1715, -1.1846, -2.3329, -1.8830, -1.2391,
         -0.7151, -0.3750],
        [-0.5731, -1.5887, -2.5521, -3.8090, -3.1846, -2.3329, -1.8830, -1.2391,
         -0.7151, -0.3750]], device='cuda:0')
pred_boxes  tensor([[54., 33., 83., 61.],
        [21., 17., 54., 51.],
        [20., 21., 48., 49.],
        [27.,  0., 56., 28.],
        [52., 28., 81., 56.]])
target_boxes  tensor([[33, 44, 60, 71],
        [17, 27, 44, 54],
        [12, 19, 39, 46],
        [18, 16, 45, 43],
        [ 9, 33, 36, 60]], dtype=torch.int32)
action_seq  tensor([[1, 3, 4, 4, 4, 3, 3, 1, 3, 2],
        [5, 7, 8, 6, 6, 7, 8, 6, 3, 9],
        [3, 6, 0, 2, 8, 3, 2, 5, 0, 6],
        [1, 8, 8, 5, 3, 1, 0, 8, 9, 3],
        [5, 8, 9, 0, 9, 7, 9, 6, 7, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.],
        [-1.,  1.,  1.,  1., -1., -1.,  1., -1., -1.,  1.],
        [ 1., -1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.],
        [-1., -1., -1., -1., -1.,  1., -1., -1.,  1.,  1.]])
adv  tensor([[-4.2427, -5.4850, -4.8144, -4.1685, -3.5478, -2.8892, -2.2240, -1.4573,
         -0.7776, -0.3750],
        [-4.3970, -3.6208, -2.9316, -2.2662, -1.6269, -0.9487, -0.2640,  0.5232,
          1.2224, -0.3750],
        [ 3.3481,  4.2034,  2.9512,  1.6547,  0.3145,  1.0122,  1.7164,  0.5027,
          1.2029,  1.6250],
        [ 3.3276,  2.1614,  2.9093,  3.6333,  4.3331,  3.0513,  1.7565,  0.5427,
         -0.7776, -0.3750],
        [-0.6675,  0.1458,  0.8731,  1.5766,  2.2559,  2.9722,  1.6764,  2.4832,
          3.2029,  1.6250]], device='cuda:0')
pred_boxes  tensor([[40., 24., 69., 52.],
        [16., 16., 83., 83.],
        [ 4., 31., 32., 60.],
        [44., 17., 74., 45.],
        [26., 30., 79., 83.]])
target_boxes  tensor([[17, 28, 44, 55],
        [20, 15, 47, 42],
        [ 2, 45, 29, 72],
        [49, 11, 76, 38],
        [55, 36, 82, 63]], dtype=torch.int32)
action_seq  tensor([[2, 4, 8, 6, 2, 8, 2, 7, 2, 8],
        [3, 7, 7, 7, 8, 1, 3, 3, 6, 3],
        [1, 6, 0, 7, 7, 2, 2, 7, 1, 4],
        [2, 0, 7, 3, 9, 3, 3, 3, 9, 6],
        [7, 6, 7, 6, 9, 8, 0, 5, 5, 8]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1., -1., -1.,  1., -1.,  1., -1.,  1., -1.],
        [ 1., -1., -1., -1.,  1.,  1., -1., -1.,  1., -1.],
        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1., -1.,  1., -1., -1., -1., -1.,  1.],
        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[ 3.1784,  2.0111,  0.6731,  1.5651,  2.2742,  1.1301,  1.7722,  0.3388,
          1.0046, -0.4688],
        [ 1.2175,  0.0296,  0.6927,  1.5846,  2.2947,  1.1497, -0.2278,  0.3388,
          1.0046, -0.4688],
        [-6.4515, -5.6960, -5.0905, -4.2581, -3.6067, -2.7908, -2.1877, -1.6417,
         -0.9954, -0.4688],
        [ 1.2771,  0.0902, -1.2663, -0.3949,  0.2957, -0.8699, -0.2473,  0.3183,
          0.9850,  1.5312],
        [-6.4515, -5.6960, -5.0905, -4.2581, -3.6067, -2.7908, -2.1877, -1.6417,
         -0.9954, -0.4688]], device='cuda:0')
pred_boxes  tensor([[ 6., 18., 34., 49.],
        [46., 27., 75., 55.],
        [33., 18., 61., 46.],
        [28., 53., 56., 82.],
        [ 0.,  0., 66., 66.]])
target_boxes  tensor([[ 6, 38, 33, 65],
        [29, 11, 56, 38],
        [32, 53, 59, 80],
        [10, 43, 37, 70],
        [49, 26, 76, 53]], dtype=torch.int32)
action_seq  tensor([[0, 7, 8, 3, 8, 7, 3, 3, 8, 5],
        [6, 2, 4, 5, 7, 0, 8, 6, 2, 7],
        [7, 6, 1, 3, 1, 7, 4, 6, 1, 0],
        [2, 3, 8, 8, 2, 1, 2, 3, 1, 8],
        [3, 0, 3, 7, 3, 7, 6, 4, 0, 4]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1.],
        [-1., -1., -1., -1., -1.,  1.,  1., -1., -1.,  1.],
        [-1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.],
        [-1., -1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.],
        [ 1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.]])
adv  tensor([[ 5.0240,  5.8633,  4.7229,  5.4975,  4.2898,  3.0079,  1.6803,  0.4038,
          0.9124, -0.6250],
        [-0.8363, -0.0557,  0.7639,  1.4975,  2.2713,  2.9883,  1.6608,  0.3833,
          0.8928,  1.3750],
        [ 4.9654,  5.8057,  6.6848,  5.4584,  4.2498,  2.9678,  3.6608,  2.4038,
          0.9124, -0.6250],
        [ 1.1813,  1.9824,  2.8235,  1.5571,  0.3113,  1.0079, -0.3392,  0.3833,
          0.8928,  1.3750],
        [ 7.1002,  5.9414,  4.8020,  3.5561,  2.3289,  1.0274,  1.7009,  0.4233,
         -1.0876, -0.6250]], device='cuda:0')
pred_boxes  tensor([[48., 13., 83., 48.],
        [13., 21., 46., 56.],
        [41., 17., 71., 45.],
        [21., 17., 49., 46.],
        [44., 37., 72., 65.]])
target_boxes  tensor([[56, 12, 83, 39],
        [24,  7, 51, 34],
        [37, 16, 64, 43],
        [42,  6, 69, 33],
        [47, 43, 74, 70]], dtype=torch.int32)
action_seq  tensor([[0, 8, 8, 2, 4, 1, 4, 3, 3, 8],
        [6, 2, 7, 3, 0, 7, 9, 1, 5, 3],
        [7, 7, 3, 3, 2, 8, 8, 3, 8, 8],
        [2, 7, 8, 7, 7, 1, 6, 1, 6, 6],
        [9, 7, 8, 3, 4, 5, 6, 0, 9, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1.,  1.,  1., -1., -1., -1., -1., -1.],
        [-1.,  1., -1., -1., -1., -1.,  1., -1., -1., -1.],
        [-1., -1.,  1., -1.,  1., -1., -1., -1., -1., -1.],
        [ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[-0.5210, -1.5363, -0.7620,  0.1461, -1.1788, -2.5163, -1.9421, -1.3935,
         -0.7764, -0.5000],
        [-2.5190, -1.5343, -2.7815, -1.8940, -1.2188, -0.5359,  0.0579, -1.3935,
         -0.7764, -0.5000],
        [-2.5014, -1.5158, -0.7424, -1.8539, -1.1788, -2.5163, -1.9421, -1.3935,
         -0.7764, -0.5000],
        [-4.3823, -5.4367, -4.7024, -3.8344, -3.1788, -2.5163, -1.9421, -1.3935,
         -0.7764, -0.5000],
        [-4.4418, -3.4767, -2.7219, -1.8344, -3.1788, -2.5163, -1.9421, -1.3935,
         -0.7764, -0.5000]], device='cuda:0')
pred_boxes  tensor([[15., 14., 43., 42.],
        [48., 43., 76., 71.],
        [37., 13., 72., 49.],
        [11.,  2., 54., 44.],
        [19., 38., 54., 73.]])
target_boxes  tensor([[10, 46, 37, 73],
        [ 9, 54, 36, 81],
        [ 8, 39, 35, 66],
        [38, 51, 65, 78],
        [40,  8, 67, 35]], dtype=torch.int32)
action_seq  tensor([[1, 1, 1, 6, 4, 2, 1, 9, 3, 8],
        [9, 4, 3, 0, 5, 1, 2, 2, 7, 0],
        [3, 8, 6, 3, 5, 6, 8, 1, 3, 6],
        [9, 7, 8, 0, 6, 6, 8, 0, 5, 2],
        [1, 7, 7, 1, 2, 7, 2, 2, 9, 1]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1.,  1.,  1., -1., -1., -1.,  1., -1.,  1., -1.],
        [ 1., -1., -1.,  1., -1., -1., -1.,  1.,  1., -1.],
        [-1., -1., -1.,  1., -1., -1., -1.,  1., -1., -1.],
        [-1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.]])
adv  tensor([[-6.1151, -5.1983, -4.3354, -3.6531, -2.9324, -2.2991, -1.8805, -1.4576,
         -0.8094, -0.3125],
        [ 1.5538,  2.5488,  1.4683,  0.1897,  0.9485,  1.6218,  2.0794,  0.5229,
          1.1906, -0.3125],
        [ 1.5353,  0.5088,  1.4302,  2.1701,  0.9289,  1.6013,  2.0599,  2.5229,
          1.1906, -0.3125],
        [-2.3104, -1.3555, -0.4526,  0.2678, -0.9920, -0.3391,  0.0999,  0.5424,
         -0.8094, -0.3125],
        [-4.1942, -3.2578, -2.3754, -1.6727, -0.9324, -2.2991, -1.8805, -1.4576,
         -0.8094, -0.3125]], device='cuda:0')
pred_boxes  tensor([[34.,  7., 64., 35.],
        [34., 26., 62., 54.],
        [14., 12., 50., 47.],
        [ 0., 10., 41., 52.],
        [37., 29., 65., 57.]])
target_boxes  tensor([[30, 52, 57, 79],
        [33, 50, 60, 77],
        [23, 26, 50, 53],
        [31, 10, 58, 37],
        [ 6, 51, 33, 78]], dtype=torch.int32)
action_seq  tensor([[1, 2, 8, 8, 9, 3, 8, 3, 7, 4],
        [0, 8, 6, 3, 8, 3, 7, 7, 4, 2],
        [7, 7, 0, 0, 1, 4, 6, 0, 2, 6],
        [0, 9, 3, 8, 8, 0, 9, 5, 4, 7],
        [9, 3, 7, 7, 9, 7, 2, 8, 9, 6]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [ 1., -1., -1.,  1., -1.,  1., -1., -1.,  1.,  1.],
        [-1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1., -1.,  1.,  1., -1., -1.,  1., -1., -1.,  1.],
        [-1.,  1., -1., -1., -1., -1., -1., -1.,  1., -1.]])
adv  tensor([[-0.7120, -1.7297, -2.9781, -1.9974, -1.4815, -2.7274, -2.1237, -1.6086,
         -1.0883, -0.5625],
        [ 2.9023,  1.9207,  2.7299,  3.7672,  2.3223,  3.1340,  1.7767,  2.3319,
          2.8922,  1.4375],
        [-4.6534, -3.6896, -2.9380, -3.9779, -3.4815, -2.7274, -2.1237, -1.6086,
         -1.0883, -0.5625],
        [ 2.9970,  2.0184,  2.8276,  1.8454,  0.3808,  1.1740,  1.8168,  0.3514,
          0.8922,  1.4375],
        [-2.7872, -1.8058, -3.0552, -2.0755, -1.5606, -0.7869, -0.1637,  0.3719,
          0.9117, -0.5625]], device='cuda:0')
pred_boxes  tensor([[44., 22., 72., 50.],
        [43., 22., 71., 50.],
        [ 1.,  4., 29., 32.],
        [23., 16., 56., 49.],
        [ 5., 28., 58., 82.]])
target_boxes  tensor([[14, 44, 41, 71],
        [29, 21, 56, 48],
        [41, 43, 68, 70],
        [40, 22, 67, 49],
        [53, 49, 80, 76]], dtype=torch.int32)
action_seq  tensor([[6, 0, 5, 0, 8, 4, 2, 7, 8, 7],
        [6, 8, 1, 0, 8, 4, 7, 7, 2, 3],
        [2, 6, 8, 3, 7, 0, 5, 2, 9, 8],
        [9, 6, 5, 0, 3, 7, 8, 5, 8, 6],
        [3, 4, 8, 2, 3, 7, 0, 3, 6, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.],
        [ 1., -1., -1.,  1., -1.,  1., -1., -1., -1.,  1.],
        [-1., -1., -1.,  1.,  1.,  1., -1., -1., -1., -1.],
        [ 1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1., -1.]])
adv  tensor([[-6.4728, -5.4334, -4.6990, -3.7994, -3.2382, -2.6711, -2.0352, -1.3929,
         -0.8389, -0.5000],
        [ 1.0614,  2.1779,  2.9885,  1.9447,  2.5645,  3.1903,  3.8857,  2.5671,
          1.1416,  1.5000],
        [ 1.1971,  0.2932,  1.0861,  2.0433,  0.6446,  1.2498, -0.0948,  0.5671,
          1.1416,  1.5000],
        [-0.7091,  0.3879,  1.1818,  2.1410,  0.7423, -0.6711, -2.0352, -1.3929,
         -0.8389, -0.5000],
        [ 5.0975,  4.2336,  3.0451,  4.0238,  2.6427,  1.2498,  1.9247,  0.5876,
          1.1611, -0.5000]], device='cuda:0')
pred_boxes  tensor([[17.,  6., 49., 39.],
        [42., 18., 70., 46.],
        [23., 23., 56., 58.],
        [12.,  0., 65., 53.],
        [31., 29., 59., 57.]])
target_boxes  tensor([[ 2, 56, 29, 83],
        [54, 40, 81, 67],
        [32, 17, 59, 44],
        [42, 27, 69, 54],
        [28, 29, 55, 56]], dtype=torch.int32)
action_seq  tensor([[0, 0, 3, 9, 0, 6, 9, 8, 8, 7],
        [1, 6, 7, 4, 8, 6, 9, 9, 3, 9],
        [4, 7, 7, 4, 3, 3, 3, 3, 9, 0],
        [7, 8, 8, 3, 3, 8, 2, 7, 0, 3],
        [1, 3, 9, 1, 4, 3, 9, 4, 4, 9]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1.,  1.,  1., -1., -1.,  1., -1., -1.,  1.],
        [-1., -1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.],
        [ 1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.],
        [ 1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[ 4.1069,  2.7925,  3.7039,  2.2572,  0.9862,  1.6908,  2.3071,  0.6889,
          1.2648,  1.6875],
        [ 1.9164,  2.5991,  3.5086,  4.0804,  4.8475,  5.5911,  6.2475,  4.6694,
          3.2648,  1.6875],
        [-1.5630, -2.9361, -2.0813, -1.5661, -2.8761, -2.2106, -1.6333, -1.2710,
         -0.7157, -0.3125],
        [ 2.0493,  2.7329,  3.6453,  4.2181,  2.9667,  1.6702,  2.2876,  2.6889,
          1.2648,  1.6875],
        [-1.5230, -2.8960, -4.0617, -3.5661, -2.8761, -2.2106, -1.6333, -1.2710,
         -0.7157, -0.3125]], device='cuda:0')
pred_boxes  tensor([[ 9., 10., 42., 43.],
        [20., 38., 64., 81.],
        [48., 44., 76., 72.],
        [43., 34., 71., 63.],
        [48., 42., 78., 70.]])
target_boxes  tensor([[15, 38, 42, 65],
        [37, 55, 64, 82],
        [40,  5, 67, 32],
        [53, 54, 80, 81],
        [21, 16, 48, 43]], dtype=torch.int32)
Test Epoch: 5 [640/982 (62%)]	Reward: -0.3523
action_seq  tensor([[6, 2, 4, 3, 5, 2, 1, 7, 3, 3],
        [5, 7, 1, 3, 7, 7, 6, 7, 8, 8],
        [7, 4, 0, 0, 4, 1, 2, 6, 1, 3],
        [1, 5, 1, 0, 4, 3, 0, 2, 8, 4],
        [1, 3, 2, 1, 0, 1, 7, 0, 7, 0]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1.,  1., -1., -1., -1., -1., -1.,  1., -1.],
        [-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[-2.1308, -1.3945, -2.6085, -3.7080, -3.0827, -2.4823, -1.8446, -1.4529,
         -0.9311, -0.6562],
        [-2.2655, -1.5302, -0.7257, -1.8056, -1.1618, -0.5419,  0.1153,  0.5276,
          1.0689, -0.6562],
        [-4.0907, -3.3750, -4.6085, -3.7080, -3.0827, -2.4823, -1.8446, -1.4529,
         -0.9311, -0.6562],
        [-6.0712, -5.3750, -4.6085, -3.7080, -3.0827, -2.4823, -1.8446, -1.4529,
         -0.9311, -0.6562],
        [-0.1308, -1.3945, -2.6085, -3.7080, -3.0827, -2.4823, -1.8446, -1.4529,
         -0.9311, -0.6562]], device='cuda:0')
pred_boxes  tensor([[27., 40., 55., 69.],
        [28.,  0., 82., 53.],
        [10., 12., 38., 40.],
        [37.,  2., 67., 30.],
        [47., 23., 75., 51.]])
target_boxes  tensor([[ 5, 19, 32, 46],
        [39,  4, 66, 31],
        [50, 39, 77, 66],
        [ 1,  8, 28, 35],
        [28, 42, 55, 69]], dtype=torch.int32)
action_seq  tensor([[4, 6, 6, 2, 6, 3, 0, 0, 4, 0],
        [1, 2, 1, 3, 8, 0, 2, 1, 3, 9],
        [8, 6, 3, 7, 2, 8, 7, 6, 2, 6],
        [3, 5, 8, 9, 6, 9, 8, 7, 8, 4],
        [0, 8, 7, 2, 8, 6, 7, 4, 3, 8]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1., -1.,  1., -1., -1.,  1.,  1., -1., -1.],
        [ 1.,  1., -1.,  1., -1., -1., -1., -1., -1.,  1.],
        [-1., -1.,  1., -1.,  1., -1., -1.,  1.,  1., -1.],
        [ 1., -1., -1., -1., -1., -1., -1.,  1., -1.,  1.],
        [ 1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.]])
adv  tensor([[ 3.3606,  2.4158,  1.0519,  1.8191,  0.6065,  1.1815,  1.8565,  0.3596,
         -1.0889, -0.5000],
        [ 1.4407,  0.4763, -0.9071, -0.1594, -1.3916, -0.8380, -0.1835,  0.3195,
          0.8916,  1.5000],
        [ 1.2835,  2.3386,  2.9933,  1.7615,  2.5674,  1.1415,  1.8165,  2.3400,
          0.9111, -0.5000],
        [-0.6159, -1.6008, -0.9852, -0.2385,  0.5488,  1.1220,  1.7969,  2.3195,
          0.8916,  1.5000],
        [ 6.9739,  6.0662,  6.7589,  7.5848,  6.4297,  5.0429,  5.7569,  4.3000,
          2.8916,  1.5000]], device='cuda:0')
pred_boxes  tensor([[10., 31., 38., 59.],
        [34., 19., 62., 47.],
        [ 6., 28., 48., 72.],
        [21.,  6., 75., 60.],
        [25.,  8., 58., 42.]])
target_boxes  tensor([[ 5, 24, 32, 51],
        [28, 47, 55, 74],
        [18, 42, 45, 69],
        [51, 19, 78, 46],
        [33, 11, 60, 38]], dtype=torch.int32)
action_seq  tensor([[9, 3, 9, 7, 3, 8, 1, 8, 4, 2],
        [2, 3, 4, 9, 8, 3, 2, 6, 3, 0],
        [3, 2, 7, 9, 0, 9, 8, 8, 0, 6],
        [0, 6, 3, 2, 0, 6, 9, 0, 8, 8],
        [9, 1, 9, 3, 6, 1, 0, 2, 8, 6]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1., -1.,  1., -1., -1., -1., -1.,  1.],
        [ 1.,  1.,  1., -1.,  1., -1., -1., -1., -1., -1.],
        [-1., -1.,  1., -1., -1., -1.,  1.,  1., -1., -1.],
        [ 1., -1.,  1.,  1.,  1., -1., -1., -1.,  1., -1.],
        [-1., -1., -1., -1.,  1., -1., -1., -1., -1.,  1.]])
adv  tensor([[-0.9364, -0.1570, -1.1056, -0.3903,  0.3318, -0.9281, -0.4007,  0.3211,
          0.8300,  1.4062],
        [ 1.1964, -0.0222, -0.9698, -2.2731, -1.5705, -2.8490, -2.3412, -1.6389,
         -1.1505, -0.5938],
        [-0.9579, -0.1775,  0.8934, -0.3923,  0.3298,  1.0914,  1.6393,  0.3611,
         -1.1505, -0.5938],
        [ 3.0020,  1.8020,  2.8934,  1.6292,  0.3504, -0.9086, -0.3812,  0.3416,
          0.8495, -0.5938],
        [-2.9169, -2.1570, -1.1056, -0.3903,  0.3318, -0.9281, -0.4007,  0.3211,
          0.8300,  1.4062]], device='cuda:0')
pred_boxes  tensor([[43., 19., 71., 47.],
        [20., 45., 48., 74.],
        [19., 19., 52., 53.],
        [ 6., 17., 34., 45.],
        [22., 25., 51., 53.]])
target_boxes  tensor([[34, 46, 61, 73],
        [28, 30, 55, 57],
        [53,  3, 80, 30],
        [15, 22, 42, 49],
        [ 0, 23, 27, 50]], dtype=torch.int32)
action_seq  tensor([[7, 3, 8, 2, 0, 6, 9, 3, 4, 2],
        [9, 4, 4, 9, 6, 8, 3, 3, 0, 7],
        [7, 5, 8, 3, 0, 8, 8, 7, 3, 8],
        [3, 4, 4, 6, 8, 2, 6, 3, 2, 3],
        [9, 2, 3, 4, 9, 9, 7, 2, 8, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1.,  1., -1.,  1.,  1., -1., -1., -1., -1.],
        [-1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.],
        [-1., -1., -1.,  1.,  1., -1., -1., -1., -1., -1.],
        [ 1.,  1.,  1., -1., -1., -1., -1.,  1., -1., -1.],
        [-1., -1.,  1., -1., -1., -1.,  1., -1.,  1., -1.]])
adv  tensor([[-0.8109, -0.0929,  0.6635, -0.4025,  0.1303, -1.1630, -2.3743, -1.6723,
         -1.0895, -0.4375],
        [ 2.9586,  3.7147,  2.4887,  1.4403,  1.9926,  2.7384,  1.5661,  0.2876,
          0.8910,  1.5625],
        [-2.7328, -2.0343, -1.2965, -0.3624, -1.8502, -3.1630, -2.3743, -1.6723,
         -1.0895, -0.4375],
        [ 1.2106, -0.0715, -1.3346, -2.4220, -1.9097, -1.2030, -0.3938,  0.3277,
         -1.0895, -0.4375],
        [-0.9057, -0.1877,  0.5668, -0.5001,  0.0307,  0.7579,  1.5857,  0.3081,
          0.9105, -0.4375]], device='cuda:0')
pred_boxes  tensor([[18., 34., 46., 62.],
        [26., 31., 54., 59.],
        [36.,  1., 79., 44.],
        [17., 32., 45., 61.],
        [26., 46., 54., 76.]])
target_boxes  tensor([[11,  3, 38, 30],
        [32, 22, 59, 49],
        [22, 33, 49, 60],
        [35, 54, 62, 81],
        [54, 24, 81, 51]], dtype=torch.int32)
action_seq  tensor([[3, 7, 0, 7, 5, 6, 9, 9, 3, 3],
        [6, 7, 4, 6, 8, 3, 2, 3, 3, 2],
        [6, 9, 7, 4, 3, 1, 3, 1, 7, 3],
        [0, 4, 3, 0, 0, 8, 8, 2, 8, 3],
        [6, 8, 8, 9, 9, 7, 4, 7, 0, 5]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.],
        [-1., -1.,  1., -1., -1.,  1., -1., -1., -1., -1.],
        [-1., -1., -1.,  1.,  1.,  1., -1., -1., -1., -1.],
        [-1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1., -1.,  1., -1.,  1., -1.]])
adv  tensor([[ 5.8742,  4.4644,  4.8772,  5.9358,  4.5264,  5.0313,  5.7252,  4.4976,
          3.0740,  1.7273],
        [-1.6238, -1.0894, -0.7332, -1.7508, -1.2168, -0.7704, -2.1556, -1.4429,
         -0.9064, -0.2727],
        [ 0.2776,  0.8306,  1.2073,  2.2297,  0.7832, -0.7704, -2.1556, -1.4429,
         -0.9064, -0.2727],
        [-3.5261, -3.0103, -2.6736, -3.7107, -3.1972, -2.7704, -2.1556, -1.4429,
         -0.9064, -0.2727],
        [-1.7576, -1.2241, -0.8699,  0.1321,  0.6836,  1.1505,  1.8043,  0.5376,
          1.0936, -0.2727]], device='cuda:0')
pred_boxes  tensor([[33., 48., 68., 83.],
        [27., 37., 55., 66.],
        [50., 29., 79., 57.],
        [16.,  0., 44., 28.],
        [17.,  8., 69., 60.]])
target_boxes  tensor([[43, 56, 70, 83],
        [48, 13, 75, 40],
        [36, 15, 63, 42],
        [53, 18, 80, 45],
        [45,  0, 72, 27]], dtype=torch.int32)
action_seq  tensor([[1, 0, 9, 4, 3, 3, 9, 9, 3, 3],
        [0, 3, 1, 8, 3, 3, 3, 0, 1, 5],
        [7, 3, 3, 3, 2, 0, 4, 9, 9, 2],
        [5, 2, 5, 8, 9, 9, 5, 3, 4, 8],
        [1, 4, 9, 2, 1, 2, 9, 4, 7, 7]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1.],
        [ 1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1.],
        [ 1.,  1., -1.,  1., -1.,  1., -1., -1., -1., -1.]])
adv  tensor([[ 5.2729,  4.1954,  5.0050,  3.6415,  4.1634,  2.9532,  1.8114,  0.3747,
         -1.0357, -0.4400],
        [-2.2769, -3.4315, -4.7186, -4.1603, -3.7175, -2.9872, -2.1690, -1.6253,
         -1.0357, -0.4400],
        [-4.2769, -3.4315, -4.7186, -4.1603, -3.7175, -2.9872, -2.1690, -1.6253,
         -1.0357, -0.4400],
        [-2.4898, -1.6258, -0.8739, -0.2775, -1.8152, -1.0663, -0.2286,  0.3346,
          0.9448,  1.5600],
        [ 1.5659,  0.4494, -0.7977, -0.2003, -1.7370, -0.9872, -2.1690, -1.6253,
         -1.0357, -0.4400]], device='cuda:0')
pred_boxes  tensor([[34., 38., 63., 66.],
        [37., 18., 66., 46.],
        [39., 55., 67., 83.],
        [18., 25., 60., 68.],
        [40., 37., 68., 65.]])
target_boxes  tensor([[34, 45, 61, 72],
        [ 9, 26, 36, 53],
        [39, 16, 66, 43],
        [ 9,  0, 36, 27],
        [16, 32, 43, 59]], dtype=torch.int32)


Train Epoch: 6 [0/50 (0%)]	Reward: -0.3480
action_seq  tensor([[6, 2, 3, 7, 7, 2, 4, 3, 9, 9],
        [8, 1, 7, 1, 1, 3, 5, 0, 7, 1],
        [1, 5, 9, 3, 3, 3, 7, 4, 8, 0],
        [2, 3, 6, 3, 8, 6, 0, 8, 3, 1],
        [8, 4, 6, 7, 0, 7, 2, 2, 3, 0]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1.,  1., -1., -1.,  1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.],
        [ 1.,  1., -1.,  1.,  1., -1., -1., -1.,  1., -1.],
        [-1.,  1.,  1., -1., -1., -1.,  1.,  1., -1., -1.]])
adv  tensor([[-0.6767,  0.3894, -0.8381, -2.2039, -1.3732, -0.8192, -2.1849, -1.6704,
         -1.1508, -0.5625],
        [-6.5195, -5.5120, -4.7785, -4.1638, -3.3537, -2.8192, -2.1849, -1.6704,
         -1.1508, -0.5625],
        [ 1.1876,  0.2527,  1.0447,  1.7190,  0.5672, -0.8788, -0.2250,  0.3100,
          0.8492, -0.5625],
        [ 3.1680,  2.2527,  1.0447,  1.7190,  0.5672, -0.8788, -0.2250,  0.3100,
          0.8492, -0.5625],
        [ 1.1680,  2.2536,  1.0447, -0.3025,  0.5467,  1.1212,  1.7955,  0.3296,
         -1.1508, -0.5625]], device='cuda:0')
pred_boxes  tensor([[39., 53., 67., 83.],
        [53.,  8., 83., 36.],
        [50., 41., 79., 69.],
        [ 9., 29., 37., 58.],
        [27., 30., 55., 60.]])
target_boxes  tensor([[ 6, 40, 33, 67],
        [ 4, 37, 31, 64],
        [51, 29, 78, 56],
        [29, 35, 56, 62],
        [ 6, 42, 33, 69]], dtype=torch.int32)


Test Epoch: 6 [0/982 (0%)]	Reward: -0.3219
action_seq  tensor([[5, 6, 4, 7, 3, 8, 8, 9, 7, 8],
        [4, 1, 2, 4, 3, 2, 0, 7, 7, 7],
        [1, 4, 0, 1, 8, 9, 9, 9, 5, 6],
        [0, 4, 4, 0, 7, 4, 7, 9, 0, 4],
        [9, 3, 8, 0, 8, 8, 6, 0, 6, 1]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1.,  1., -1.,  1., -1., -1.,  1., -1., -1.],
        [ 1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1., -1., -1.,  1.,  1.,  1., -1., -1.],
        [ 1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1., -1.],
        [-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[-0.4611,  0.3555,  1.1167, -0.2924,  0.3672, -0.9233, -0.3638,  0.3896,
         -0.9954, -0.4688],
        [-2.2463, -3.4677, -2.7456, -4.1938, -3.5732, -2.8833, -2.3443, -1.6104,
         -0.9954, -0.4688],
        [ 3.4236,  2.2579,  1.0181,  1.6275,  2.3076,  3.0571,  1.6362,  0.3896,
         -0.9954, -0.4688],
        [ 5.4402,  4.2959,  3.0757,  1.6871,  2.3672,  1.0972, -0.3443, -1.6104,
         -0.9954, -0.4688],
        [-4.2258, -3.4482, -4.7456, -4.1938, -3.5732, -2.8833, -2.3443, -1.6104,
         -0.9954, -0.4688]], device='cuda:0')
pred_boxes  tensor([[30.,  0., 83., 53.],
        [45., 27., 73., 55.],
        [23., 18., 58., 51.],
        [24., 18., 52., 46.],
        [ 8.,  0., 42., 33.]])
target_boxes  tensor([[22, 52, 49, 79],
        [17, 55, 44, 82],
        [32, 31, 59, 58],
        [25, 15, 52, 42],
        [30, 44, 57, 71]], dtype=torch.int32)
action_seq  tensor([[5, 2, 7, 3, 5, 2, 6, 8, 8, 7],
        [5, 3, 3, 2, 9, 4, 8, 2, 0, 7],
        [4, 5, 9, 1, 8, 4, 7, 6, 9, 9],
        [0, 4, 0, 6, 8, 0, 0, 8, 6, 2],
        [7, 8, 9, 1, 1, 7, 9, 8, 2, 8]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1.,  1., -1.,  1., -1., -1., -1.,  1.],
        [-1.,  1., -1., -1., -1., -1.,  1., -1., -1., -1.],
        [ 1., -1., -1., -1., -1.,  1., -1.,  1., -1., -1.],
        [ 1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1.,  1., -1., -1.,  1., -1.,  1., -1.]])
adv  tensor([[ 1.6239,  2.3652,  1.0010,  1.6733,  0.4602,  1.0951, -0.1879,  0.5361,
          1.1419,  1.4688],
        [-2.1632, -1.4590, -2.8633, -2.2290, -1.4626, -0.8453, -0.1284, -1.4238,
         -0.8386, -0.5312],
        [-0.2599, -1.5576, -0.9414, -0.2886,  0.4983,  1.1342, -0.1479,  0.5762,
         -0.8386, -0.5312],
        [-0.0861, -1.3809, -2.7842, -4.1695, -3.4226, -2.8258, -2.1284, -1.4238,
         -0.8386, -0.5312],
        [-0.3575,  0.3652,  1.0000,  1.6733,  0.4583,  1.0951,  1.8316,  0.5567,
          1.1614, -0.5312]], device='cuda:0')
pred_boxes  tensor([[25., 21., 67., 65.],
        [38., 42., 66., 71.],
        [25., 27., 67., 68.],
        [ 0.,  0., 28., 28.],
        [29.,  1., 72., 43.]])
target_boxes  tensor([[33, 44, 60, 71],
        [17, 27, 44, 54],
        [12, 19, 39, 46],
        [18, 16, 45, 43],
        [ 9, 33, 36, 60]], dtype=torch.int32)
action_seq  tensor([[6, 7, 5, 9, 7, 4, 0, 3, 0, 7],
        [2, 8, 9, 0, 3, 7, 0, 8, 1, 9],
        [7, 4, 2, 3, 7, 6, 2, 4, 8, 6],
        [1, 2, 8, 0, 9, 6, 3, 9, 7, 2],
        [0, 3, 3, 4, 4, 3, 8, 7, 3, 1]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1., -1.,  1.,  1.,  1.,  1., -1.],
        [ 1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1., -1.],
        [-1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.],
        [ 1.,  1.,  1., -1., -1., -1., -1., -1.,  1., -1.],
        [-1.,  1.,  1., -1., -1., -1., -1.,  1., -1., -1.]])
adv  tensor([[ 0.7683,  1.6595,  2.5914,  3.4699,  4.2309,  4.8738,  3.6605,  2.2457,
          0.9736, -0.5000],
        [ 4.7869,  3.6986,  2.6314,  3.5099,  2.2505,  2.8738,  3.6605,  2.2457,
          0.9736, -0.5000],
        [ 2.8259,  3.7386,  2.6705,  1.5294,  2.2719,  2.8943,  1.6605,  0.2252,
          0.9541,  1.5000],
        [ 1.0593, -0.0661, -1.1723, -2.3514, -1.6499, -1.0666, -0.3200,  0.2457,
          0.9736, -0.5000],
        [-0.9221, -0.0475, -1.1528, -2.3329, -1.6304, -1.0471, -0.2995,  0.2652,
         -1.0264, -0.5000]], device='cuda:0')
pred_boxes  tensor([[24., 18., 57., 51.],
        [23., 23., 51., 51.],
        [13., 35., 41., 65.],
        [21., 30., 49., 58.],
        [35., 24., 63., 52.]])
target_boxes  tensor([[17, 28, 44, 55],
        [20, 15, 47, 42],
        [ 2, 45, 29, 72],
        [49, 11, 76, 38],
        [55, 36, 82, 63]], dtype=torch.int32)
action_seq  tensor([[1, 3, 3, 0, 6, 3, 7, 2, 8, 6],
        [0, 3, 6, 9, 8, 1, 0, 7, 3, 2],
        [0, 9, 4, 8, 8, 5, 8, 7, 3, 1],
        [3, 3, 9, 3, 6, 7, 3, 7, 7, 8],
        [9, 4, 6, 3, 6, 1, 9, 9, 3, 8]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1., -1.,  1.,  1., -1.,  1., -1., -1.],
        [-1.,  1.,  1., -1., -1., -1., -1., -1.,  1., -1.],
        [ 1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [-1.,  1., -1.,  1., -1.,  1., -1., -1., -1.,  1.]])
adv  tensor([[-4.8141, -3.7577, -2.9434, -2.3095, -1.5758, -2.8227, -2.1252, -1.5154,
         -1.0258, -0.5625],
        [ 2.9330,  2.0460,  0.8994,  1.5713,  2.3451,  1.1373, -0.1448,  0.4846,
         -1.0258, -0.5625],
        [-0.9488,  0.1466, -1.0205, -2.3876, -1.6549, -0.8822, -0.1653,  0.4651,
          0.9742, -0.5625],
        [-2.8141, -3.7577, -2.9434, -2.3095, -1.5758, -2.8227, -2.1252, -1.5154,
         -1.0258, -0.5625],
        [ 0.9154,  2.0285,  0.8818,  1.5528,  0.3070,  1.0982, -0.1848,  0.4445,
          0.9547,  1.4375]], device='cuda:0')
pred_boxes  tensor([[37., 23., 66., 51.],
        [23., 17., 52., 45.],
        [34., 10., 69., 44.],
        [47., 39., 83., 75.],
        [20., 38., 55., 72.]])
target_boxes  tensor([[ 6, 38, 33, 65],
        [29, 11, 56, 38],
        [32, 53, 59, 80],
        [10, 43, 37, 70],
        [49, 26, 76, 53]], dtype=torch.int32)
action_seq  tensor([[9, 7, 3, 2, 2, 8, 0, 9, 6, 2],
        [3, 1, 8, 7, 3, 6, 2, 7, 4, 2],
        [6, 9, 2, 8, 8, 3, 3, 3, 1, 0],
        [4, 3, 3, 5, 0, 9, 0, 3, 6, 3],
        [2, 3, 3, 7, 8, 7, 3, 4, 4, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1.,  1., -1., -1.,  1., -1., -1., -1., -1.],
        [-1.,  1.,  1., -1., -1.,  1., -1., -1., -1., -1.],
        [-1., -1.,  1., -1., -1.,  1.,  1., -1.,  1., -1.],
        [ 1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [ 1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.]])
adv  tensor([[-2.1043, -1.4941, -0.8466, -2.1179, -1.6336, -0.8613, -2.0065, -1.3638,
         -0.7779, -0.3438],
        [-0.1238,  0.5059, -0.8466, -2.1179, -1.6336, -0.8613, -2.0065, -1.3638,
         -0.7779, -0.3438],
        [ 1.6242,  2.2725,  2.9571,  1.7249,  2.2473,  3.0596,  1.9535,  0.6166,
          1.2221, -0.3438],
        [-2.0457, -3.4551, -2.8270, -2.0974, -1.6140, -2.8613, -2.0065, -1.3638,
         -0.7779, -0.3438],
        [ 5.6613,  4.3301,  3.0167,  1.7835,  0.2863,  1.0791,  1.9740,  0.6362,
         -0.7779, -0.3438]], device='cuda:0')
pred_boxes  tensor([[ 9., 42., 37., 72.],
        [40., 26., 68., 54.],
        [38., 31., 66., 59.],
        [25., 37., 53., 65.],
        [50., 41., 78., 70.]])
target_boxes  tensor([[56, 12, 83, 39],
        [24,  7, 51, 34],
        [37, 16, 64, 43],
        [42,  6, 69, 33],
        [47, 43, 74, 70]], dtype=torch.int32)
action_seq  tensor([[9, 3, 8, 2, 7, 3, 2, 8, 7, 6],
        [8, 2, 6, 6, 8, 7, 3, 9, 5, 3],
        [6, 1, 9, 0, 8, 3, 5, 5, 2, 6],
        [2, 3, 9, 5, 8, 2, 3, 9, 0, 7],
        [0, 9, 3, 7, 9, 2, 4, 8, 2, 6]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1.,  1., -1., -1.,  1., -1., -1.,  1.],
        [-1.,  1., -1., -1., -1., -1., -1.,  1., -1., -1.],
        [-1.,  1., -1.,  1., -1., -1., -1., -1.,  1.,  1.],
        [ 1.,  1., -1., -1., -1., -1.,  1.,  1., -1.,  1.],
        [ 1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[ 1.1404,  1.7834,  0.9176,  1.8102,  0.5978,  1.1721,  1.8149,  0.4442,
          0.9229,  1.5000],
        [-2.6457, -2.0418, -2.9456, -2.0922, -1.3241, -0.7693, -0.1451,  0.4843,
         -1.0576, -0.5000],
        [ 1.1033,  1.7453,  0.8795,  1.7721,  0.5587,  1.1321,  1.7749,  2.4247,
          2.9229,  1.5000],
        [ 3.0643,  1.7063,  0.8395,  1.7311,  2.5382,  3.1321,  3.7954,  2.4442,
          0.9229,  1.5000],
        [-2.5500, -3.9646, -2.8675, -2.0131, -3.2645, -2.7292, -2.1255, -1.5157,
         -1.0576, -0.5000]], device='cuda:0')
pred_boxes  tensor([[35., 25., 69., 61.],
        [36., 35., 79., 79.],
        [19., 20., 53., 54.],
        [26., 43., 54., 72.],
        [21., 42., 49., 71.]])
target_boxes  tensor([[10, 46, 37, 73],
        [ 9, 54, 36, 81],
        [ 8, 39, 35, 66],
        [38, 51, 65, 78],
        [40,  8, 67, 35]], dtype=torch.int32)
action_seq  tensor([[3, 0, 5, 7, 9, 4, 6, 8, 8, 4],
        [4, 3, 3, 8, 8, 6, 1, 1, 0, 7],
        [1, 8, 3, 8, 3, 8, 6, 8, 6, 2],
        [0, 2, 8, 5, 7, 7, 3, 7, 8, 1],
        [1, 8, 6, 2, 9, 5, 3, 9, 9, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1.,  1.,  1.,  1., -1., -1., -1.],
        [ 1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1., -1.,  1., -1., -1., -1.,  1., -1.,  1.,  1.],
        [ 1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.],
        [-1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1.]])
adv  tensor([[ 1.8893e+00,  6.1424e-01,  1.2828e+00,  1.9594e+00,  2.6422e+00,
          1.2487e+00, -1.7395e-03, -1.4223e+00, -1.0579e+00, -4.6875e-01],
        [ 1.2369e-01, -1.1690e+00, -2.5385e+00, -3.9215e+00, -3.2982e+00,
         -2.7317e+00, -2.0017e+00, -1.4223e+00, -1.0579e+00, -4.6875e-01],
        [ 3.6989e+00,  2.4433e+00,  3.1295e+00,  1.8041e+00,  2.4850e+00,
          3.1101e+00,  3.8987e+00,  2.5181e+00,  2.9225e+00,  1.5312e+00],
        [ 5.7731e+00,  4.5381e+00,  3.2252e+00,  1.9018e+00,  2.5826e+00,
          1.1892e+00,  1.9582e+00,  5.5815e-01,  9.4208e-01, -4.6875e-01],
        [ 5.5788e+00,  6.3623e+00,  7.0895e+00,  5.8031e+00,  4.5045e+00,
          3.1296e+00,  3.9192e+00,  2.5376e+00,  9.2255e-01,  1.5312e+00]],
       device='cuda:0')
pred_boxes  tensor([[26., 17., 59., 50.],
        [41., 13., 70., 41.],
        [21.,  8., 56., 43.],
        [46.,  3., 80., 37.],
        [12., 48., 46., 83.]])
target_boxes  tensor([[30, 52, 57, 79],
        [33, 50, 60, 77],
        [23, 26, 50, 53],
        [31, 10, 58, 37],
        [ 6, 51, 33, 78]], dtype=torch.int32)
action_seq  tensor([[1, 9, 3, 6, 5, 2, 3, 3, 7, 1],
        [2, 1, 4, 8, 1, 9, 1, 2, 1, 9],
        [3, 2, 7, 0, 9, 1, 5, 5, 0, 9],
        [3, 2, 6, 7, 3, 3, 7, 8, 9, 5],
        [0, 5, 8, 9, 3, 4, 7, 0, 8, 6]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1., -1.,  1., -1.,  1., -1., -1., -1., -1.],
        [ 1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1., -1.],
        [ 1.,  1., -1.,  1., -1.,  1., -1., -1., -1.,  1.],
        [ 1.,  1., -1.,  1., -1., -1., -1.,  1., -1., -1.],
        [-1., -1., -1.,  1.,  1., -1.,  1., -1., -1., -1.]])
adv  tensor([[ 1.2081,  0.1774, -1.0826, -0.2732, -1.4433, -0.7954, -2.1293, -1.4879,
         -0.8085, -0.4062],
        [ 5.0313,  4.0407,  2.8178,  1.6477,  2.5167,  1.1851, -0.1293, -1.4879,
         -0.8085, -0.4062],
        [ 3.0352,  2.0231,  0.7817,  1.6096,  0.4590,  1.1255, -0.1889,  0.4721,
          1.1719,  1.5938],
        [ 1.1700,  0.1393, -1.1207, -0.3123, -1.4833, -0.8354, -0.1488,  0.5121,
         -0.8085, -0.4062],
        [-0.8710,  0.0993,  0.8578,  1.6877,  0.5362, -0.8149, -0.1293, -1.4879,
         -0.8085, -0.4062]], device='cuda:0')
pred_boxes  tensor([[38., 51., 66., 79.],
        [31., 23., 60., 51.],
        [34., 42., 62., 70.],
        [40., 46., 75., 82.],
        [19., 24., 52., 57.]])
target_boxes  tensor([[14, 44, 41, 71],
        [29, 21, 56, 48],
        [41, 43, 68, 70],
        [40, 22, 67, 49],
        [53, 49, 80, 76]], dtype=torch.int32)
action_seq  tensor([[2, 3, 8, 0, 3, 9, 0, 6, 1, 9],
        [4, 3, 3, 3, 3, 7, 8, 6, 3, 8],
        [0, 7, 9, 0, 9, 2, 8, 8, 8, 8],
        [3, 3, 2, 4, 3, 7, 7, 7, 0, 8],
        [3, 6, 7, 0, 9, 8, 2, 9, 8, 0]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1., -1.,  1., -1.,  1., -1.,  1.],
        [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.],
        [ 1., -1., -1.,  1., -1., -1.,  1.,  1., -1., -1.],
        [ 1.,  1., -1., -1., -1., -1., -1., -1., -1.,  1.],
        [ 1., -1., -1.,  1., -1., -1.,  1., -1.,  1.,  1.]])
adv  tensor([[ 0.2391, -0.7063,  0.0764,  0.9601,  1.7918,  2.4716,  1.2979,  2.1942,
          0.8597,  1.5625],
        [ 6.2323,  5.3484,  4.1712,  3.0773,  1.9090,  0.5712, -0.6230, -1.7658,
         -1.1207, -0.4375],
        [ 0.3329, -0.6105,  0.1731,  1.0577, -0.1311,  0.5311,  1.3574,  0.2342,
         -1.1207, -0.4375],
        [-1.5470, -2.5100, -3.7663, -2.9208, -2.1291, -1.4884, -0.6826,  0.1942,
          0.8597,  1.5625],
        [ 2.1415,  1.2166,  2.0178,  2.9220,  1.7518,  2.4325,  3.2773,  2.1747,
          2.8597,  1.5625]], device='cuda:0')
pred_boxes  tensor([[15., 38., 43., 66.],
        [45., 34., 73., 62.],
        [13.,  0., 54., 42.],
        [54., 43., 82., 72.],
        [15., 24., 48., 58.]])
target_boxes  tensor([[ 2, 56, 29, 83],
        [54, 40, 81, 67],
        [32, 17, 59, 44],
        [42, 27, 69, 54],
        [28, 29, 55, 56]], dtype=torch.int32)
action_seq  tensor([[5, 9, 4, 0, 0, 7, 4, 7, 7, 7],
        [6, 8, 0, 0, 0, 5, 7, 8, 9, 8],
        [0, 3, 2, 8, 3, 3, 8, 0, 2, 2],
        [6, 7, 4, 3, 7, 8, 7, 3, 0, 6],
        [6, 7, 9, 3, 0, 0, 3, 0, 0, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1.,  1.,  1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1.,  1., -1., -1.,  1., -1., -1., -1.],
        [-1., -1., -1.,  1.,  1., -1., -1.,  1., -1., -1.],
        [-1., -1., -1.,  1.,  1.,  1., -1.,  1., -1., -1.]])
adv  tensor([[-2.8443, -1.9886, -1.3140, -2.6219, -3.7216, -2.9384, -2.3683, -1.8242,
         -1.3692, -0.5938],
        [-6.7447, -5.9290, -5.2944, -4.6219, -3.7216, -2.9384, -2.3683, -1.8242,
         -1.3692, -0.5938],
        [ 1.0590, -0.0667, -1.3931, -0.6815, -1.7616, -0.9579, -0.3683, -1.8242,
         -1.3692, -0.5938],
        [-1.0191, -0.1458,  0.5483,  1.2794,  0.2188, -0.9784, -0.3879,  0.1758,
         -1.3692, -0.5938],
        [ 0.8832,  1.7751,  2.4888,  3.2394,  2.1993,  1.0216, -0.3879,  0.1758,
         -1.3692, -0.5938]], device='cuda:0')
pred_boxes  tensor([[38., 12., 70., 44.],
        [ 8.,  0., 49., 41.],
        [27., 22., 55., 51.],
        [33., 20., 67., 54.],
        [24., 24., 52., 52.]])
target_boxes  tensor([[15, 38, 42, 65],
        [37, 55, 64, 82],
        [40,  5, 67, 32],
        [53, 54, 80, 81],
        [21, 16, 48, 43]], dtype=torch.int32)
Test Epoch: 6 [640/982 (62%)]	Reward: -0.3261
action_seq  tensor([[4, 6, 8, 6, 4, 9, 9, 0, 7, 8],
        [2, 7, 8, 4, 3, 3, 7, 4, 6, 4],
        [0, 1, 8, 3, 7, 7, 2, 3, 3, 7],
        [5, 8, 4, 0, 4, 0, 5, 4, 6, 7],
        [7, 9, 7, 8, 9, 3, 9, 0, 9, 1]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1., -1., -1.,  1., -1., -1.,  1., -1.,  1.],
        [-1., -1.,  1.,  1., -1., -1., -1., -1.,  1., -1.],
        [-1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.],
        [-1., -1.,  1.,  1., -1.,  1., -1., -1.,  1., -1.],
        [-1., -1., -1., -1., -1.,  1., -1.,  1., -1.,  1.]])
adv  tensor([[ 3.7035,  2.6988,  1.3375,  2.0137,  2.6970,  1.3979,  1.9810,  2.5371,
          1.0797,  1.4375],
        [-0.1431,  0.8345,  1.4742,  0.1319, -1.2248, -0.5425,  0.0200,  0.5576,
          1.0992, -0.5625],
        [ 5.4487,  6.4820,  7.1793,  7.9141,  6.6375,  5.3784,  3.9810,  2.5371,
          1.0797,  1.4375],
        [ 1.7592,  2.7554,  3.4147,  2.0919,  0.7556,  1.4575,  0.0200,  0.5576,
          1.0992, -0.5625],
        [-0.2955,  0.6792,  1.3180,  1.9932,  2.6775,  3.3979,  1.9810,  2.5371,
          1.0797,  1.4375]], device='cuda:0')
pred_boxes  tensor([[14., 17., 56., 59.],
        [41., 29., 69., 58.],
        [50., 24., 78., 52.],
        [14., 15., 42., 43.],
        [26., 26., 69., 68.]])
target_boxes  tensor([[ 5, 19, 32, 46],
        [39,  4, 66, 31],
        [50, 39, 77, 66],
        [ 1,  8, 28, 35],
        [28, 42, 55, 69]], dtype=torch.int32)
action_seq  tensor([[4, 8, 3, 0, 2, 0, 3, 1, 2, 7],
        [7, 3, 6, 1, 4, 9, 3, 1, 7, 8],
        [2, 4, 1, 4, 7, 7, 9, 4, 7, 0],
        [8, 3, 2, 1, 7, 7, 6, 8, 6, 3],
        [3, 8, 1, 1, 8, 1, 7, 2, 4, 0]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1.,  1.,  1.,  1., -1., -1., -1., -1.],
        [-1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.],
        [ 1.,  1.,  1., -1., -1., -1.,  1., -1., -1., -1.],
        [-1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1., -1.],
        [ 1.,  1.,  1.,  1., -1., -1., -1.,  1., -1., -1.]])
adv  tensor([[ 0.3624, -0.8024,  0.2635,  1.2450,  0.1845, -1.0135, -2.2234, -1.5198,
         -0.8091, -0.3438],
        [ 2.2257,  3.1000,  2.1844,  3.1854,  2.1445,  0.9669, -0.2234, -1.5198,
         -0.8091, -0.3438],
        [ 0.4220, -0.7408, -1.6964, -2.7550, -1.8360, -1.0331, -0.2234, -1.5198,
         -0.8091, -0.3438],
        [ 2.2072,  3.0805,  2.1659,  3.1659,  2.1250,  0.9464, -0.2429,  0.4802,
         -0.8091, -0.3438],
        [ 2.3439,  1.1996,  0.2655, -0.7745, -1.8555, -1.0536, -0.2429,  0.4802,
         -0.8091, -0.3438]], device='cuda:0')
pred_boxes  tensor([[26., 21., 54., 49.],
        [39., 31., 68., 59.],
        [40., 35., 68., 63.],
        [30., 28., 65., 63.],
        [47.,  4., 76., 32.]])
target_boxes  tensor([[ 5, 24, 32, 51],
        [28, 47, 55, 74],
        [18, 42, 45, 69],
        [51, 19, 78, 46],
        [33, 11, 60, 38]], dtype=torch.int32)
action_seq  tensor([[0, 7, 6, 0, 2, 4, 2, 0, 1, 7],
        [3, 3, 3, 2, 7, 2, 8, 7, 7, 8],
        [1, 7, 6, 8, 3, 7, 6, 6, 7, 6],
        [0, 8, 3, 0, 0, 3, 6, 2, 9, 0],
        [3, 7, 6, 8, 0, 7, 7, 2, 0, 7]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1., -1., -1., -1., -1., -1.,  1.],
        [ 1.,  1., -1., -1., -1., -1.,  1., -1., -1.,  1.],
        [ 1., -1., -1., -1., -1.,  1., -1., -1.,  1., -1.],
        [ 1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.],
        [-1., -1.,  1., -1.,  1., -1., -1.,  1.,  1., -1.]])
adv  tensor([[-2.7547, -3.9186, -3.0745, -2.4113, -1.6776, -1.0007, -0.1585,  0.5027,
          1.1398,  1.6875],
        [ 1.1086, -0.0163, -1.1536, -0.4709,  0.2823,  0.9797,  1.8415,  0.5027,
          1.1398,  1.6875],
        [-0.8338, -1.9792, -1.1155, -0.4318,  0.3214,  1.0188, -0.1390,  0.5232,
          1.1593, -0.3125],
        [ 6.8703,  5.8040,  6.7458,  5.4891,  4.2813,  2.9993,  1.8610,  0.5232,
          1.1593, -0.3125],
        [ 1.0090,  1.9036,  2.8064,  1.5096,  2.2813,  0.9787,  1.8415,  2.5232,
          1.1593, -0.3125]], device='cuda:0')
pred_boxes  tensor([[ 9., 18., 37., 47.],
        [55., 42., 83., 71.],
        [ 2., 13., 56., 66.],
        [12., 23., 40., 51.],
        [28., 12., 61., 46.]])
target_boxes  tensor([[34, 46, 61, 73],
        [28, 30, 55, 57],
        [53,  3, 80, 30],
        [15, 22, 42, 49],
        [ 0, 23, 27, 50]], dtype=torch.int32)
action_seq  tensor([[5, 1, 3, 0, 9, 0, 6, 2, 4, 0],
        [2, 0, 8, 3, 3, 8, 8, 4, 0, 3],
        [8, 7, 3, 0, 9, 0, 6, 3, 3, 4],
        [4, 7, 0, 2, 6, 9, 3, 6, 8, 3],
        [1, 4, 8, 1, 9, 1, 8, 2, 2, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1.,  1., -1.,  1.,  1., -1., -1., -1.],
        [ 1.,  1., -1.,  1.,  1.,  1., -1., -1., -1., -1.],
        [-1., -1.,  1.,  1., -1.,  1., -1.,  1., -1., -1.],
        [ 1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.],
        [ 1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1.]])
adv  tensor([[ 0.7815,  1.7356,  0.4592,  1.2526, -0.0599,  0.7606, -0.5581, -1.8579,
         -1.1192, -0.5938],
        [ 2.8195,  1.7737,  0.4983,  1.2927, -0.0198, -1.2199, -2.5581, -1.8579,
         -1.1192, -0.5938],
        [ 0.7424,  1.6966,  2.4407,  1.2331, -0.0794,  0.7401, -0.5776,  0.1421,
         -1.1192, -0.5938],
        [ 2.6281,  1.5813,  2.3235,  3.1355,  1.8425,  2.6815,  1.3823,  0.1020,
          0.8613,  1.4062],
        [-1.0232, -2.1071, -3.4226, -2.6673, -2.0003, -3.2199, -2.5581, -1.8579,
         -1.1192, -0.5938]], device='cuda:0')
pred_boxes  tensor([[22., 26., 50., 54.],
        [21., 12., 49., 40.],
        [21., 40., 49., 68.],
        [14., 32., 42., 61.],
        [40.,  5., 68., 34.]])
target_boxes  tensor([[11,  3, 38, 30],
        [32, 22, 59, 49],
        [22, 33, 49, 60],
        [35, 54, 62, 81],
        [54, 24, 81, 51]], dtype=torch.int32)
action_seq  tensor([[7, 3, 1, 7, 7, 1, 9, 9, 8, 8],
        [7, 7, 1, 7, 9, 9, 4, 7, 8, 6],
        [1, 4, 9, 0, 7, 8, 7, 6, 0, 8],
        [5, 8, 6, 0, 4, 6, 3, 8, 0, 0],
        [5, 7, 8, 0, 6, 9, 7, 4, 3, 6]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1., -1., -1., -1.,  1.,  1., -1., -1.],
        [-1., -1.,  1., -1., -1., -1.,  1., -1.,  1., -1.],
        [ 1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.],
        [-1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.],
        [-1., -1., -1.,  1., -1., -1.,  1., -1., -1., -1.]])
adv  tensor([[-0.4480,  0.1900, -1.2775, -0.6479,  0.3556,  0.7272,  1.3775,  0.1971,
         -1.0865, -0.4545],
        [-0.4871,  0.1519,  0.7030, -0.6665,  0.3361,  0.7077,  1.3570,  0.1776,
          0.9135, -0.4545],
        [ 5.3576,  4.0328,  2.6053,  3.2740,  2.2971,  2.6871,  1.3374,  2.1776,
          0.9135, -0.4545],
        [-4.2927, -3.6928, -3.1798, -2.5688, -1.5848, -1.2328, -0.6030, -1.8029,
         -1.0865, -0.4545],
        [-2.3523, -1.7328, -1.1994, -0.5688, -1.5848, -1.2328, -0.6030, -1.8029,
         -1.0865, -0.4545]], device='cuda:0')
pred_boxes  tensor([[39., 14., 83., 56.],
        [18., 12., 72., 65.],
        [29.,  0., 63., 33.],
        [10.,  7., 38., 35.],
        [20., 29., 63., 72.]])
target_boxes  tensor([[43, 56, 70, 83],
        [48, 13, 75, 40],
        [36, 15, 63, 42],
        [53, 18, 80, 45],
        [45,  0, 72, 27]], dtype=torch.int32)
action_seq  tensor([[6, 4, 1, 4, 6, 4, 3, 7, 7, 8],
        [2, 8, 0, 2, 3, 1, 8, 1, 3, 2],
        [8, 6, 3, 2, 8, 1, 3, 7, 2, 7],
        [6, 7, 3, 2, 3, 8, 8, 0, 8, 5],
        [3, 4, 7, 3, 3, 3, 1, 2, 7, 6]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [-1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.],
        [ 1.,  1., -1., -1., -1., -1., -1., -1., -1.,  1.]])
adv  tensor([[ 3.6658,  4.5914,  3.4260,  2.1275,  0.8159, -0.5501, -2.0506, -1.4653,
         -0.9953, -0.4800],
        [-6.0383, -5.2104, -4.4548, -3.8130, -3.1646, -2.5501, -2.0506, -1.4653,
         -0.9953, -0.4800],
        [-4.1174, -3.2699, -2.4949, -1.8325, -1.1646, -2.5501, -2.0506, -1.4653,
         -0.9953, -0.4800],
        [ 3.4168,  4.3404,  5.1916,  3.9107,  4.6371,  5.3308,  3.8898,  2.5152,
          1.0047, -0.4800],
        [-0.2307, -1.3647, -2.5906, -1.9302, -1.2623, -0.6292, -0.1102,  0.4946,
          0.9852,  1.5200]], device='cuda:0')
pred_boxes  tensor([[35., 15., 64., 43.],
        [13., 14., 41., 43.],
        [46., 33., 74., 61.],
        [26., 14., 60., 49.],
        [49., 47., 77., 75.]])
target_boxes  tensor([[19, 30, 46, 57],
        [55, 54, 82, 81],
        [ 1,  4, 28, 31],
        [39, 11, 66, 38],
        [28, 23, 55, 50]], dtype=torch.int32)


Train Epoch: 7 [0/50 (0%)]	Reward: -0.3720
action_seq  tensor([[9, 7, 0, 0, 2, 8, 7, 3, 8, 3],
        [9, 0, 1, 3, 7, 3, 8, 7, 8, 9],
        [5, 8, 2, 4, 7, 5, 4, 7, 8, 7],
        [4, 3, 8, 2, 2, 1, 1, 6, 9, 3],
        [9, 5, 0, 4, 7, 7, 3, 7, 3, 9]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1.,  1., -1.,  1., -1., -1., -1., -1., -1.],
        [-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1.,  1., -1., -1.,  1., -1.,  1.],
        [ 1.,  1., -1.,  1.,  1., -1., -1., -1.,  1., -1.],
        [-1., -1.,  1.,  1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[-2.1977, -1.3036, -0.4019, -1.6994, -0.9595, -2.4211, -1.8143, -1.3591,
         -0.9942, -0.5938],
        [-4.0981, -3.2245, -4.3618, -3.6798, -2.9595, -2.4211, -1.8143, -1.3591,
         -0.9942, -0.5938],
        [-0.4663,  0.4444,  1.3647,  2.1044,  2.8832,  1.4598,  2.1066,  2.6008,
          0.9863,  1.4062],
        [ 3.6089,  2.5401,  1.4614,  2.2030,  0.9614, -0.4807,  0.1457,  0.6213,
          1.0058, -0.5938],
        [-2.1782, -1.2841, -0.3814, -1.6798, -2.9595, -2.4211, -1.8143, -1.3591,
         -0.9942, -0.5938]], device='cuda:0')
pred_boxes  tensor([[21.,  7., 49., 36.],
        [46., 10., 81., 44.],
        [37., 18., 79., 61.],
        [20., 33., 48., 62.],
        [48., 31., 83., 66.]])
target_boxes  tensor([[ 6, 40, 33, 67],
        [ 4, 37, 31, 64],
        [51, 29, 78, 56],
        [29, 35, 56, 62],
        [ 6, 42, 33, 69]], dtype=torch.int32)


Test Epoch: 7 [0/982 (0%)]	Reward: -0.3688
action_seq  tensor([[7, 7, 8, 2, 7, 9, 6, 8, 3, 3],
        [5, 0, 8, 8, 2, 8, 7, 9, 8, 3],
        [2, 1, 0, 7, 5, 7, 8, 1, 1, 7],
        [9, 6, 4, 0, 2, 7, 4, 8, 0, 2],
        [7, 8, 8, 8, 3, 8, 9, 7, 8, 6]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1.,  1., -1., -1., -1., -1.,  1.,  1.],
        [-1., -1., -1., -1.,  1., -1., -1.,  1., -1., -1.],
        [ 1.,  1.,  1.,  1., -1., -1., -1., -1., -1., -1.],
        [-1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],
        [-1., -1., -1., -1.,  1., -1.,  1., -1., -1., -1.]])
adv  tensor([[-1.0165, -0.1430,  0.6136,  1.4087,  0.1917,  0.9192,  1.6230,  2.2712,
          2.7363,  1.4062],
        [-2.8446, -1.9896, -1.2516, -0.4751,  0.3089, -0.9821, -0.2969,  0.3308,
         -1.2442, -0.5938],
        [ 1.2511,  0.1275, -1.1335, -2.3765, -3.6315, -2.9421, -2.2774, -1.6692,
         -1.2442, -0.5938],
        [ 6.6866,  7.6383,  8.4730,  7.3276,  6.1702,  4.9388,  3.6630,  2.3113,
          0.7558, -0.5938],
        [-2.8260, -1.9701, -1.2331, -0.4556,  0.3284, -0.9616, -0.2774, -1.6692,
         -1.2442, -0.5938]], device='cuda:0')
pred_boxes  tensor([[23., 25., 66., 69.],
        [20., 11., 62., 54.],
        [47.,  7., 76., 35.],
        [20., 15., 48., 43.],
        [ 2.,  1., 69., 68.]])
target_boxes  tensor([[22, 52, 49, 79],
        [17, 55, 44, 82],
        [32, 31, 59, 58],
        [25, 15, 52, 42],
        [30, 44, 57, 71]], dtype=torch.int32)
action_seq  tensor([[3, 5, 9, 9, 8, 9, 8, 7, 3, 9],
        [9, 6, 2, 3, 0, 3, 4, 2, 9, 0],
        [6, 7, 7, 0, 9, 9, 0, 1, 2, 8],
        [7, 3, 8, 0, 8, 0, 4, 8, 8, 3],
        [3, 2, 1, 9, 6, 4, 7, 8, 6, 8]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1., -1.,  1., -1., -1.,  1.,  1.],
        [-1., -1.,  1.,  1.,  1., -1., -1., -1., -1., -1.],
        [-1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.],
        [-1.,  1., -1.,  1., -1.,  1.,  1., -1., -1., -1.],
        [ 1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.]])
adv  tensor([[ 1.3993,  0.1817,  0.9094,  1.6132,  2.3877,  2.9158,  1.5249,  2.3931,
          2.8910,  1.5625],
        [-0.3546,  0.4317,  1.1624, -0.1514, -1.4160, -2.9455, -2.3755, -1.5473,
         -1.0895, -0.4375],
        [ 3.1844,  4.0059,  4.7727,  5.5146,  4.3076,  4.8562,  5.5054,  4.3931,
          2.8910,  1.5625],
        [ 1.5301,  2.3340,  1.0637,  1.7685,  0.5244,  1.0349, -0.3755, -1.5473,
         -1.0895, -0.4375],
        [ 5.2626,  4.0840,  2.8313,  3.5546,  4.3476,  2.8758,  3.5054,  4.3931,
          2.8910,  1.5625]], device='cuda:0')
pred_boxes  tensor([[29., 24., 83., 78.],
        [24., 45., 52., 73.],
        [10., 18., 43., 51.],
        [25.,  4., 53., 33.],
        [20., 27., 54., 61.]])
target_boxes  tensor([[33, 44, 60, 71],
        [17, 27, 44, 54],
        [12, 19, 39, 46],
        [18, 16, 45, 43],
        [ 9, 33, 36, 60]], dtype=torch.int32)
action_seq  tensor([[2, 8, 3, 0, 6, 2, 3, 1, 8, 3],
        [3, 2, 4, 7, 3, 8, 8, 9, 8, 8],
        [3, 3, 6, 4, 6, 3, 2, 2, 8, 7],
        [3, 3, 0, 8, 9, 4, 2, 7, 0, 8],
        [1, 0, 9, 7, 5, 8, 2, 9, 3, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1.,  1.,  1., -1., -1.,  1., -1., -1., -1.],
        [ 1., -1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.],
        [-1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.],
        [ 1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,  1.],
        [ 1., -1.,  1.,  1., -1., -1., -1.,  1.,  1., -1.]])
adv  tensor([[ 1.9410,  0.7307,  1.2428, -0.0076, -1.4598, -0.8425, -0.2834, -1.5804,
         -0.8389, -0.5000],
        [ 3.6158,  2.4211,  2.9498,  3.7376,  4.3439,  5.0188,  3.6170,  2.3600,
          3.1416,  1.5000],
        [ 1.7672,  2.5754,  3.1051,  1.8753,  2.4611,  1.0979,  1.6766,  0.4001,
          1.1611, -0.5000],
        [ 3.7496,  2.5568,  3.0885,  1.8557,  0.4230,  1.0579,  1.6375,  2.3796,
          1.1416,  1.5000],
        [ 3.7682,  2.5754,  3.1070,  1.8753,  0.4416,  1.0774,  1.6570,  2.4001,
          1.1611, -0.5000]], device='cuda:0')
pred_boxes  tensor([[ 9., 22., 37., 52.],
        [37., 21., 71., 56.],
        [27., 43., 55., 71.],
        [38., 32., 66., 60.],
        [34., 32., 62., 60.]])
target_boxes  tensor([[17, 28, 44, 55],
        [20, 15, 47, 42],
        [ 2, 45, 29, 72],
        [49, 11, 76, 38],
        [55, 36, 82, 63]], dtype=torch.int32)
action_seq  tensor([[4, 0, 2, 6, 7, 1, 0, 2, 4, 3],
        [7, 7, 6, 7, 8, 7, 1, 3, 9, 1],
        [8, 2, 8, 3, 8, 8, 7, 1, 7, 9],
        [9, 0, 2, 3, 7, 8, 3, 2, 4, 9],
        [3, 8, 6, 7, 3, 7, 7, 9, 7, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1.,  1.,  1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1.],
        [-1.,  1., -1.,  1., -1., -1., -1., -1., -1., -1.],
        [-1.,  1.,  1.,  1., -1., -1., -1.,  1., -1.,  1.],
        [ 1., -1., -1.,  1.,  1., -1., -1., -1., -1., -1.]])
adv  tensor([[ 1.9744,  0.7003, -0.6497, -2.0140, -3.3285, -2.6360, -2.0630, -1.6105,
         -1.0585, -0.4062],
        [-2.1594, -1.4549, -0.8069, -0.1527,  0.5719,  1.3044,  1.9174,  0.3895,
         -1.0585, -0.4062],
        [-1.9856, -1.2801, -2.6497, -2.0140, -3.3285, -2.6360, -2.0630, -1.6105,
         -1.0585, -0.4062],
        [ 3.6658,  4.4289,  3.1169,  1.7897,  0.5143,  1.2448,  1.8579,  2.3495,
          0.9219,  1.5938],
        [-0.0452, -1.3397, -0.6897, -0.0336, -1.3285, -2.6360, -2.0630, -1.6105,
         -1.0585, -0.4062]], device='cuda:0')
pred_boxes  tensor([[16., 18., 44., 46.],
        [39., 23., 83., 65.],
        [40.,  8., 83., 51.],
        [26., 33., 54., 62.],
        [29., 35., 72., 79.]])
target_boxes  tensor([[ 6, 38, 33, 65],
        [29, 11, 56, 38],
        [32, 53, 59, 80],
        [10, 43, 37, 70],
        [49, 26, 76, 53]], dtype=torch.int32)
action_seq  tensor([[8, 7, 2, 8, 1, 7, 6, 7, 9, 9],
        [3, 3, 8, 0, 3, 9, 5, 2, 6, 7],
        [6, 5, 3, 4, 9, 7, 7, 8, 4, 0],
        [8, 7, 9, 5, 3, 8, 0, 3, 2, 3],
        [3, 8, 6, 8, 1, 4, 6, 8, 6, 5]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1.,  1.,  1.,  1., -1.,  1., -1., -1.],
        [-1., -1.,  1.,  1., -1., -1., -1., -1., -1., -1.],
        [-1., -1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.],
        [-1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1.],
        [ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[ 1.0189,  1.8805,  2.5638,  3.5993,  2.3418,  1.1339, -0.1166,  0.5130,
         -0.9338, -0.3750],
        [-2.7086, -1.8831, -1.2389, -2.2621, -3.5791, -2.8260, -2.0971, -1.4870,
         -0.9338, -0.3750],
        [ 2.8285,  3.7096,  4.4105,  3.4440,  2.1846,  2.9952,  3.7838,  4.4534,
          3.0466,  1.6250],
        [-0.9596, -0.1175,  0.5443,  1.5592,  2.3018,  3.1144,  1.8834,  0.5130,
         -0.9338, -0.3750],
        [-4.6090, -5.8236, -5.2194, -4.2621, -3.5791, -2.8260, -2.0971, -1.4870,
         -0.9338, -0.3750]], device='cuda:0')
pred_boxes  tensor([[22., 22., 75., 75.],
        [36., 40., 64., 68.],
        [34., 23., 68., 57.],
        [32., 26., 60., 55.],
        [ 2.,  0., 45., 42.]])
target_boxes  tensor([[56, 12, 83, 39],
        [24,  7, 51, 34],
        [37, 16, 64, 43],
        [42,  6, 69, 33],
        [47, 43, 74, 70]], dtype=torch.int32)
action_seq  tensor([[8, 9, 1, 1, 2, 9, 8, 5, 2, 9],
        [1, 4, 6, 8, 1, 9, 0, 9, 4, 4],
        [5, 9, 4, 6, 0, 2, 9, 7, 4, 8],
        [7, 4, 8, 4, 3, 8, 4, 1, 3, 1],
        [9, 0, 4, 8, 8, 9, 7, 3, 1, 4]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.],
        [-1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.],
        [-1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [-1.,  1.,  1., -1., -1., -1.,  1., -1.,  1., -1.]])
adv  tensor([[ 1.1028,  1.9657,  2.7430,  3.4659,  4.2271,  3.0693,  1.7430,  2.3925,
          2.9219,  1.5938],
        [-4.4333, -3.6251, -2.9045, -4.2597, -3.5766, -2.7920, -2.1574, -1.5480,
         -1.0585, -0.4062],
        [ 3.1184,  4.0029,  4.7996,  3.5235,  4.2847,  3.1289,  1.8026,  0.4325,
          0.9415, -0.4062],
        [-2.4919, -1.6651, -2.9445, -2.2792, -1.5766, -2.7920, -2.1574, -1.5480,
         -1.0585, -0.4062],
        [ 1.2757,  2.1415,  0.8992, -0.4169,  0.3042,  1.1289,  1.8026,  0.4325,
          0.9415, -0.4062]], device='cuda:0')
pred_boxes  tensor([[29., 23., 63., 57.],
        [23., 16., 53., 44.],
        [12., 23., 44., 56.],
        [34., 11., 62., 39.],
        [37., 23., 65., 51.]])
target_boxes  tensor([[10, 46, 37, 73],
        [ 9, 54, 36, 81],
        [ 8, 39, 35, 66],
        [38, 51, 65, 78],
        [40,  8, 67, 35]], dtype=torch.int32)
action_seq  tensor([[5, 8, 2, 9, 8, 8, 1, 8, 8, 8],
        [1, 8, 6, 7, 9, 8, 7, 3, 3, 9],
        [6, 7, 1, 2, 9, 9, 4, 0, 4, 7],
        [3, 2, 8, 3, 3, 1, 1, 8, 4, 0],
        [2, 8, 7, 0, 2, 3, 5, 0, 6, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.],
        [-1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1.],
        [ 1., -1.,  1., -1., -1., -1., -1.,  1., -1., -1.],
        [ 1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.]])
adv  tensor([[-4.3743, -3.5655, -2.9705, -4.2001, -3.5796, -2.9214, -2.1933, -1.3633,
         -0.8719, -0.3125],
        [ 1.1238,  1.9872,  2.6388,  3.4864,  4.1840,  2.8999,  3.6876,  4.5772,
          3.1085,  1.6875],
        [ 3.1589,  4.0438,  4.7160,  3.5636,  2.2417,  2.9595,  3.7471,  2.6172,
          1.1281, -0.3125],
        [-0.5100, -1.6827, -1.0682, -2.2792, -1.6392, -0.9614, -0.2128,  0.6367,
         -0.8719, -0.3125],
        [-2.4133, -3.6056, -3.0106, -2.2196, -1.5796, -2.9214, -2.1933, -1.3633,
         -0.8719, -0.3125]], device='cuda:0')
pred_boxes  tensor([[13.,  0., 66., 53.],
        [39., 31., 83., 74.],
        [28., 37., 56., 65.],
        [41., 30., 69., 58.],
        [15., 20., 43., 49.]])
target_boxes  tensor([[30, 52, 57, 79],
        [33, 50, 60, 77],
        [23, 26, 50, 53],
        [31, 10, 58, 37],
        [ 6, 51, 33, 78]], dtype=torch.int32)
action_seq  tensor([[6, 7, 0, 9, 3, 4, 6, 6, 8, 8],
        [8, 7, 3, 3, 7, 7, 4, 0, 0, 3],
        [2, 1, 6, 7, 2, 3, 6, 6, 3, 8],
        [9, 1, 3, 3, 8, 8, 5, 2, 3, 8],
        [2, 4, 3, 6, 8, 7, 8, 4, 0, 8]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.],
        [-1., -1.,  1.,  1., -1., -1., -1.,  1.,  1., -1.],
        [ 1.,  1., -1.,  1., -1.,  1., -1., -1., -1., -1.],
        [-1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.],
        [-1., -1.,  1., -1., -1.,  1., -1., -1., -1., -1.]])
adv  tensor([[ 3.0258,  3.7516,  4.7044,  3.6476,  2.6113,  1.2176, -0.0334, -1.5804,
         -0.9020, -0.4375],
        [ 1.0297,  1.7350,  2.6683,  1.5900,  0.5322,  1.1375,  1.9071,  2.4001,
          1.0980, -0.4375],
        [ 1.2426, -0.0717, -1.1765, -0.2733, -1.3487, -0.7629, -2.0334, -1.5804,
         -0.9020, -0.4375],
        [ 4.9311,  5.6754,  4.6282,  3.5704,  2.5322,  1.1375,  1.9071,  2.4001,
          1.0980, -0.4375],
        [-2.7183, -2.0512, -1.1569, -2.2733, -1.3487, -0.7629, -2.0334, -1.5804,
         -0.9020, -0.4375]], device='cuda:0')
pred_boxes  tensor([[ 0., 13., 42., 55.],
        [34., 34., 62., 62.],
        [12., 34., 40., 63.],
        [46., 14., 74., 42.],
        [19., 12., 47., 40.]])
target_boxes  tensor([[14, 44, 41, 71],
        [29, 21, 56, 48],
        [41, 43, 68, 70],
        [40, 22, 67, 49],
        [53, 49, 80, 76]], dtype=torch.int32)
action_seq  tensor([[2, 0, 3, 3, 9, 1, 6, 6, 3, 8],
        [8, 9, 8, 2, 3, 0, 1, 0, 9, 6],
        [4, 8, 4, 6, 9, 3, 6, 9, 8, 8],
        [2, 9, 0, 9, 7, 7, 9, 8, 7, 8],
        [7, 6, 2, 3, 3, 3, 3, 9, 1, 6]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1.,  1., -1.,  1.,  1., -1., -1.],
        [-1., -1., -1., -1.,  1., -1.,  1., -1., -1., -1.],
        [ 1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.],
        [ 1., -1., -1., -1.,  1.,  1., -1.,  1., -1., -1.],
        [-1., -1.,  1.,  1., -1., -1., -1., -1., -1.,  1.]])
adv  tensor([[ 1.2738, -0.0072,  0.5607,  1.1664,  1.9985,  0.6936,  1.2374, -0.0133,
         -1.2130, -0.5938],
        [-2.5905, -1.8900, -1.3416, -0.7545,  0.0581, -1.2663, -0.7431, -2.0133,
         -1.2130, -0.5938],
        [ 1.2386, -0.0423,  0.5246, -0.8902, -0.0786,  0.6145,  1.1573,  1.9272,
          2.7675,  1.4062],
        [ 1.2933,  0.0114,  0.5803,  1.1860,  2.0190,  0.7132, -0.7626, -0.0133,
         -1.2130, -0.5938],
        [-0.6666,  0.0534,  0.6223, -0.7926, -1.9995, -1.3259, -0.8027, -0.0533,
          0.7675,  1.4062]], device='cuda:0')
pred_boxes  tensor([[12., 35., 40., 63.],
        [15., 34., 43., 62.],
        [ 4., 16., 47., 59.],
        [30.,  8., 82., 61.],
        [32., 54., 60., 83.]])
target_boxes  tensor([[ 2, 56, 29, 83],
        [54, 40, 81, 67],
        [32, 17, 59, 44],
        [42, 27, 69, 54],
        [28, 29, 55, 56]], dtype=torch.int32)
action_seq  tensor([[7, 4, 8, 1, 2, 4, 9, 8, 9, 9],
        [5, 4, 3, 7, 2, 8, 0, 9, 7, 4],
        [3, 3, 0, 8, 1, 3, 4, 9, 1, 9],
        [2, 5, 5, 8, 0, 7, 7, 8, 7, 4],
        [2, 8, 3, 0, 6, 6, 6, 3, 9, 9]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1., -1.,  1., -1.,  1., -1.,  1.,  1.],
        [-1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1., -1.],
        [-1., -1.,  1.,  1.,  1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1.,  1.,  1., -1., -1., -1.],
        [ 1., -1.,  1.,  1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[ 2.9496,  3.8004,  2.6698,  3.3292,  4.0249,  2.7401,  3.5564,  2.2988,
          2.9850,  1.5312],
        [ 3.0638,  3.9156,  2.7870,  1.4268,  2.1030,  0.7987,  1.5964,  2.3388,
          1.0046, -0.4688],
        [-0.6862,  0.1285,  0.9823, -0.3964, -1.7583, -3.1017, -2.3440, -1.6417,
         -0.9954, -0.4688],
        [-2.7223, -1.9291, -1.0968, -0.4765,  0.1821,  0.8787, -0.3440, -1.6417,
         -0.9954, -0.4688],
        [-0.6071, -1.8119, -0.9777, -2.3769, -3.7583, -3.1017, -2.3440, -1.6417,
         -0.9954, -0.4688]], device='cuda:0')
pred_boxes  tensor([[25., 25., 58., 58.],
        [38., 30., 66., 59.],
        [43., 36., 72., 64.],
        [35.,  5., 76., 47.],
        [ 8., 37., 42., 72.]])
target_boxes  tensor([[15, 38, 42, 65],
        [37, 55, 64, 82],
        [40,  5, 67, 32],
        [53, 54, 80, 81],
        [21, 16, 48, 43]], dtype=torch.int32)
Test Epoch: 7 [640/982 (62%)]	Reward: -0.3423
action_seq  tensor([[1, 6, 8, 0, 9, 0, 1, 9, 0, 2],
        [0, 8, 8, 8, 8, 5, 1, 7, 0, 8],
        [3, 7, 4, 6, 8, 7, 8, 0, 9, 7],
        [2, 1, 0, 8, 1, 5, 9, 4, 9, 8],
        [2, 5, 9, 0, 1, 3, 8, 0, 7, 4]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.],
        [ 1., -1., -1., -1., -1., -1.,  1., -1.,  1., -1.],
        [ 1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.],
        [ 1., -1.,  1.,  1., -1., -1., -1., -1., -1.,  1.],
        [ 1., -1., -1.,  1., -1.,  1., -1., -1.,  1., -1.]])
adv  tensor([[ 2.9734,  4.0119,  2.7278,  3.5755,  2.5384,  3.1003,  1.8696,  2.7095,
          1.3474, -0.3750],
        [-0.8313, -1.8494, -1.1746, -0.3649,  0.5775,  1.1208,  1.8891,  0.7095,
          1.3474, -0.3750],
        [ 2.9753,  1.9953,  2.7092,  1.5374,  2.5004,  3.0612,  1.8295,  2.6694,
          3.3279,  1.6250],
        [ 1.1677,  0.1701,  0.8664, -0.3249, -1.4010, -0.8792, -0.1304,  0.6890,
          1.3279,  1.6250],
        [ 1.1286,  0.1291,  0.8254,  1.6546,  0.5980,  1.1403, -0.1109,  0.7095,
          1.3474, -0.3750]], device='cuda:0')
pred_boxes  tensor([[10., 16., 39., 44.],
        [23.,  0., 65., 41.],
        [29.,  8., 72., 51.],
        [23., 14., 52., 42.],
        [23., 17., 51., 45.]])
target_boxes  tensor([[ 5, 19, 32, 46],
        [39,  4, 66, 31],
        [50, 39, 77, 66],
        [ 1,  8, 28, 35],
        [28, 42, 55, 69]], dtype=torch.int32)
action_seq  tensor([[4, 7, 6, 8, 7, 8, 8, 8, 8, 7],
        [4, 8, 9, 2, 8, 9, 1, 1, 3, 4],
        [1, 9, 8, 8, 7, 3, 7, 8, 0, 7],
        [0, 4, 8, 8, 0, 8, 7, 7, 0, 3],
        [1, 8, 5, 0, 7, 7, 7, 7, 0, 9]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.],
        [ 1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1., -1.,  1.,  1., -1.,  1.],
        [ 1., -1., -1.,  1., -1., -1., -1., -1.,  1., -1.]])
adv  tensor([[-2.8200, -3.9526, -3.3616, -4.5318, -3.8201, -3.2274, -2.4077, -1.5482,
         -0.9642, -0.4688],
        [ 4.7513,  3.6948,  4.3630,  3.2709,  2.0412,  2.6935,  1.5522,  0.4322,
          1.0358, -0.4688],
        [-2.7995, -3.9331, -5.3616, -4.5318, -3.8201, -3.2274, -2.4077, -1.5482,
         -0.9642, -0.4688],
        [-1.2057, -0.3022,  0.3259,  1.2123,  1.9826,  2.6339,  3.5132,  2.4117,
          1.0163,  1.5312],
        [-0.9938, -2.1089, -1.4983, -0.6295, -1.8992, -1.2870, -0.4478,  0.4322,
          1.0358, -0.4688]], device='cuda:0')
pred_boxes  tensor([[17.,  0., 83., 66.],
        [31., 30., 60., 58.],
        [37.,  2., 80., 44.],
        [27.,  4., 55., 33.],
        [30.,  8., 72., 49.]])
target_boxes  tensor([[ 5, 24, 32, 51],
        [28, 47, 55, 74],
        [18, 42, 45, 69],
        [51, 19, 78, 46],
        [33, 11, 60, 38]], dtype=torch.int32)
action_seq  tensor([[3, 2, 7, 4, 9, 4, 0, 1, 4, 2],
        [8, 4, 9, 7, 7, 9, 0, 8, 0, 8],
        [6, 0, 8, 7, 5, 3, 1, 0, 6, 4],
        [0, 6, 3, 3, 0, 6, 4, 1, 8, 0],
        [1, 0, 4, 3, 6, 4, 5, 8, 1, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1., -1.,  1., -1.,  1.,  1., -1., -1., -1.],
        [-1.,  1., -1., -1., -1., -1.,  1., -1., -1., -1.],
        [-1., -1., -1.,  1., -1., -1.,  1., -1., -1., -1.],
        [ 1., -1.,  1., -1.,  1.,  1., -1., -1.,  1., -1.],
        [-1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1.]])
adv  tensor([[ 2.9208,  1.8764,  0.6014,  1.3962,  0.3062,  1.1303, -0.2477, -1.7023,
         -1.1514, -0.5000],
        [-2.9219, -2.0044, -3.3195, -2.5638, -1.6743, -0.8697, -0.2477, -1.7023,
         -1.1514, -0.5000],
        [-2.9620, -2.0445, -1.3391, -0.5638, -1.6743, -0.8697, -0.2477, -1.7023,
         -1.1514, -0.5000],
        [ 2.8437,  1.7993,  2.5428,  1.3386,  2.2671,  1.0903, -0.2878,  0.2781,
          0.8486, -0.5000],
        [-2.8839, -1.9663, -3.2805, -2.5237, -1.6343, -2.8502, -2.2477, -1.7023,
         -1.1514, -0.5000]], device='cuda:0')
pred_boxes  tensor([[35., 44., 63., 72.],
        [17.,  0., 58., 41.],
        [31., 15., 60., 43.],
        [19., 20., 47., 48.],
        [24.,  9., 53., 37.]])
target_boxes  tensor([[34, 46, 61, 73],
        [28, 30, 55, 57],
        [53,  3, 80, 30],
        [15, 22, 42, 49],
        [ 0, 23, 27, 50]], dtype=torch.int32)
action_seq  tensor([[1, 7, 4, 2, 0, 8, 9, 2, 8, 9],
        [2, 3, 2, 8, 8, 9, 6, 7, 7, 3],
        [1, 3, 8, 1, 7, 2, 7, 8, 3, 8],
        [4, 7, 3, 7, 6, 3, 6, 2, 3, 3],
        [1, 3, 3, 4, 7, 4, 5, 8, 0, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1.,  1.,  1., -1., -1.,  1., -1.],
        [ 1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.],
        [ 1.,  1., -1., -1., -1.,  1., -1., -1., -1., -1.],
        [ 1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1.],
        [ 1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.]])
adv  tensor([[ 0.9496, -0.1462,  0.7676,  1.5342,  2.2121,  0.7505, -0.5994,  0.1844,
          0.8802, -0.5312],
        [ 4.8324,  3.7757,  2.7100,  3.4951,  2.1720,  0.7105,  1.3811,  2.1844,
          0.8802, -0.5312],
        [-0.8366, -1.9509, -3.0752, -2.3486, -1.7088, -1.1899, -2.5593, -1.7961,
         -1.1198, -0.5312],
        [ 0.9886, -0.1062,  0.8076, -0.4463,  0.2121,  0.7505, -0.5994,  0.1844,
          0.8802, -0.5312],
        [ 6.8490,  5.8128,  4.7676,  3.5527,  2.2316,  0.7701, -0.5789,  0.2039,
         -1.1198, -0.5312]], device='cuda:0')
pred_boxes  tensor([[22., 20., 50., 48.],
        [28., 37., 62., 73.],
        [52.,  3., 81., 31.],
        [26., 45., 54., 74.],
        [51., 24., 79., 52.]])
target_boxes  tensor([[11,  3, 38, 30],
        [32, 22, 59, 49],
        [22, 33, 49, 60],
        [35, 54, 62, 81],
        [54, 24, 81, 51]], dtype=torch.int32)
action_seq  tensor([[8, 9, 3, 7, 8, 1, 7, 2, 1, 6],
        [9, 2, 1, 8, 7, 7, 4, 4, 2, 9],
        [7, 1, 4, 0, 4, 4, 3, 3, 4, 0],
        [6, 8, 9, 7, 6, 0, 3, 3, 8, 7],
        [6, 6, 2, 2, 3, 8, 1, 1, 3, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.],
        [-1.,  1.,  1.,  1.,  1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.],
        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[-5.1983, -4.5158, -3.8270, -4.6921, -3.6375, -3.0315, -2.6029, -1.6192,
         -1.1765, -0.5455],
        [ 2.4101,  3.1698,  3.9367,  3.1497,  2.2629,  0.9089,  1.3775,  0.3808,
         -1.1765, -0.5455],
        [ 0.6435,  1.3846,  0.1134, -0.7116, -1.6375, -3.0315, -2.6029, -1.6192,
         -1.1765, -0.5455],
        [ 0.2617,  0.9989,  1.7433,  2.9544,  4.0862,  4.7702,  5.2779,  4.3212,
          2.8040,  1.4545],
        [-7.1582, -6.4962, -5.8270, -4.6921, -3.6375, -3.0315, -2.6029, -1.6192,
         -1.1765, -0.5455]], device='cuda:0')
pred_boxes  tensor([[30., 12., 65., 46.],
        [39., 24., 67., 52.],
        [28., 12., 57., 40.],
        [31., 14., 74., 57.],
        [24., 30., 52., 58.]])
target_boxes  tensor([[43, 56, 70, 83],
        [48, 13, 75, 40],
        [36, 15, 63, 42],
        [53, 18, 80, 45],
        [45,  0, 72, 27]], dtype=torch.int32)
action_seq  tensor([[0, 6, 7, 7, 5, 7, 7, 0, 4, 8],
        [0, 6, 9, 2, 8, 8, 9, 2, 9, 1],
        [6, 3, 2, 7, 1, 7, 9, 6, 7, 9],
        [2, 6, 6, 9, 8, 8, 8, 0, 8, 2],
        [4, 3, 6, 9, 3, 1, 2, 4, 8, 8]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1.],
        [ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1., -1.,  1., -1., -1., -1., -1., -1., -1.,  1.]])
adv  tensor([[-6.5199, -5.7372, -5.1083, -4.3921, -3.6285, -3.1397, -2.4039, -1.8221,
         -1.1941, -0.6000],
        [-6.5199, -5.7372, -5.1083, -4.3921, -3.6285, -3.1397, -2.4039, -1.8221,
         -1.1941, -0.6000],
        [ 4.8590,  5.7560,  4.4806,  5.2935,  4.1352,  4.7021,  3.4965,  2.1183,
          2.7863,  1.4000],
        [-4.5199, -5.7372, -5.1083, -4.3921, -3.6285, -3.1397, -2.4039, -1.8221,
         -1.1941, -0.6000],
        [-0.7328, -1.9110, -1.2440, -2.5093, -1.7261, -1.2188, -0.4634,  0.1378,
          0.7863,  1.4000]], device='cuda:0')
pred_boxes  tensor([[22.,  0., 63., 41.],
        [ 8., 32., 41., 66.],
        [39., 40., 82., 83.],
        [ 0., 10., 41., 53.],
        [28., 34., 56., 62.]])
target_boxes  tensor([[12, 52, 39, 79],
        [56, 36, 83, 63],
        [55, 54, 82, 81],
        [ 1, 56, 28, 83],
        [14,  9, 41, 36]], dtype=torch.int32)


Train Epoch: 8 [0/50 (0%)]	Reward: -0.3200
action_seq  tensor([[3, 1, 7, 1, 3, 1, 3, 4, 6, 8],
        [7, 8, 4, 9, 8, 9, 7, 6, 7, 9],
        [3, 7, 8, 8, 9, 8, 5, 7, 1, 3],
        [6, 3, 3, 8, 8, 4, 7, 9, 8, 0],
        [4, 7, 2, 7, 2, 3, 9, 0, 0, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1.,  1., -1., -1., -1., -1.,  1., -1., -1.],
        [ 1., -1., -1., -1., -1., -1., -1., -1.,  1.,  1.],
        [-1.,  1.,  1., -1., -1., -1., -1.,  1., -1., -1.],
        [ 1., -1.,  1., -1.,  1., -1., -1., -1., -1., -1.]])
adv  tensor([[-6.7476, -5.8372, -4.7597, -3.9871, -3.2066, -2.5445, -2.0021, -1.4858,
         -1.0273, -0.4062],
        [-2.9234, -1.9739, -0.8574, -2.0662, -1.2662, -0.5845, -0.0216,  0.5142,
         -1.0273, -0.4062],
        [-1.0748, -2.1272, -1.0126, -0.2019,  0.6166,  1.3168,  1.8983,  2.4547,
          2.9532,  1.5938],
        [-0.9429,  0.0261, -0.8574, -2.0662, -1.2662, -0.5845, -0.0216,  0.5142,
         -1.0273, -0.4062],
        [-0.8668, -1.9163, -0.7997, -2.0066, -1.2066, -2.5445, -2.0021, -1.4858,
         -1.0273, -0.4062]], device='cuda:0')
pred_boxes  tensor([[47., 18., 77., 46.],
        [16., 17., 82., 83.],
        [39., 10., 83., 53.],
        [40., 11., 74., 45.],
        [35., 46., 63., 75.]])
target_boxes  tensor([[ 6, 40, 33, 67],
        [ 4, 37, 31, 64],
        [51, 29, 78, 56],
        [29, 35, 56, 62],
        [ 6, 42, 33, 69]], dtype=torch.int32)


Test Epoch: 8 [0/982 (0%)]	Reward: -0.3000
action_seq  tensor([[1, 0, 7, 0, 4, 1, 5, 9, 9, 7],
        [1, 8, 9, 8, 8, 3, 6, 2, 3, 9],
        [4, 7, 0, 3, 5, 6, 8, 8, 7, 8],
        [7, 6, 1, 9, 9, 8, 8, 8, 7, 3],
        [3, 8, 9, 7, 7, 3, 6, 8, 9, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.],
        [ 1., -1.,  1.,  1., -1., -1., -1., -1., -1., -1.],
        [-1., -1.,  1., -1., -1.,  1., -1., -1., -1.,  1.],
        [ 1., -1.,  1., -1., -1.,  1., -1., -1., -1.,  1.]])
adv  tensor([[-6.3395, -5.8038, -5.1363, -4.4621, -3.8128, -3.1568, -2.6522, -1.7951,
         -1.1189, -0.6250],
        [ 1.1947,  1.8075,  2.5512,  1.2820,  1.9900,  2.7045,  3.2687,  2.1649,
          0.8616,  1.3750],
        [-0.4391, -1.8634, -1.1558, -2.4621, -3.8128, -3.1568, -2.6522, -1.7951,
         -1.1189, -0.6250],
        [-0.6500, -0.0567,  0.6684, -0.6193,  0.0700,  0.7641, -0.7117,  0.1649,
          0.8616,  1.3750],
        [ 1.3500, -0.0567,  0.6684, -0.6193,  0.0700,  0.7641, -0.7117,  0.1649,
          0.8616,  1.3750]], device='cuda:0')
pred_boxes  tensor([[39., 14., 68., 42.],
        [26., 38., 61., 73.],
        [26.,  0., 68., 42.],
        [29., 13., 83., 66.],
        [18., 37., 61., 81.]])
target_boxes  tensor([[22, 52, 49, 79],
        [17, 55, 44, 82],
        [32, 31, 59, 58],
        [25, 15, 52, 42],
        [30, 44, 57, 71]], dtype=torch.int32)
action_seq  tensor([[3, 3, 2, 5, 9, 1, 5, 6, 7, 2],
        [9, 1, 4, 1, 7, 7, 0, 4, 9, 0],
        [4, 4, 1, 7, 8, 1, 3, 4, 3, 0],
        [3, 8, 2, 1, 2, 4, 7, 9, 9, 3],
        [2, 2, 3, 1, 2, 5, 8, 5, 2, 9]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1.,  1., -1., -1.,  1., -1.,  1., -1.,  1.],
        [-1.,  1.,  1., -1., -1., -1., -1., -1.,  1., -1.],
        [ 1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1.,  1., -1., -1., -1.,  1., -1., -1., -1.]])
adv  tensor([[ 5.1129,  3.9646,  2.7737,  1.6012,  2.1869,  2.8707,  1.6379,  2.3167,
          1.0151,  1.6562],
        [-0.6351,  0.1794, -1.0505, -2.2601, -1.7154, -1.0697, -0.3231,  0.3372,
          1.0346, -0.3438],
        [-2.4408, -3.6653, -4.9333, -4.1624, -3.6363, -3.0101, -2.2830, -1.6433,
         -0.9654, -0.3438],
        [-2.4613, -3.6849, -2.9333, -4.1624, -3.6363, -3.0101, -2.2830, -1.6433,
         -0.9654, -0.3438],
        [ 1.4020,  0.2175, -1.0124, -2.2220, -1.6763, -1.0296, -0.2830, -1.6433,
         -0.9654, -0.3438]], device='cuda:0')
pred_boxes  tensor([[37., 46., 65., 74.],
        [41., 13., 71., 41.],
        [45., 10., 75., 38.],
        [34., 36., 62., 64.],
        [18., 44., 46., 73.]])
target_boxes  tensor([[33, 44, 60, 71],
        [17, 27, 44, 54],
        [12, 19, 39, 46],
        [18, 16, 45, 43],
        [ 9, 33, 36, 60]], dtype=torch.int32)
action_seq  tensor([[4, 3, 4, 0, 6, 0, 8, 4, 8, 2],
        [9, 7, 4, 8, 7, 2, 2, 8, 0, 0],
        [2, 9, 3, 7, 7, 9, 7, 6, 9, 1],
        [3, 3, 9, 0, 7, 7, 4, 4, 2, 8],
        [1, 7, 1, 8, 7, 5, 9, 3, 3, 1]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.],
        [-1., -1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1.],
        [ 1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.],
        [ 1., -1., -1.,  1.,  1., -1., -1., -1., -1.,  1.],
        [ 1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1.]])
adv  tensor([[ 4.9230,  4.0885,  2.6466,  1.5056,  0.1952, -1.1605, -2.4350, -1.7651,
         -1.0886, -0.5312],
        [ 2.6183,  3.7809,  4.3556,  3.2312,  3.9589,  4.6608,  3.4459,  4.1753,
          2.8919,  1.4688],
        [-2.9169, -3.8305, -3.3319, -2.5139, -1.8448, -1.2005, -0.4545,  0.2349,
         -1.0886, -0.5312],
        [ 0.9074,  0.0328,  0.5704,  1.4285,  0.1171, -1.2396, -0.4945,  0.1948,
          0.8919,  1.4688],
        [ 0.8117, -0.0639,  0.4718,  1.3289,  2.0360,  2.7204,  3.5055,  2.2153,
          0.9114, -0.5312]], device='cuda:0')
pred_boxes  tensor([[19., 14., 47., 42.],
        [17., 14., 45., 43.],
        [29., 29., 72., 72.],
        [47., 30., 75., 58.],
        [53., 28., 83., 56.]])
target_boxes  tensor([[17, 28, 44, 55],
        [20, 15, 47, 42],
        [ 2, 45, 29, 72],
        [49, 11, 76, 38],
        [55, 36, 82, 63]], dtype=torch.int32)
action_seq  tensor([[3, 6, 1, 2, 7, 0, 8, 2, 6, 8],
        [3, 8, 9, 8, 2, 3, 6, 4, 3, 1],
        [4, 8, 4, 7, 3, 2, 3, 8, 7, 7],
        [1, 1, 8, 7, 9, 2, 8, 2, 9, 1],
        [4, 3, 7, 8, 7, 2, 8, 7, 8, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.],
        [ 1.,  1., -1.,  1.,  1., -1., -1., -1., -1., -1.],
        [ 1., -1., -1., -1.,  1.,  1., -1., -1., -1., -1.],
        [-1., -1., -1., -1.,  1.,  1., -1.,  1.,  1., -1.],
        [ 1.,  1.,  1., -1., -1.,  1., -1.,  1., -1.,  1.]])
adv  tensor([[ 2.7871,  3.7923,  2.6323,  3.2895,  2.0287,  2.7117,  1.3824,  2.1856,
          0.7867, -0.5625],
        [ 1.0957,  0.0648, -1.1333, -0.5132, -1.8131, -3.1887, -2.5581, -1.7948,
         -1.2133, -0.5625],
        [-0.9228, -1.9743, -1.1734, -0.5533,  0.1674, -1.1887, -2.5581, -1.7948,
         -1.2133, -0.5625],
        [ 0.7871,  1.7728,  2.6118,  3.2700,  4.0287,  2.7117,  1.3824,  2.1856,
          0.7867, -0.5625],
        [ 4.7881,  3.7943,  2.6333,  1.2700,  2.0101,  2.6922,  1.3628,  2.1651,
          0.7672,  1.4375]], device='cuda:0')
pred_boxes  tensor([[17., 19., 45., 47.],
        [27., 34., 55., 63.],
        [50., 24., 78., 53.],
        [35., 25., 63., 53.],
        [46., 10., 80., 45.]])
target_boxes  tensor([[ 6, 38, 33, 65],
        [29, 11, 56, 38],
        [32, 53, 59, 80],
        [10, 43, 37, 70],
        [49, 26, 76, 53]], dtype=torch.int32)
action_seq  tensor([[8, 8, 1, 8, 9, 7, 3, 6, 2, 8],
        [3, 6, 7, 7, 3, 3, 8, 3, 4, 9],
        [1, 4, 3, 6, 3, 9, 3, 6, 3, 9],
        [0, 7, 8, 5, 8, 0, 0, 9, 8, 7],
        [1, 1, 3, 9, 8, 3, 8, 7, 7, 1]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1.,  1., -1., -1., -1., -1., -1., -1.,  1.],
        [-1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.],
        [ 1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1., -1., -1.,  1., -1., -1.,  1.,  1.],
        [ 1., -1.,  1.,  1., -1.,  1., -1., -1., -1., -1.]])
adv  tensor([[-3.1813, -2.3604, -1.4694, -2.5260, -1.6672, -1.0218, -0.4323,  0.2261,
          0.8919,  1.4688],
        [-5.0856, -4.2842, -3.4127, -2.4684, -1.6096, -0.9622, -0.3728, -1.7339,
         -1.0886, -0.5312],
        [-1.0280, -2.2061, -3.3336, -4.4089, -3.5696, -2.9427, -2.3728, -1.7339,
         -1.0886, -0.5312],
        [ 2.5872,  1.4443,  0.3539,  1.3363,  2.2341,  2.9186,  1.5276,  2.2066,
          2.8919,  1.4688],
        [ 0.8343, -0.3253,  0.5873, -0.4489, -1.5891, -0.9427, -2.3728, -1.7339,
         -1.0886, -0.5312]], device='cuda:0')
pred_boxes  tensor([[18., 27., 61., 70.],
        [50., 46., 79., 75.],
        [32., 43., 61., 71.],
        [21.,  0., 62., 41.],
        [53., 10., 83., 38.]])
target_boxes  tensor([[56, 12, 83, 39],
        [24,  7, 51, 34],
        [37, 16, 64, 43],
        [42,  6, 69, 33],
        [47, 43, 74, 70]], dtype=torch.int32)
action_seq  tensor([[6, 1, 8, 7, 9, 3, 7, 3, 7, 0],
        [6, 9, 7, 0, 2, 2, 3, 9, 7, 8],
        [1, 8, 8, 6, 0, 3, 2, 0, 7, 7],
        [8, 8, 1, 9, 0, 8, 2, 7, 0, 3],
        [0, 0, 8, 3, 8, 3, 7, 7, 6, 8]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.],
        [ 1., -1., -1.,  1., -1.,  1.,  1., -1., -1., -1.],
        [-1., -1., -1.,  1., -1., -1.,  1.,  1., -1., -1.],
        [ 1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.]])
adv  tensor([[-4.2213, -3.5376, -2.7843, -2.3382, -1.7310, -2.9480, -2.2834, -1.5804,
         -0.8704, -0.4688],
        [ 1.4281,  2.1684,  2.9794,  3.4831,  4.1498,  2.9925,  1.6971,  0.4196,
         -0.8704, -0.4688],
        [ 1.5834,  0.3051,  1.0975,  1.5817,  0.2094,  1.0325, -0.2834, -1.5804,
         -0.8704, -0.4688],
        [-0.4547,  0.2670,  1.0594,  1.5427,  0.1694,  0.9925,  1.6971,  0.4196,
         -0.8704, -0.4688],
        [ 7.1957,  5.9741,  6.8241,  7.3659,  6.0522,  4.9134,  3.6375,  2.3796,
          1.1100,  1.5312]], device='cuda:0')
pred_boxes  tensor([[39., 36., 74., 70.],
        [14., 31., 47., 66.],
        [22., 18., 50., 46.],
        [29., 17., 57., 45.],
        [23.,  2., 57., 36.]])
target_boxes  tensor([[10, 46, 37, 73],
        [ 9, 54, 36, 81],
        [ 8, 39, 35, 66],
        [38, 51, 65, 78],
        [40,  8, 67, 35]], dtype=torch.int32)
action_seq  tensor([[1, 8, 8, 7, 7, 2, 6, 4, 9, 3],
        [8, 3, 8, 1, 0, 1, 3, 7, 7, 3],
        [1, 8, 3, 1, 6, 8, 6, 7, 3, 8],
        [5, 5, 9, 9, 1, 7, 4, 2, 8, 4],
        [1, 4, 4, 3, 9, 3, 1, 0, 3, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1., -1.,  1., -1., -1.,  1.,  1.],
        [-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1., -1.,  1., -1.,  1., -1.,  1., -1., -1., -1.],
        [-1., -1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1.],
        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[-0.5772,  0.0477,  0.9319,  1.7622,  2.4118,  3.0350,  1.8345,  2.3903,
          3.0776,  1.6562],
        [-4.1720, -3.5831, -4.7556, -3.9829, -3.3919, -2.8263, -2.0658, -1.5501,
         -0.9029, -0.3438],
        [ 1.6113,  0.2401,  1.1252, -0.0620,  0.5681, -0.8459, -0.0658, -1.5501,
         -0.9029, -0.3438],
        [ 3.1884,  3.8524,  4.7746,  5.6440,  6.3317,  4.9754,  5.8150,  4.3903,
          3.0776,  1.6562],
        [-6.1524, -5.5831, -4.7556, -3.9829, -3.3919, -2.8263, -2.0658, -1.5501,
         -0.9029, -0.3438]], device='cuda:0')
pred_boxes  tensor([[18., 34., 52., 68.],
        [54.,  6., 83., 35.],
        [37.,  5., 73., 39.],
        [26., 11., 60., 45.],
        [41., 31., 70., 59.]])
target_boxes  tensor([[30, 52, 57, 79],
        [33, 50, 60, 77],
        [23, 26, 50, 53],
        [31, 10, 58, 37],
        [ 6, 51, 33, 78]], dtype=torch.int32)
action_seq  tensor([[8, 1, 9, 8, 5, 6, 3, 0, 0, 3],
        [9, 8, 1, 0, 3, 8, 0, 4, 3, 3],
        [2, 8, 9, 6, 3, 8, 8, 7, 3, 8],
        [1, 1, 9, 1, 2, 3, 0, 6, 8, 4],
        [3, 8, 3, 2, 7, 3, 9, 1, 9, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1.,  1., -1., -1.,  1.,  1., -1., -1., -1.],
        [-1., -1.,  1.,  1.,  1., -1., -1., -1., -1., -1.],
        [ 1., -1.,  1., -1.,  1., -1., -1.,  1.,  1., -1.],
        [ 1.,  1., -1.,  1.,  1., -1., -1.,  1., -1., -1.],
        [ 1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.]])
adv  tensor([[ 0.6559,  1.5781,  0.3304, -0.9919, -0.1807,  0.5755, -0.5240, -1.8867,
         -1.2745, -0.6875],
        [-1.2484, -0.3447,  0.4095, -0.9118, -2.1211, -3.4050, -2.5240, -1.8867,
         -1.2745, -0.6875],
        [ 2.5211,  1.4424,  2.2142,  0.9115,  1.7402,  0.4954,  1.4164,  2.0938,
          0.7255, -0.6875],
        [ 2.6364,  1.5576,  0.3119,  1.0091, -0.1807, -1.4450, -0.5436,  0.1133,
         -1.2745, -0.6875],
        [ 4.4420,  3.3828,  4.1732,  2.8910,  3.7402,  2.5159,  1.4359,  0.0938,
          0.7255, -0.6875]], device='cuda:0')
pred_boxes  tensor([[20., 18., 49., 46.],
        [28.,  3., 57., 31.],
        [33.,  7., 76., 51.],
        [38., 17., 68., 45.],
        [52., 45., 80., 73.]])
target_boxes  tensor([[14, 44, 41, 71],
        [29, 21, 56, 48],
        [41, 43, 68, 70],
        [40, 22, 67, 49],
        [53, 49, 80, 76]], dtype=torch.int32)
action_seq  tensor([[2, 8, 2, 3, 8, 8, 0, 6, 3, 3],
        [2, 8, 6, 6, 2, 4, 8, 6, 7, 3],
        [7, 3, 0, 9, 6, 8, 3, 2, 7, 2],
        [9, 5, 4, 6, 2, 8, 0, 9, 5, 3],
        [8, 1, 0, 8, 2, 3, 3, 7, 9, 0]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1.,  1.,  1., -1., -1.,  1., -1., -1.,  1., -1.],
        [-1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [-1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.]])
adv  tensor([[-3.3506e+00, -4.5201e+00, -3.8086e+00, -4.9202e+00, -4.0546e+00,
         -3.3378e+00, -2.7087e+00, -1.9786e+00, -1.3989e+00, -7.5000e-01],
        [-7.3105e+00, -6.5006e+00, -5.8086e+00, -4.9202e+00, -4.0546e+00,
         -3.3378e+00, -2.7087e+00, -1.9786e+00, -1.3989e+00, -7.5000e-01],
        [ 3.7796e-01,  1.2650e+00,  1.4664e-02, -1.0579e+00, -1.5320e-01,
          6.0260e-01, -7.4876e-01,  1.8921e-03,  6.0107e-01, -7.5000e-01],
        [-5.3506e+00, -4.5201e+00, -3.8086e+00, -4.9202e+00, -4.0546e+00,
         -3.3378e+00, -2.7087e+00, -1.9786e+00, -1.3989e+00, -7.5000e-01],
        [ 4.1817e+00,  5.1078e+00,  3.8955e+00,  2.8630e+00,  3.8068e+00,
          2.5831e+00,  1.2512e+00,  1.8921e-03,  6.0107e-01, -7.5000e-01]],
       device='cuda:0')
pred_boxes  tensor([[ 7., 13., 36., 42.],
        [16., 19., 49., 54.],
        [21., 39., 49., 68.],
        [ 8., 26., 41., 60.],
        [35., 29., 63., 57.]])
target_boxes  tensor([[ 2, 56, 29, 83],
        [54, 40, 81, 67],
        [32, 17, 59, 44],
        [42, 27, 69, 54],
        [28, 29, 55, 56]], dtype=torch.int32)
action_seq  tensor([[3, 4, 0, 1, 7, 7, 9, 7, 1, 8],
        [8, 1, 7, 2, 3, 3, 9, 4, 8, 8],
        [1, 8, 3, 7, 8, 1, 0, 0, 8, 2],
        [7, 0, 8, 3, 7, 1, 9, 2, 7, 0],
        [0, 9, 8, 8, 8, 5, 7, 2, 9, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.],
        [ 1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1.],
        [-1., -1., -1.,  1.,  1., -1.,  1., -1.,  1., -1.],
        [ 1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.]])
adv  tensor([[-0.7374, -1.7861, -3.0989, -4.4243, -3.5853, -2.8322, -1.9139, -1.3020,
         -0.7469, -0.3125],
        [ 2.8329,  3.8399,  4.6052,  5.3774,  4.2956,  3.1082,  2.0665,  0.6980,
         -0.7469, -0.3125],
        [ 4.8525,  3.8604,  4.6248,  3.3774,  4.2956,  3.1082,  2.0665,  0.6980,
         -0.7469, -0.3125],
        [ 0.9120,  1.9004,  2.6453,  3.3989,  2.2956,  1.0887,  2.0460,  0.6785,
          1.2531, -0.3125],
        [-2.8135, -3.8838, -3.1965, -2.5034, -1.6448, -0.8723,  0.0665,  0.6980,
         -0.7469, -0.3125]], device='cuda:0')
pred_boxes  tensor([[54., 22., 83., 50.],
        [37., 29., 65., 57.],
        [39.,  0., 68., 28.],
        [39., 29., 67., 57.],
        [23., 33., 65., 76.]])
target_boxes  tensor([[15, 38, 42, 65],
        [37, 55, 64, 82],
        [40,  5, 67, 32],
        [53, 54, 80, 81],
        [21, 16, 48, 43]], dtype=torch.int32)
Test Epoch: 8 [640/982 (62%)]	Reward: -0.3054
action_seq  tensor([[0, 8, 2, 4, 9, 7, 4, 2, 3, 3],
        [0, 9, 3, 1, 7, 8, 3, 9, 0, 1],
        [3, 2, 6, 3, 2, 0, 8, 8, 3, 3],
        [5, 1, 9, 1, 3, 3, 4, 8, 8, 1],
        [3, 4, 0, 3, 7, 4, 9, 0, 6, 9]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1.,  1.,  1., -1., -1., -1., -1., -1., -1.],
        [ 1., -1., -1.,  1., -1.,  1., -1., -1.,  1., -1.],
        [ 1.,  1., -1.,  1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1.]])
adv  tensor([[-0.1170, -1.2222, -0.3506, -1.8696, -3.0564, -2.4244, -1.9755, -1.3957,
         -0.7154, -0.3438],
        [ 1.6711,  0.5825,  1.4727,  1.9927,  0.8449,  1.5160, -0.0156,  0.5848,
          1.2846, -0.3438],
        [-0.0965, -1.2027, -2.3506, -1.8696, -3.0564, -2.4244, -1.9755, -1.3957,
         -0.7154, -0.3438],
        [-6.0174, -5.1626, -4.3311, -3.8696, -3.0564, -2.4244, -1.9755, -1.3957,
         -0.7154, -0.3438],
        [ 7.4191,  6.3901,  5.3174,  3.8560,  2.7268,  3.4174,  3.9249,  2.5447,
          3.2651,  1.6562]], device='cuda:0')
pred_boxes  tensor([[17., 34., 45., 63.],
        [39., 31., 67., 59.],
        [15., 35., 43., 64.],
        [50., 22., 79., 50.],
        [34., 43., 62., 71.]])
target_boxes  tensor([[ 5, 19, 32, 46],
        [39,  4, 66, 31],
        [50, 39, 77, 66],
        [ 1,  8, 28, 35],
        [28, 42, 55, 69]], dtype=torch.int32)
action_seq  tensor([[8, 6, 7, 3, 6, 8, 6, 0, 7, 6],
        [5, 9, 6, 2, 4, 2, 4, 9, 8, 8],
        [2, 0, 7, 9, 6, 8, 8, 2, 5, 9],
        [0, 7, 1, 0, 8, 3, 6, 8, 7, 6],
        [1, 8, 8, 6, 1, 9, 3, 7, 0, 4]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1.,  1., -1., -1.,  1., -1.,  1.],
        [-1., -1., -1.,  1.,  1.,  1., -1.,  1., -1., -1.],
        [ 1.,  1., -1., -1., -1., -1., -1.,  1., -1.,  1.],
        [-1.,  1.,  1., -1., -1.,  1., -1., -1.,  1., -1.],
        [ 1., -1., -1., -1.,  1., -1., -1., -1.,  1., -1.]])
adv  tensor([[-1.1826, -0.2159,  0.7608,  1.3995,  2.2030,  1.0882,  1.8260,  2.4436,
          0.9538,  1.5312],
        [ 0.8330,  1.8192,  2.8174,  3.4767,  2.2811,  1.1673, -0.1144,  0.4836,
         -1.0267, -0.4688],
        [ 0.8770, -0.1564, -1.1992, -0.5810,  0.2030,  1.0882,  1.8260,  2.4436,
          0.9538,  1.5312],
        [ 0.8936,  1.8807,  0.8575, -0.5224,  0.2616,  1.1478, -0.1349,  0.4641,
          0.9733, -0.4688],
        [-1.0283, -2.0802, -1.1230, -0.5019,  0.2811, -0.8522, -0.1349,  0.4641,
          0.9733, -0.4688]], device='cuda:0')
pred_boxes  tensor([[ 0.,  2., 53., 55.],
        [10., 29., 43., 64.],
        [ 0., 22., 41., 65.],
        [26.,  1., 60., 34.],
        [35., 22., 65., 50.]])
target_boxes  tensor([[ 5, 24, 32, 51],
        [28, 47, 55, 74],
        [18, 42, 45, 69],
        [51, 19, 78, 46],
        [33, 11, 60, 38]], dtype=torch.int32)
action_seq  tensor([[1, 9, 7, 9, 2, 4, 3, 0, 1, 9],
        [4, 6, 8, 2, 8, 7, 8, 6, 5, 8],
        [6, 2, 3, 2, 7, 8, 3, 6, 4, 2],
        [6, 4, 2, 9, 2, 8, 1, 4, 0, 0],
        [3, 0, 2, 3, 9, 3, 8, 8, 7, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1., -1., -1.,  1.,  1.,  1., -1., -1., -1.],
        [ 1., -1., -1.,  1., -1.,  1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.],
        [-1.,  1.,  1., -1., -1.,  1.,  1., -1., -1., -1.],
        [-1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[ 2.6413,  1.4679,  0.2195,  1.1696,  2.0969,  0.8243, -0.4937, -1.8560,
         -1.1805, -0.7188],
        [-1.2025, -2.4149, -1.6809, -0.7513, -1.8631, -1.1562, -2.4937, -1.8560,
         -1.1805, -0.7188],
        [-5.1429, -4.3749, -3.6613, -2.7513, -1.8631, -1.1562, -2.4937, -1.8560,
         -1.1805, -0.7188],
        [ 0.6803,  1.5079,  0.2596, -0.8108,  0.0969,  0.8243, -0.4937, -1.8560,
         -1.1805, -0.7188],
        [-3.1048, -2.3153, -3.6018, -4.7112, -3.8435, -3.1562, -2.4937, -1.8560,
         -1.1805, -0.7188]], device='cuda:0')
pred_boxes  tensor([[29., 48., 57., 76.],
        [ 0.,  0., 52., 53.],
        [25., 41., 53., 70.],
        [18., 33., 46., 62.],
        [35., 35., 63., 64.]])
target_boxes  tensor([[34, 46, 61, 73],
        [28, 30, 55, 57],
        [53,  3, 80, 30],
        [15, 22, 42, 49],
        [ 0, 23, 27, 50]], dtype=torch.int32)
action_seq  tensor([[5, 7, 8, 5, 8, 0, 5, 0, 5, 3],
        [5, 6, 4, 8, 7, 9, 2, 8, 7, 2],
        [7, 3, 3, 6, 3, 7, 3, 7, 3, 7],
        [0, 0, 6, 8, 0, 7, 8, 2, 7, 5],
        [4, 8, 7, 8, 9, 1, 3, 7, 3, 0]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1., -1.,  1., -1.,  1., -1.,  1.],
        [-1., -1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.],
        [-1.,  1.,  1.,  1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1., -1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.]])
adv  tensor([[-0.4350,  0.1912,  0.9512,  1.5281,  2.3023,  3.0820,  1.8828,  2.5959,
          1.3285,  1.5625],
        [ 1.5054,  2.1531,  2.9317,  1.5086,  2.2818,  3.0625,  3.8828,  2.5959,
          1.3285,  1.5625],
        [-0.1479,  0.4822, -0.7754, -2.2356, -3.5209, -2.7988, -2.0381, -1.3641,
         -0.6520, -0.4375],
        [-6.0288, -5.4582, -4.7558, -4.2356, -3.5209, -2.7988, -2.0381, -1.3641,
         -0.6520, -0.4375],
        [ 3.5435,  2.1912,  2.9697,  1.5476,  2.3218,  3.1025,  1.9024,  0.5959,
          1.3285,  1.5625]], device='cuda:0')
pred_boxes  tensor([[10., 10., 52., 52.],
        [27., 25., 68., 68.],
        [54., 54., 83., 83.],
        [14.,  8., 46., 41.],
        [48., 31., 76., 59.]])
target_boxes  tensor([[11,  3, 38, 30],
        [32, 22, 59, 49],
        [22, 33, 49, 60],
        [35, 54, 62, 81],
        [54, 24, 81, 51]], dtype=torch.int32)
action_seq  tensor([[4, 2, 9, 3, 8, 8, 1, 8, 2, 2],
        [3, 8, 7, 3, 8, 4, 6, 8, 0, 2],
        [8, 2, 0, 3, 1, 2, 2, 0, 9, 2],
        [3, 3, 6, 3, 2, 8, 3, 7, 9, 3],
        [1, 3, 4, 3, 7, 8, 9, 3, 2, 0]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1.,  1.,  1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1.,  1.,  1.,  1., -1., -1., -1., -1.],
        [-1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [ 1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.],
        [ 1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.]])
adv  tensor([[-0.5516, -1.7500, -0.8492, -2.5111, -3.7304, -3.1251, -2.2384, -1.6183,
         -1.1756, -0.6364],
        [ 3.2922,  2.1309,  1.0512,  1.4293,  0.2501, -1.1251, -2.2384, -1.6183,
         -1.1756, -0.6364],
        [-2.5506, -1.7500, -2.8697, -2.5306, -1.7304, -3.1251, -2.2384, -1.6183,
         -1.1756, -0.6364],
        [-2.5496, -3.7695, -2.8892, -2.5511, -1.7499, -1.1251, -2.2384, -1.6183,
         -1.1756, -0.6364],
        [-2.5496, -3.7695, -2.8892, -2.5511, -1.7499, -1.1251, -2.2384, -1.6183,
         -1.1756, -0.6364]], device='cuda:0')
pred_boxes  tensor([[26., 21., 54., 49.],
        [25.,  6., 53., 34.],
        [18., 37., 46., 65.],
        [40., 51., 68., 80.],
        [54., 31., 83., 59.]])
target_boxes  tensor([[43, 56, 70, 83],
        [48, 13, 75, 40],
        [36, 15, 63, 42],
        [53, 18, 80, 45],
        [45,  0, 72, 27]], dtype=torch.int32)
action_seq  tensor([[1, 8, 9, 1, 9, 6, 8, 1, 6, 8],
        [1, 5, 7, 8, 5, 2, 3, 8, 8, 6],
        [7, 4, 6, 9, 6, 8, 9, 1, 1, 7],
        [2, 8, 4, 0, 0, 3, 9, 0, 7, 3],
        [6, 9, 7, 0, 3, 1, 8, 5, 9, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1., -1.,  1., -1., -1.,  1., -1.],
        [ 1., -1., -1., -1., -1.,  1.,  1., -1., -1., -1.],
        [-1.,  1., -1., -1., -1., -1., -1.,  1.,  1., -1.],
        [-1.,  1.,  1.,  1.,  1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1.,  1., -1., -1., -1.,  1., -1.]])
adv  tensor([[-2.6027, -1.8215, -0.7894, -0.0293,  0.4552,  1.1464, -0.0542,  0.6328,
          1.1639, -0.4000],
        [-0.5656, -1.7834, -0.7513,  0.0088,  0.4943,  1.1864, -0.0142, -1.3477,
         -0.8361, -0.4000],
        [-0.6603,  0.1404, -0.8275, -0.0684,  0.4152,  1.1064,  1.9262,  2.6328,
          1.1639, -0.4000],
        [ 1.4510,  2.2742,  1.3278,  0.0889, -1.4462, -2.7940, -2.0142, -1.3477,
         -0.8361, -0.4000],
        [-2.5841, -1.8020, -0.7699, -0.0088,  0.4747, -0.8536, -0.0542,  0.6328,
          1.1639, -0.4000]], device='cuda:0')
pred_boxes  tensor([[19.,  3., 63., 44.],
        [17.,  5., 60., 48.],
        [31., 16., 74., 57.],
        [16., 18., 44., 47.],
        [23., 20., 57., 54.]])
target_boxes  tensor([[ 2, 30, 29, 57],
        [28, 23, 55, 50],
        [24, 21, 51, 48],
        [ 9,  4, 36, 31],
        [50, 44, 77, 71]], dtype=torch.int32)


Train Epoch: 9 [0/50 (0%)]	Reward: -0.3400
action_seq  tensor([[4, 8, 5, 1, 2, 6, 6, 2, 9, 0],
        [3, 8, 0, 9, 3, 3, 8, 7, 0, 4],
        [9, 7, 7, 3, 0, 8, 8, 8, 2, 9],
        [4, 8, 5, 2, 6, 3, 8, 3, 9, 1],
        [3, 2, 4, 2, 8, 0, 3, 4, 6, 6]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1.],
        [-1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1.],
        [ 1., -1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1.],
        [-1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.]])
adv  tensor([[ 4.6183,  3.3703,  4.1932,  4.9938,  5.8961,  4.6618,  3.3201,  2.2176,
          0.8505, -0.6875],
        [-4.8573, -4.1805, -3.4328, -2.7103, -3.9057, -3.2190, -2.6203, -1.7629,
         -1.1495, -0.6875],
        [-3.0302, -2.3348, -1.5685, -0.8275, -2.0033, -1.2981, -0.6799,  0.1971,
          0.8309,  1.3125],
        [ 4.5821,  3.3332,  4.1571,  4.9557,  3.8385,  4.6022,  3.2606,  4.1775,
          2.8309,  1.3125],
        [ 2.7560,  3.5099,  2.3143,  1.0749, -0.0824,  0.6423,  1.2801,  2.1775,
          2.8309,  1.3125]], device='cuda:0')
pred_boxes  tensor([[ 3., 24., 31., 52.],
        [41., 23., 69., 51.],
        [16., 18., 58., 61.],
        [24., 29., 52., 57.],
        [ 9., 35., 37., 64.]])
target_boxes  tensor([[ 6, 40, 33, 67],
        [ 4, 37, 31, 64],
        [51, 29, 78, 56],
        [29, 35, 56, 62],
        [ 6, 42, 33, 69]], dtype=torch.int32)


Test Epoch: 9 [0/982 (0%)]	Reward: -0.2906
action_seq  tensor([[4, 6, 6, 4, 9, 3, 0, 0, 4, 0],
        [0, 2, 0, 6, 0, 3, 8, 3, 8, 8],
        [2, 4, 1, 3, 7, 2, 5, 4, 8, 3],
        [1, 3, 0, 7, 8, 3, 8, 8, 1, 7],
        [3, 1, 7, 4, 8, 4, 9, 8, 2, 7]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1.,  1.,  1., -1., -1., -1., -1.],
        [-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1., -1.],
        [ 1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1., -1., -1., -1.,  1., -1.,  1., -1.]])
adv  tensor([[-0.5457, -1.7511, -0.7901, -0.1978,  0.3371, -0.7963, -2.0986, -1.4570,
         -0.8404, -0.3438],
        [-4.3885, -3.6125, -4.6905, -4.1382, -3.6434, -2.7963, -2.0986, -1.4570,
         -0.8404, -0.3438],
        [ 5.2599,  4.1131,  3.1132,  1.7241,  0.2579,  1.1441, -0.1387,  0.5235,
          1.1596, -0.3438],
        [-0.4285, -1.6320, -2.6905, -4.1382, -3.6434, -2.7963, -2.0986, -1.4570,
         -0.8404, -0.3438],
        [ 1.3400,  0.1541, -0.8868, -0.2955,  0.2374,  1.1246,  1.8613,  0.5235,
          1.1596, -0.3438]], device='cuda:0')
pred_boxes  tensor([[16., 34., 44., 62.],
        [ 4.,  0., 32., 29.],
        [31., 31., 59., 59.],
        [54.,  0., 83., 28.],
        [43., 20., 71., 48.]])
target_boxes  tensor([[22, 52, 49, 79],
        [17, 55, 44, 82],
        [32, 31, 59, 58],
        [25, 15, 52, 42],
        [30, 44, 57, 71]], dtype=torch.int32)
action_seq  tensor([[8, 8, 4, 8, 6, 0, 3, 4, 7, 9],
        [7, 6, 9, 8, 4, 4, 4, 1, 4, 2],
        [4, 5, 6, 7, 4, 0, 2, 6, 4, 8],
        [6, 8, 4, 7, 6, 1, 7, 8, 5, 1],
        [7, 2, 2, 8, 9, 3, 8, 6, 1, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1.,  1., -1., -1., -1.,  1., -1.,  1.,  1.],
        [-1., -1., -1., -1.,  1.,  1.,  1., -1., -1., -1.],
        [ 1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.],
        [-1., -1.,  1., -1., -1.,  1., -1., -1., -1., -1.],
        [-1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.]])
adv  tensor([[ 0.9140,  2.0294,  2.7429,  1.3820,  1.9323,  2.8045,  3.7161,  2.1128,
          2.7972,  1.5625],
        [-0.8956,  0.2003,  0.8962,  1.5372,  2.0896,  0.9432, -0.1843, -1.8277,
         -1.1832, -0.4375],
        [ 6.6415,  5.7931,  6.5456,  7.2433,  7.8532,  6.7645,  5.6966,  4.1128,
          2.7972,  1.5625],
        [-2.7394, -1.6620, -0.9847, -2.3837, -1.8704, -1.0373, -2.1843, -1.8277,
         -1.1832, -0.4375],
        [ 6.6610,  7.8331,  6.5856,  5.2628,  5.8532,  6.7645,  5.6966,  4.1128,
          2.7972,  1.5625]], device='cuda:0')
pred_boxes  tensor([[20., 20., 53., 53.],
        [29., 21., 58., 49.],
        [14., 18., 42., 47.],
        [36.,  0., 79., 41.],
        [ 9., 35., 37., 64.]])
target_boxes  tensor([[33, 44, 60, 71],
        [17, 27, 44, 54],
        [12, 19, 39, 46],
        [18, 16, 45, 43],
        [ 9, 33, 36, 60]], dtype=torch.int32)
action_seq  tensor([[0, 8, 7, 6, 9, 4, 5, 6, 4, 4],
        [2, 4, 0, 9, 1, 9, 8, 4, 8, 3],
        [9, 0, 8, 7, 9, 5, 7, 2, 0, 4],
        [4, 3, 7, 7, 6, 5, 8, 4, 7, 0],
        [6, 6, 0, 3, 8, 8, 1, 8, 6, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1., -1.,  1., -1., -1.,  1.,  1.],
        [ 1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.],
        [-1.,  1., -1., -1.,  1., -1., -1.,  1.,  1., -1.],
        [ 1., -1.,  1., -1., -1., -1.,  1., -1.,  1., -1.],
        [-1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1.]])
adv  tensor([[ 0.5221, -0.4834,  0.3323,  1.1249,  1.8629,  2.7014,  1.3714,  2.1434,
          2.8597,  1.5625],
        [ 4.5367,  3.5732,  2.4085,  1.2030,  1.9401,  0.7610,  1.4310,  0.1834,
          0.8793, -0.4375],
        [ 0.5582,  1.5732,  0.3899,  1.1835,  1.9205,  0.7405,  1.4114,  2.1834,
          0.8793, -0.4375],
        [ 0.6353, -0.3672,  0.4485, -0.7774, -0.0599,  0.7610,  1.4310,  0.1834,
          0.8793, -0.4375],
        [-3.2856, -2.3086, -1.5105, -0.7374, -2.0385, -1.2390, -0.5886,  0.1629,
          0.8597,  1.5625]], device='cuda:0')
pred_boxes  tensor([[ 9., 28., 42., 61.],
        [17., 26., 45., 54.],
        [21., 30., 53., 63.],
        [32., 15., 65., 48.],
        [22.,  8., 57., 42.]])
target_boxes  tensor([[17, 28, 44, 55],
        [20, 15, 47, 42],
        [ 2, 45, 29, 72],
        [49, 11, 76, 38],
        [55, 36, 82, 63]], dtype=torch.int32)
action_seq  tensor([[0, 3, 7, 9, 0, 3, 2, 8, 6, 8],
        [1, 2, 2, 7, 0, 9, 3, 8, 4, 6],
        [9, 1, 3, 2, 9, 6, 2, 7, 6, 8],
        [8, 4, 8, 2, 3, 2, 2, 6, 2, 1],
        [4, 9, 4, 8, 8, 8, 0, 8, 3, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1., -1., -1.,  1., -1.,  1., -1.,  1., -1.],
        [ 1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.],
        [-1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.],
        [-1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1., -1.],
        [ 1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.]])
adv  tensor([[ 2.4277,  1.6001,  0.2580,  1.0196,  1.7861,  0.6057,  1.5266,  0.2169,
          0.8183, -0.5938],
        [ 0.5635, -0.2837, -1.6433, -0.9023, -0.1543, -1.3553, -0.4529,  0.2364,
         -1.1817, -0.5938],
        [ 2.3662,  3.5591,  4.2580,  3.0381,  1.8057,  0.6252,  1.5471,  0.2364,
         -1.1817, -0.5938],
        [ 2.3682,  3.5591,  2.2385,  3.0176,  1.7861,  2.6252,  1.5471,  0.2364,
         -1.1817, -0.5938],
        [ 0.4307, -0.4165,  0.2414, -1.0185, -0.2715,  0.5461,  1.4670,  2.1769,
          2.7988,  1.4062]], device='cuda:0')
pred_boxes  tensor([[25., 25., 53., 53.],
        [23., 28., 51., 57.],
        [19., 32., 53., 67.],
        [12., 36., 40., 66.],
        [28., 14., 56., 42.]])
target_boxes  tensor([[ 6, 38, 33, 65],
        [29, 11, 56, 38],
        [32, 53, 59, 80],
        [10, 43, 37, 70],
        [49, 26, 76, 53]], dtype=torch.int32)
action_seq  tensor([[3, 1, 8, 4, 7, 9, 6, 7, 9, 9],
        [4, 9, 8, 1, 5, 1, 3, 4, 6, 4],
        [5, 3, 8, 7, 2, 3, 3, 3, 4, 6],
        [4, 7, 9, 2, 1, 1, 2, 8, 7, 8],
        [4, 2, 4, 6, 5, 8, 7, 0, 1, 6]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1., -1.],
        [ 1., -1.,  1.,  1., -1.,  1., -1., -1.,  1., -1.],
        [-1.,  1., -1., -1.,  1., -1., -1., -1., -1.,  1.],
        [ 1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1.],
        [ 1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.]])
adv  tensor([[ 4.6369,  3.5790,  2.5427,  1.3684,  0.1825, -0.9837, -0.4248,  0.2964,
         -1.0579, -0.4688],
        [ 2.6194,  1.5409,  2.5036,  1.3294,  0.1434,  0.9968, -0.4453,  0.2769,
          0.9421, -0.4688],
        [-1.3006, -0.3985, -1.4759, -0.6696,  0.1444, -1.0227, -0.4648,  0.2564,
          0.9225,  1.5312],
        [ 4.3313,  3.2694,  4.2497,  5.1136,  5.9862,  4.8777,  3.4756,  4.2369,
          2.9225,  1.5312],
        [-3.1463, -4.2823, -3.3792, -2.5925, -1.7980, -0.9632, -0.4052, -1.7036,
         -1.0579, -0.4688]], device='cuda:0')
pred_boxes  tensor([[39., 34., 82., 76.],
        [35., 13., 65., 41.],
        [35., 40., 63., 69.],
        [40., 23., 68., 51.],
        [10., 17., 38., 45.]])
target_boxes  tensor([[56, 12, 83, 39],
        [24,  7, 51, 34],
        [37, 16, 64, 43],
        [42,  6, 69, 33],
        [47, 43, 74, 70]], dtype=torch.int32)
action_seq  tensor([[9, 3, 8, 0, 6, 2, 0, 3, 8, 3],
        [6, 0, 4, 9, 0, 3, 7, 0, 3, 8],
        [1, 8, 1, 4, 8, 3, 2, 4, 4, 8],
        [1, 8, 3, 9, 7, 4, 9, 2, 3, 9],
        [3, 6, 4, 0, 5, 1, 6, 3, 7, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1., -1.,  1.,  1., -1.,  1., -1., -1.],
        [-1., -1., -1.,  1., -1.,  1., -1., -1., -1., -1.],
        [ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.],
        [ 1., -1., -1., -1., -1.,  1., -1., -1.,  1., -1.]])
adv  tensor([[ 0.6270,  1.4528,  0.2055,  0.9967,  1.7962,  0.6775, -0.5776,  0.1736,
         -1.1820, -0.5625],
        [-3.1982, -2.4105, -1.6764, -0.9047, -2.1442, -1.2824, -2.5581, -1.8264,
         -1.1820, -0.5625],
        [-5.0410, -6.2914, -5.5973, -4.8647, -4.1247, -3.2824, -2.5581, -1.8264,
         -1.1820, -0.5625],
        [ 4.3545,  5.2194,  6.0297,  4.8590,  3.6771,  4.5984,  3.3824,  2.1541,
          0.8180, -0.5625],
        [-1.2929, -2.5062, -1.7740, -1.0024, -0.2233,  0.6580, -0.5981,  0.1541,
          0.8180, -0.5625]], device='cuda:0')
pred_boxes  tensor([[10., 11., 38., 40.],
        [20., 18., 48., 46.],
        [42.,  7., 71., 35.],
        [40., 55., 68., 83.],
        [20., 28., 49., 56.]])
target_boxes  tensor([[10, 46, 37, 73],
        [ 9, 54, 36, 81],
        [ 8, 39, 35, 66],
        [38, 51, 65, 78],
        [40,  8, 67, 35]], dtype=torch.int32)
action_seq  tensor([[6, 3, 5, 8, 3, 2, 4, 4, 8, 0],
        [6, 1, 7, 3, 3, 2, 1, 4, 2, 9],
        [3, 2, 0, 0, 4, 7, 1, 3, 2, 3],
        [5, 2, 3, 3, 7, 3, 7, 6, 2, 7],
        [2, 3, 5, 5, 7, 9, 3, 9, 9, 6]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1., -1.,  1.,  1., -1., -1., -1., -1.],
        [-1., -1., -1.,  1.,  1.,  1., -1., -1., -1.,  1.],
        [ 1.,  1.,  1.,  1., -1.,  1., -1., -1., -1., -1.],
        [-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1., -1., -1., -1., -1., -1., -1.,  1.]])
adv  tensor([[-0.5688,  0.3400, -0.7614, -0.1370,  0.7772, -0.6358, -2.1259, -1.4845,
         -0.9630, -0.5938],
        [ 1.2184,  2.1456,  3.0833,  3.7458,  2.6795,  1.2851, -0.1854,  0.4755,
          1.0175,  1.4062],
        [ 3.4107,  2.3400,  1.2591, -0.1174, -1.2228, -0.6358, -2.1259, -1.4845,
         -0.9630, -0.5938],
        [-4.3920, -3.5214, -4.6618, -4.0774, -3.2033, -2.6358, -2.1259, -1.4845,
         -0.9630, -0.5938],
        [-0.5648, -1.6757, -2.7975, -2.1946, -1.3009, -0.7149, -0.1854,  0.4755,
          1.0175,  1.4062]], device='cuda:0')
pred_boxes  tensor([[36., 26., 64., 54.],
        [46., 36., 74., 64.],
        [23., 31., 51., 60.],
        [44., 54., 72., 83.],
        [24., 39., 67., 83.]])
target_boxes  tensor([[30, 52, 57, 79],
        [33, 50, 60, 77],
        [23, 26, 50, 53],
        [31, 10, 58, 37],
        [ 6, 51, 33, 78]], dtype=torch.int32)
action_seq  tensor([[9, 4, 7, 3, 2, 2, 7, 7, 8, 0],
        [4, 6, 3, 9, 9, 7, 6, 4, 2, 3],
        [7, 6, 6, 4, 8, 2, 3, 3, 3, 0],
        [4, 3, 6, 5, 7, 3, 8, 1, 7, 1],
        [3, 1, 3, 8, 1, 8, 9, 3, 1, 6]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1., -1.,  1.,  1., -1., -1., -1., -1.],
        [ 1., -1.,  1., -1., -1., -1., -1.,  1., -1., -1.],
        [-1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1.],
        [ 1.,  1., -1., -1.,  1., -1.,  1.,  1., -1., -1.],
        [ 1.,  1.,  1., -1., -1., -1.,  1.,  1., -1., -1.]])
adv  tensor([[-0.9035,  0.0649, -1.0390, -0.1651,  0.4648, -0.8251, -2.1593, -1.4867,
         -0.9020, -0.4375],
        [-0.8830, -1.9331, -1.0371, -2.1846, -1.5753, -0.8652, -0.1788,  0.5133,
         -0.9020, -0.4375],
        [ 2.7283,  3.7339,  4.6875,  5.6181,  4.2861,  5.0557,  3.7811,  2.4938,
          1.0980, -0.4375],
        [ 2.9412,  1.9292,  0.8438,  1.7363,  2.3847,  1.1153,  1.8212,  0.5133,
         -0.9020, -0.4375],
        [ 2.9803,  1.9692,  0.8838, -0.2442,  0.3847,  1.1153,  1.8212,  0.5133,
         -0.9020, -0.4375]], device='cuda:0')
pred_boxes  tensor([[42., 32., 70., 61.],
        [22., 48., 50., 77.],
        [32., 37., 60., 66.],
        [51., 22., 80., 50.],
        [47., 22., 77., 50.]])
target_boxes  tensor([[14, 44, 41, 71],
        [29, 21, 56, 48],
        [41, 43, 68, 70],
        [40, 22, 67, 49],
        [53, 49, 80, 76]], dtype=torch.int32)
action_seq  tensor([[4, 0, 3, 1, 1, 4, 3, 8, 1, 2],
        [7, 8, 8, 7, 2, 1, 4, 8, 8, 3],
        [1, 3, 0, 7, 1, 3, 2, 2, 4, 2],
        [4, 4, 4, 3, 3, 7, 8, 7, 0, 0],
        [0, 4, 2, 1, 9, 8, 8, 8, 9, 0]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1.,  1., -1., -1., -1.,  1.],
        [ 1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1.],
        [ 1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1., -1.]])
adv  tensor([[-6.6094, -5.8238, -4.9988, -4.0390, -3.3855, -2.8829, -2.2178, -1.7982,
         -0.9957, -0.4375],
        [-2.8799, -2.0572, -1.1941, -0.1963,  0.4973,  1.0380, -0.2773,  0.1617,
          0.9847,  1.5625],
        [-0.6690, -1.8433, -2.9988, -4.0390, -3.3855, -2.8829, -2.2178, -1.7982,
         -0.9957, -0.4375],
        [ 6.9209,  5.8227,  4.7453,  3.7823,  2.4954,  3.0575,  1.7627,  0.2018,
         -0.9957, -0.4375],
        [ 5.0381,  3.9213,  2.8244,  1.8438,  0.5354, -0.9425, -0.2578,  0.1822,
          1.0043, -0.4375]], device='cuda:0')
pred_boxes  tensor([[31., 12., 60., 40.],
        [26., 11., 60., 45.],
        [50., 18., 80., 46.],
        [43., 27., 71., 55.],
        [14.,  7., 42., 35.]])
target_boxes  tensor([[ 2, 56, 29, 83],
        [54, 40, 81, 67],
        [32, 17, 59, 44],
        [42, 27, 69, 54],
        [28, 29, 55, 56]], dtype=torch.int32)
action_seq  tensor([[4, 3, 4, 1, 7, 0, 9, 2, 8, 2],
        [3, 6, 6, 1, 7, 0, 9, 8, 9, 2],
        [3, 7, 6, 8, 0, 2, 4, 8, 9, 7],
        [6, 3, 6, 2, 7, 2, 4, 1, 1, 3],
        [3, 9, 5, 8, 4, 2, 6, 1, 3, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1.,  1., -1., -1., -1.,  1., -1., -1., -1.],
        [ 1., -1., -1., -1., -1., -1.,  1., -1.,  1., -1.],
        [-1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1.],
        [-1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [ 1., -1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.]])
adv  tensor([[ 1.4245,  0.3033, -0.8626, -2.1654, -1.5244, -0.7815, -0.1902, -1.5811,
         -0.9026, -0.3750],
        [-0.6702, -1.8129, -0.9798, -0.2630,  0.3965,  1.1589,  1.7697,  0.3994,
          1.0974, -0.3750],
        [-2.6312, -1.7738, -0.9388, -0.2230, -1.5820, -0.8411, -0.2498,  0.3789,
          1.0779,  1.6250],
        [-2.4974, -1.6391, -2.8236, -2.1254, -1.4844, -2.7620, -2.1902, -1.5811,
         -0.9026, -0.3750],
        [ 3.1716,  2.0670,  2.9401,  3.6959,  4.3965,  3.1785,  1.7902,  0.4189,
         -0.9026, -0.3750]], device='cuda:0')
pred_boxes  tensor([[40., 25., 68., 53.],
        [23., 31., 57., 65.],
        [12., 15., 45., 49.],
        [21., 43., 49., 72.],
        [28., 25., 56., 53.]])
target_boxes  tensor([[15, 38, 42, 65],
        [37, 55, 64, 82],
        [40,  5, 67, 32],
        [53, 54, 80, 81],
        [21, 16, 48, 43]], dtype=torch.int32)
Test Epoch: 9 [640/982 (62%)]	Reward: -0.2980
action_seq  tensor([[3, 0, 0, 4, 3, 6, 8, 5, 2, 2],
        [7, 7, 3, 7, 8, 5, 3, 7, 7, 3],
        [4, 7, 1, 1, 9, 2, 1, 7, 9, 6],
        [6, 6, 4, 7, 9, 8, 4, 8, 3, 3],
        [6, 4, 7, 5, 9, 8, 9, 8, 3, 4]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1., -1.],
        [-1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [ 1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.],
        [-1., -1.,  1., -1., -1.,  1., -1.,  1., -1., -1.],
        [-1.,  1., -1., -1., -1., -1., -1., -1.,  1., -1.]])
adv  tensor([[ 3.1234,  3.9443,  2.8158,  1.6129,  0.3671,  1.0657, -0.2184, -1.7357,
         -0.9326, -0.5000],
        [-4.6217, -3.8790, -3.0660, -2.3070, -1.5733, -2.9148, -2.2184, -1.7357,
         -0.9326, -0.5000],
        [ 6.9310,  5.7695,  4.6596,  3.4762,  4.2685,  2.9856,  1.7220,  2.2448,
          1.0674, -0.5000],
        [-0.8160, -0.0352,  0.8168, -0.4066,  0.3476,  1.0452, -0.2379,  0.2643,
         -0.9326, -0.5000],
        [-2.7164, -1.9552, -3.1432, -2.3851, -1.6524, -0.9744, -0.2585,  0.2448,
          1.0674, -0.5000]], device='cuda:0')
pred_boxes  tensor([[19., 19., 47., 47.],
        [39., 25., 83., 69.],
        [44., 29., 73., 57.],
        [41., 18., 76., 53.],
        [35., 20., 77., 62.]])
target_boxes  tensor([[ 5, 19, 32, 46],
        [39,  4, 66, 31],
        [50, 39, 77, 66],
        [ 1,  8, 28, 35],
        [28, 42, 55, 69]], dtype=torch.int32)
action_seq  tensor([[5, 8, 0, 2, 6, 2, 2, 4, 1, 8],
        [1, 9, 8, 0, 1, 2, 8, 3, 2, 8],
        [6, 3, 2, 5, 7, 0, 6, 0, 9, 4],
        [9, 7, 7, 6, 7, 1, 0, 9, 7, 8],
        [7, 4, 3, 7, 3, 9, 8, 0, 1, 7]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1.],
        [ 1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.],
        [-1., -1., -1., -1., -1.,  1., -1., -1.,  1., -1.],
        [-1.,  1., -1., -1., -1., -1.,  1.,  1., -1., -1.]])
adv  tensor([[ 2.3085e+00,  3.3426e+00,  4.2914e+00,  3.1978e+00,  2.0948e+00,
          2.7786e+00,  1.4489e+00, -2.0187e-02,  6.4313e-01,  1.3438e+00],
        [-3.2237e+00, -4.2668e+00, -5.4146e+00, -4.5854e+00, -3.7479e+00,
         -3.1227e+00, -2.4915e+00, -1.9801e+00, -1.3373e+00, -6.5625e-01],
        [ 6.0585e+00,  7.1297e+00,  6.0961e+00,  5.0210e+00,  5.9562e+00,
          6.6790e+00,  5.3893e+00,  3.9603e+00,  2.6431e+00,  1.3438e+00],
        [-3.4561e+00, -2.4816e+00, -1.5914e+00, -7.2310e-01,  1.5344e-01,
          8.1769e-01, -5.3157e-01,  3.2043e-04,  6.6266e-01, -6.5625e-01],
        [-1.4766e+00, -4.8160e-01, -1.5914e+00, -7.2408e-01,  1.5247e-01,
          8.1769e-01,  1.4889e+00,  1.9852e-02, -1.3373e+00, -6.5625e-01]],
       device='cuda:0')
pred_boxes  tensor([[ 2., 27., 30., 57.],
        [31.,  0., 59., 29.],
        [19., 37., 47., 66.],
        [26.,  0., 79., 52.],
        [51., 30., 79., 58.]])
target_boxes  tensor([[ 5, 24, 32, 51],
        [28, 47, 55, 74],
        [18, 42, 45, 69],
        [51, 19, 78, 46],
        [33, 11, 60, 38]], dtype=torch.int32)
action_seq  tensor([[2, 0, 0, 9, 7, 8, 8, 3, 8, 0],
        [1, 6, 4, 1, 0, 9, 3, 2, 7, 8],
        [7, 8, 6, 3, 4, 9, 9, 7, 6, 3],
        [2, 6, 7, 7, 0, 3, 4, 8, 6, 3],
        [7, 4, 4, 3, 2, 8, 4, 9, 8, 8]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1.,  1.,  1., -1., -1.,  1., -1., -1.],
        [ 1., -1.,  1., -1., -1.,  1.,  1., -1.,  1., -1.],
        [-1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.],
        [ 1., -1., -1., -1.,  1., -1., -1.,  1.,  1., -1.],
        [-1.,  1., -1., -1., -1.,  1., -1., -1.,  1.,  1.]])
adv  tensor([[ 1.3796,  0.2570,  0.8290,  1.5314,  0.1576, -1.1981, -0.5151,  0.2367,
         -1.2130, -0.5938],
        [ 3.2449,  2.1417,  2.7304,  1.4328,  2.0785,  2.7628,  1.4644,  0.2172,
          0.7870, -0.5938],
        [-4.4817, -3.6434, -3.1114, -2.4490, -1.8424, -1.1981, -0.5151,  0.2367,
         -1.2130, -0.5938],
        [ 1.2849,  0.1613,  0.7314,  1.4338,  2.0785,  0.7423,  1.4449,  2.2172,
          0.7870, -0.5938],
        [ 1.2097,  2.1046,  0.6738,  1.3752,  2.0209,  2.7033,  1.4048,  2.1772,
          2.7675,  1.4062]], device='cuda:0')
pred_boxes  tensor([[16.,  7., 44., 35.],
        [29., 11., 59., 39.],
        [28., 39., 72., 83.],
        [29., 28., 57., 57.],
        [27., 21., 55., 49.]])
target_boxes  tensor([[34, 46, 61, 73],
        [28, 30, 55, 57],
        [53,  3, 80, 30],
        [15, 22, 42, 49],
        [ 0, 23, 27, 50]], dtype=torch.int32)
action_seq  tensor([[0, 4, 9, 8, 1, 4, 0, 0, 0, 4],
        [1, 0, 0, 4, 8, 8, 6, 8, 3, 2],
        [7, 7, 2, 7, 8, 6, 7, 3, 4, 9],
        [2, 8, 8, 2, 8, 4, 1, 8, 8, 4],
        [9, 4, 8, 4, 6, 8, 6, 9, 1, 5]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1., -1.,  1.,  1., -1.,  1., -1., -1., -1.],
        [ 1.,  1., -1., -1., -1., -1., -1., -1.,  1., -1.],
        [-1., -1.,  1., -1., -1., -1., -1.,  1.,  1., -1.],
        [ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[ 3.3490e+00,  2.2151e+00,  1.1327e+00,  1.8705e+00,  6.2625e-01,
         -5.9775e-01, -4.5624e-03, -1.4251e+00, -9.0289e-01, -3.4375e-01],
        [-5.4941e-01, -1.7234e+00, -2.8458e+00, -2.1481e+00, -1.4128e+00,
         -6.3779e-01, -4.4601e-02,  5.5534e-01,  1.0971e+00, -3.4375e-01],
        [-7.0566e-01,  1.3989e-01,  1.0565e+00, -2.2719e-01,  5.2762e-01,
          1.3222e+00,  1.9359e+00,  2.5553e+00,  1.0971e+00, -3.4375e-01],
        [-4.3756e+00, -5.5876e+00, -4.7286e+00, -4.0504e+00, -3.3337e+00,
         -2.5782e+00, -2.0046e+00, -1.4251e+00, -9.0289e-01, -3.4375e-01],
        [-4.3951e+00, -3.5876e+00, -4.7286e+00, -4.0504e+00, -3.3337e+00,
         -2.5782e+00, -2.0046e+00, -1.4251e+00, -9.0289e-01, -3.4375e-01]],
       device='cuda:0')
pred_boxes  tensor([[20.,  9., 48., 37.],
        [17.,  4., 46., 32.],
        [31., 28., 73., 71.],
        [15.,  2., 43., 31.],
        [10., 10., 53., 52.]])
target_boxes  tensor([[11,  3, 38, 30],
        [32, 22, 59, 49],
        [22, 33, 49, 60],
        [35, 54, 62, 81],
        [54, 24, 81, 51]], dtype=torch.int32)
action_seq  tensor([[7, 8, 2, 9, 2, 3, 0, 9, 4, 3],
        [9, 7, 0, 0, 3, 7, 8, 8, 2, 3],
        [6, 8, 3, 9, 2, 3, 8, 3, 2, 7],
        [1, 5, 7, 3, 9, 9, 4, 8, 2, 9],
        [9, 9, 8, 4, 0, 8, 8, 7, 7, 7]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1.,  1., -1., -1.,  1., -1.,  1., -1., -1.],
        [-1., -1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.],
        [-1., -1.,  1., -1., -1., -1.,  1., -1., -1., -1.],
        [ 1., -1., -1.,  1., -1., -1., -1.,  1., -1., -1.],
        [-1., -1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.]])
adv  tensor([[-0.4318,  0.2983,  0.6688, -0.5186, -0.0642,  0.3022, -0.7963, -0.2537,
         -1.1747, -0.7273],
        [ 1.4520,  2.2016,  2.5906,  1.4237,  1.8977,  0.2631, -0.8363, -0.2938,
          0.8058,  1.2727],
        [-2.3156, -1.6031, -1.2531, -2.4591, -2.0252, -1.6773, -0.7768, -2.2537,
         -1.1747, -0.7273],
        [-0.3537, -1.6431, -1.2912, -0.4786, -2.0447, -1.6978, -0.7963, -0.2537,
         -1.1747, -0.7273],
        [ 1.3944,  2.1420,  2.5320,  3.3837,  1.8567,  2.2426,  1.1637,  1.7267,
          0.8253, -0.7273]], device='cuda:0')
pred_boxes  tensor([[12., 48., 40., 78.],
        [23., 13., 51., 42.],
        [39., 45., 67., 74.],
        [34., 40., 68., 74.],
        [31.,  0., 83., 52.]])
target_boxes  tensor([[43, 56, 70, 83],
        [48, 13, 75, 40],
        [36, 15, 63, 42],
        [53, 18, 80, 45],
        [45,  0, 72, 27]], dtype=torch.int32)
action_seq  tensor([[8, 2, 0, 4, 8, 2, 0, 0, 1, 0],
        [0, 8, 3, 8, 3, 1, 3, 8, 3, 9],
        [3, 3, 9, 6, 3, 8, 6, 7, 2, 0],
        [6, 8, 4, 2, 3, 5, 8, 9, 2, 3],
        [4, 6, 3, 1, 2, 7, 1, 0, 8, 6]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1., -1., -1.,  1., -1., -1., -1., -1.],
        [-1., -1.,  1., -1.,  1., -1., -1., -1., -1., -1.],
        [ 1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.],
        [-1., -1.,  1.,  1., -1., -1., -1.,  1.,  1., -1.],
        [ 1., -1.,  1.,  1., -1.,  1.,  1., -1., -1., -1.]])
adv  tensor([[-2.8614, -2.1239, -3.5592, -2.6254, -1.8432, -1.2562, -2.6427, -1.8613,
         -1.2741, -0.6000],
        [-2.8633, -2.1239, -1.5396, -2.6049, -1.8237, -3.2562, -2.6427, -1.8613,
         -1.2741, -0.6000],
        [ 2.8085,  1.5841,  2.2064,  3.1978,  2.0191,  2.6452,  1.2978,  0.0986,
          0.7063,  1.4000],
        [ 0.8662,  1.6427,  2.2660,  1.2378,  0.0377,  0.6442,  1.2978,  2.1191,
          0.7259, -0.6000],
        [ 2.9413,  1.7189,  2.3422,  1.3150,  0.1168,  0.7243, -0.6427, -1.8613,
         -1.2741, -0.6000]], device='cuda:0')
pred_boxes  tensor([[ 5., 20., 33., 49.],
        [37., 17., 66., 45.],
        [27., 38., 55., 66.],
        [23., 43., 51., 73.],
        [29., 23., 57., 51.]])
target_boxes  tensor([[12, 52, 39, 79],
        [55, 48, 82, 75],
        [26, 21, 53, 48],
        [10, 55, 37, 82],
        [45, 30, 72, 57]], dtype=torch.int32)


Train Epoch: 10 [0/50 (0%)]	Reward: -0.2960
action_seq  tensor([[8, 2, 2, 0, 4, 7, 4, 6, 2, 2],
        [1, 4, 7, 4, 6, 4, 3, 3, 7, 2],
        [4, 7, 9, 2, 5, 8, 5, 9, 7, 8],
        [5, 5, 7, 2, 4, 9, 7, 1, 9, 9],
        [8, 2, 9, 0, 0, 5, 0, 9, 2, 9]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1., -1.],
        [-1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1., -1., -1.,  1., -1., -1.,  1., -1.],
        [-1., -1., -1.,  1.,  1., -1., -1.,  1., -1., -1.],
        [-1.,  1., -1.,  1., -1., -1., -1.,  1., -1.,  1.]])
adv  tensor([[ 2.9690,  3.8514,  2.7862,  1.6776,  0.2737, -0.9545, -0.2692,  0.2011,
         -0.9648, -0.4062],
        [-4.7761, -3.9718, -3.0966, -2.2433, -1.6667, -2.9145, -2.2496, -1.7989,
         -0.9648, -0.4062],
        [ 1.0315, -0.1271, -1.2333, -0.3615,  0.2347,  1.0260, -0.2897,  0.1816,
          1.0352, -0.4062],
        [-0.9714, -0.1291,  0.7862,  1.6776,  0.2737, -0.9545, -0.2692,  0.2011,
         -0.9648, -0.4062],
        [ 0.9153,  1.7762,  0.6905,  1.5800,  0.1761,  0.9664,  1.6712,  2.1611,
          1.0157,  1.5938]], device='cuda:0')
pred_boxes  tensor([[ 6., 35., 34., 64.],
        [39., 20., 68., 48.],
        [27., 18., 79., 71.],
        [26., 40., 69., 83.],
        [ 0., 31., 28., 60.]])
target_boxes  tensor([[ 6, 40, 33, 67],
        [ 4, 37, 31, 64],
        [51, 29, 78, 56],
        [29, 35, 56, 62],
        [ 6, 42, 33, 69]], dtype=torch.int32)


Test Epoch: 10 [0/982 (0%)]	Reward: -0.3031
action_seq  tensor([[2, 8, 7, 7, 3, 6, 8, 7, 8, 0],
        [8, 0, 4, 8, 7, 7, 7, 7, 4, 0],
        [3, 4, 9, 3, 8, 3, 7, 8, 9, 9],
        [3, 6, 0, 6, 8, 3, 3, 0, 8, 8],
        [1, 3, 2, 2, 8, 9, 4, 4, 0, 0]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1., -1.,  1.,  1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.],
        [ 1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.],
        [ 1.,  1.,  1.,  1., -1.,  1., -1., -1., -1., -1.]])
adv  tensor([[-1.1670, -2.1894, -1.5169, -0.8372, -0.0247, -1.1933, -2.4680, -1.6407,
         -1.0576, -0.5000],
        [-6.9902, -6.0507, -5.4173, -4.7776, -4.0052, -3.1933, -2.4680, -1.6407,
         -1.0576, -0.5000],
        [ 0.7754, -0.2275, -1.5550, -0.8763, -0.0648, -1.2334, -0.4876,  0.3593,
         -1.0576, -0.5000],
        [ 4.5029,  3.5381,  4.2682,  2.9861,  3.8366,  2.7070,  1.4724,  2.3397,
          0.9424, -0.5000],
        [ 2.7930,  1.8106,  0.5036, -0.8177, -2.0247, -1.1933, -2.4680, -1.6407,
         -1.0576, -0.5000]], device='cuda:0')
pred_boxes  tensor([[29.,  0., 71., 43.],
        [35.,  5., 68., 38.],
        [47., 44., 83., 80.],
        [18., 11., 46., 39.],
        [32., 34., 60., 62.]])
target_boxes  tensor([[22, 52, 49, 79],
        [17, 55, 44, 82],
        [32, 31, 59, 58],
        [25, 15, 52, 42],
        [30, 44, 57, 71]], dtype=torch.int32)
action_seq  tensor([[9, 0, 3, 2, 2, 2, 7, 3, 7, 8],
        [3, 8, 4, 1, 6, 3, 4, 9, 4, 8],
        [8, 2, 7, 0, 4, 4, 0, 2, 6, 7],
        [4, 6, 9, 3, 7, 5, 4, 2, 6, 3],
        [2, 3, 5, 8, 6, 8, 0, 9, 8, 8]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1., -1.],
        [ 1., -1.,  1., -1.,  1., -1., -1.,  1., -1., -1.],
        [-1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1., -1.],
        [ 1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.],
        [ 1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.]])
adv  tensor([[ 3.2864e+00,  4.1725e+00,  3.1092e+00,  1.9412e+00,  6.9751e-01,
          1.4946e+00,  2.1404e+00,  7.4223e-01,  1.1596e+00, -3.4375e-01],
        [ 1.4221e+00,  2.6915e-01,  1.1873e+00, -1.8311e-04,  7.5708e-01,
         -4.6637e-01,  1.6093e-01,  7.6176e-01, -8.4039e-01, -3.4375e-01],
        [ 3.2473e+00,  4.1324e+00,  3.0692e+00,  3.9217e+00,  2.6975e+00,
          1.4946e+00,  2.1404e+00,  7.4223e-01,  1.1596e+00, -3.4375e-01],
        [-2.4773e+00, -3.6703e+00, -2.7922e+00, -1.9992e+00, -1.2625e+00,
         -4.8590e-01,  1.4043e-01,  7.4223e-01,  1.1596e+00, -3.4375e-01],
        [ 1.4426e+00,  2.8868e-01, -8.1267e-01, -1.8311e-04,  7.5708e-01,
         -4.6637e-01,  1.6093e-01,  7.6176e-01, -8.4039e-01, -3.4375e-01]],
       device='cuda:0')
pred_boxes  tensor([[23., 30., 51., 60.],
        [34., 18., 63., 46.],
        [21., 25., 49., 53.],
        [26., 48., 54., 77.],
        [ 2.,  0., 44., 43.]])
target_boxes  tensor([[33, 44, 60, 71],
        [17, 27, 44, 54],
        [12, 19, 39, 46],
        [18, 16, 45, 43],
        [ 9, 33, 36, 60]], dtype=torch.int32)
action_seq  tensor([[4, 3, 3, 0, 0, 2, 4, 0, 3, 0],
        [0, 1, 0, 0, 2, 9, 4, 8, 7, 7],
        [2, 6, 2, 1, 3, 9, 1, 4, 3, 9],
        [3, 4, 3, 9, 2, 2, 9, 7, 9, 8],
        [1, 9, 8, 4, 0, 6, 8, 8, 4, 3]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1., -1.,  1.,  1., -1., -1., -1., -1., -1.],
        [ 1.,  1.,  1., -1., -1.,  1., -1., -1.,  1., -1.],
        [ 1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[ 1.8394,  0.7843, -0.5643,  0.0930, -1.5480, -2.6367, -2.0005, -1.4841,
         -0.9942, -0.5938],
        [ 3.6860,  2.6495,  1.3185, -0.0252,  0.3534,  1.3037, -0.0406,  0.4963,
          1.0058, -0.5938],
        [-2.0425, -3.1356, -2.5047, -3.8875, -3.5480, -2.6367, -2.0005, -1.4841,
         -0.9942, -0.5938],
        [-2.0220, -3.1161, -4.5047, -3.8875, -3.5480, -2.6367, -2.0005, -1.4841,
         -0.9942, -0.5938],
        [-4.0024, -5.1161, -4.5047, -3.8875, -3.5480, -2.6367, -2.0005, -1.4841,
         -0.9942, -0.5938]], device='cuda:0')
pred_boxes  tensor([[31., 31., 59., 59.],
        [23.,  3., 51., 31.],
        [24., 49., 52., 77.],
        [37., 48., 65., 77.],
        [22.,  9., 51., 37.]])
target_boxes  tensor([[17, 28, 44, 55],
        [20, 15, 47, 42],
        [ 2, 45, 29, 72],
        [49, 11, 76, 38],
        [55, 36, 82, 63]], dtype=torch.int32)
action_seq  tensor([[6, 9, 2, 1, 6, 1, 7, 3, 7, 3],
        [6, 4, 9, 4, 8, 2, 8, 6, 1, 7],
        [3, 1, 8, 4, 2, 2, 8, 0, 9, 9],
        [4, 5, 3, 4, 5, 8, 0, 4, 4, 1],
        [2, 1, 7, 9, 7, 7, 2, 7, 6, 5]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1.,  1.,  1.,  1., -1., -1., -1., -1., -1.],
        [-1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1.],
        [ 1., -1., -1., -1., -1., -1., -1., -1., -1.,  1.],
        [ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1.,  1.,  1., -1., -1., -1., -1.,  1., -1., -1.]])
adv  tensor([[-1.5969, -0.6970,  0.1486, -0.8282, -1.9419, -3.0978, -2.4346, -1.5754,
         -1.1811, -0.6562],
        [ 3.9793,  4.9349,  3.8166,  4.8974,  3.8413,  2.7440,  3.4658,  2.3650,
          2.7994,  1.3438],
        [-3.5910, -4.7321, -3.9275, -2.9259, -2.0395, -1.1769, -0.4942,  0.3845,
          0.7994,  1.3438],
        [-5.4182, -6.5778, -5.7918, -4.8087, -3.9419, -3.0978, -2.4346, -1.5754,
         -1.1811, -0.6562],
        [-1.6135, -0.7145, -1.8895, -2.8878, -2.0014, -1.1378, -0.4541,  0.4246,
         -1.1811, -0.6562]], device='cuda:0')
pred_boxes  tensor([[41., 30., 70., 58.],
        [19., 13., 53., 47.],
        [34., 28., 62., 56.],
        [28., 19., 56., 47.],
        [29., 36., 71., 79.]])
target_boxes  tensor([[ 6, 38, 33, 65],
        [29, 11, 56, 38],
        [32, 53, 59, 80],
        [10, 43, 37, 70],
        [49, 26, 76, 53]], dtype=torch.int32)
action_seq  tensor([[3, 3, 9, 8, 0, 6, 3, 0, 8, 5],
        [7, 4, 9, 4, 0, 3, 3, 4, 4, 3],
        [8, 6, 0, 8, 9, 8, 0, 5, 9, 7],
        [8, 2, 7, 7, 4, 6, 0, 3, 3, 6],
        [9, 7, 8, 8, 8, 8, 7, 7, 8, 8]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1.,  1., -1., -1., -1., -1.,  1., -1.],
        [-1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [-1., -1.,  1., -1., -1., -1., -1., -1., -1.,  1.],
        [-1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[-0.8559, -1.9065, -1.1676, -0.2324, -1.4664, -0.7551, -0.2262,  0.3403,
          0.8799, -0.5000],
        [-2.7407, -1.7903, -3.0710, -2.1543, -1.3873, -2.6955, -2.1862, -1.6401,
         -1.1201, -0.5000],
        [-2.8550, -1.9045, -1.1667, -2.2520, -1.4850, -0.7746, -0.2457,  0.3198,
          0.8604,  1.5000],
        [-4.6821, -3.7502, -3.0309, -4.1348, -3.3873, -2.6955, -2.1862, -1.6401,
         -1.1201, -0.5000],
        [-6.6421, -5.7307, -5.0309, -4.1348, -3.3873, -2.6955, -2.1862, -1.6401,
         -1.1201, -0.5000]], device='cuda:0')
pred_boxes  tensor([[28., 20., 56., 48.],
        [28., 37., 56., 65.],
        [10., 10., 62., 62.],
        [20., 36., 48., 65.],
        [ 0.,  0., 83., 83.]])
target_boxes  tensor([[56, 12, 83, 39],
        [24,  7, 51, 34],
        [37, 16, 64, 43],
        [42,  6, 69, 33],
        [47, 43, 74, 70]], dtype=torch.int32)
action_seq  tensor([[4, 2, 3, 5, 0, 3, 0, 8, 4, 3],
        [8, 3, 8, 0, 1, 0, 4, 3, 9, 1],
        [2, 3, 8, 5, 1, 7, 2, 8, 5, 8],
        [6, 0, 6, 8, 9, 3, 9, 6, 8, 9],
        [3, 9, 8, 9, 4, 6, 9, 0, 8, 9]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [ 1.,  1., -1., -1., -1., -1.,  1., -1., -1., -1.],
        [-1., -1., -1., -1.,  1.,  1., -1., -1., -1.,  1.],
        [ 1., -1.,  1., -1.,  1., -1., -1., -1.,  1., -1.]])
adv  tensor([[-2.3647e+00, -3.3991e+00, -4.6013e+00, -3.9849e+00, -3.3308e+00,
         -2.6067e+00, -1.9386e+00, -1.4532e+00, -1.0576e+00, -5.0000e-01],
        [-4.3647e+00, -3.3991e+00, -4.6013e+00, -3.9849e+00, -3.3308e+00,
         -2.6067e+00, -1.9386e+00, -1.4532e+00, -1.0576e+00, -5.0000e-01],
        [-4.8190e-01, -1.4967e+00, -2.6804e+00, -2.0445e+00, -1.3708e+00,
         -6.2624e-01,  6.1371e-02, -1.4532e+00, -1.0576e+00, -5.0000e-01],
        [-6.9479e-01,  3.0795e-01,  1.1634e+00,  1.8383e+00,  2.5520e+00,
          1.3142e+00,  1.8005e-03,  5.0671e-01,  9.2285e-01,  1.5000e+00],
        [ 1.3814e+00,  3.8608e-01,  1.2415e+00, -1.0213e-01,  5.9013e-01,
         -6.6628e-01,  2.1332e-02,  5.2722e-01,  9.4238e-01, -5.0000e-01]],
       device='cuda:0')
pred_boxes  tensor([[23., 30., 51., 59.],
        [28.,  9., 57., 37.],
        [31., 12., 65., 47.],
        [ 2., 29., 55., 82.],
        [11., 28., 54., 71.]])
target_boxes  tensor([[10, 46, 37, 73],
        [ 9, 54, 36, 81],
        [ 8, 39, 35, 66],
        [38, 51, 65, 78],
        [40,  8, 67, 35]], dtype=torch.int32)
action_seq  tensor([[3, 8, 0, 9, 7, 0, 6, 0, 8, 1],
        [4, 8, 6, 8, 4, 3, 3, 0, 9, 2],
        [3, 6, 6, 8, 7, 1, 7, 8, 7, 8],
        [3, 9, 3, 9, 3, 6, 2, 7, 7, 3],
        [7, 4, 9, 3, 9, 7, 4, 4, 7, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[ 1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.],
        [ 1., -1., -1., -1., -1.,  1.,  1., -1.,  1., -1.],
        [ 1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.],
        [ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1.]])
adv  tensor([[-1.8479, -3.0346, -2.0227, -1.3492, -2.7517, -2.1798, -1.7283, -1.0513,
         -0.7463, -0.3750],
        [ 1.8425,  0.6930,  1.7410,  2.4535,  3.1096,  3.7411,  2.2317,  0.9291,
          1.2537, -0.3750],
        [-1.8860, -3.0736, -2.0627, -1.3892, -0.7712, -0.1798, -1.7283, -1.0513,
         -0.7463, -0.3750],
        [-3.7883, -4.9945, -4.0032, -3.3492, -2.7517, -2.1798, -1.7283, -1.0513,
         -0.7463, -0.3750],
        [-1.8479, -1.0141, -2.0032, -3.3492, -2.7517, -2.1798, -1.7283, -1.0513,
         -0.7463, -0.3750]], device='cuda:0')
pred_boxes  tensor([[22.,  5., 50., 33.],
        [24., 29., 52., 57.],
        [29.,  0., 83., 53.],
        [51., 54., 79., 83.],
        [45., 44., 73., 72.]])
target_boxes  tensor([[30, 52, 57, 79],
        [33, 50, 60, 77],
        [23, 26, 50, 53],
        [31, 10, 58, 37],
        [ 6, 51, 33, 78]], dtype=torch.int32)
action_seq  tensor([[8, 4, 1, 3, 6, 7, 7, 7, 0, 0],
        [7, 8, 3, 3, 0, 3, 9, 5, 0, 8],
        [1, 2, 1, 6, 6, 2, 8, 8, 2, 3],
        [7, 6, 1, 4, 0, 5, 8, 0, 3, 9],
        [4, 8, 8, 3, 7, 4, 4, 9, 1, 2]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1.],
        [-1., -1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.],
        [ 1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1., -1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.],
        [ 1., -1., -1.,  1.,  1., -1., -1.,  1., -1., -1.]])
adv  tensor([[-3.3888, -2.3817, -3.6368, -2.8205, -2.0605, -3.2806, -2.4615, -1.8235,
         -1.2739, -0.7500],
        [ 2.2039,  3.2687,  4.0907,  2.9646,  1.7628,  0.5807,  1.4389,  2.1169,
          2.7065,  1.2500],
        [-3.3097, -4.3221, -5.5968, -4.8010, -4.0605, -3.2806, -2.4615, -1.8235,
         -1.2739, -0.7500],
        [ 2.2039,  3.2687,  4.0907,  2.9646,  1.7628,  0.5807,  1.4389,  2.1169,
          2.7065,  1.2500],
        [ 0.4354, -0.5389,  0.2460,  1.1004, -0.1201, -1.3206, -0.4811,  0.1765,
         -1.2739, -0.7500]], device='cuda:0')
pred_boxes  tensor([[40., 18., 68., 46.],
        [37., 38., 65., 66.],
        [ 8., 13., 36., 41.],
        [27.,  9., 56., 38.],
        [44., 28., 72., 56.]])
target_boxes  tensor([[14, 44, 41, 71],
        [29, 21, 56, 48],
        [41, 43, 68, 70],
        [40, 22, 67, 49],
        [53, 49, 80, 76]], dtype=torch.int32)
action_seq  tensor([[4, 4, 4, 6, 3, 9, 8, 2, 2, 0],
        [8, 9, 7, 4, 4, 3, 9, 1, 7, 2],
        [6, 4, 9, 7, 6, 6, 8, 6, 7, 6],
        [9, 3, 2, 7, 7, 8, 0, 4, 1, 3],
        [0, 3, 0, 8, 6, 7, 6, 7, 4, 0]], device='cuda:0', dtype=torch.int32)
rewards_all  tensor([[-1., -1., -1.,  1., -1.,  1., -1.,  1., -1., -1.],
        [-1., -1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.],
        [-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],
        [-1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.],
        [ 1.,  1.,  1., -1., -1.,  1., -1.,  1., -1., -1.]])
adv  tensor([[-0.9885, -0.0838,  0.8005,  1.4387,  0.1282,  0.8867, -0.0822,  0.4530,
         -1.0576, -0.5000],
        [ 0.8572,  1.7804,  2.6833,  3.3410,  2.0491,  2.8271,  1.8777,  2.4335,
          0.9424, -0.5000],
        [-4.7151, -3.8475, -5.0227, -4.4422, -3.7927, -3.0733, -2.0627, -1.5470,
         -1.0576, -0.5000],
        [ 4.7400,  5.7033,  4.6237,  3.2815,  4.0090,  4.8076,  3.8777,  2.4335,
          0.9424, -0.5000],
        [ 3.0115,  1.9367,  0.8200, -0.5613,  0.1282,  0.8867, -0.0822,  0.4530,
         -1.0576, -0.5000]], device='cuda:0')
pred_boxes  tensor([[18., 32., 46., 60.],
        [39., 38., 67., 66.],
        [ 0.,  3., 66., 69.],
        [39., 22., 67., 50.],
        [15.,  8., 43., 36.]])
target_boxes  tensor([[ 2, 56, 29, 83],
        [54, 40, 81, 67],
        [32, 17, 59, 44],
        [42, 27, 69, 54],
        [28, 29, 55, 56]], dtype=torch.int32)
Traceback (most recent call last):
  File "baseline-pg.py", line 305, in <module>
    test_loss, test_acc = feed_data(net, agent,  data_loader=test_loader, is_train=False)
  File "baseline-pg.py", line 150, in feed_data
    reward, pred_boxes = actor.takeaction(actions)
  File "/research/cbim/vast/tl601/projects/selfpaced/util/actions_tree_dqn_batch.py", line 86, in takeaction
    elif action == ASPECT_RATIO_DOWN_S:
KeyboardInterrupt
wandb: Waiting for W&B process to finish, PID 54451
wandb: Program failed with code 255.  Press ctrl-c to abort syncing.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.28MB of 0.28MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: wandb/run-20210422_150921-2wli45id/logs/debug.log
wandb: Find internal logs for this run at: wandb/run-20210422_150921-2wli45id/logs/debug-internal.log
wandb: Run summary:
wandb:            Train Pol Loss -25.32846
wandb:             Train Rewards -0.296
wandb:             Train Loc Acc 12.0
wandb:            Train Ent Loss 1106.89746
wandb:             learning rate 0.001
wandb:             Test Pol Loss -60.80528
wandb:              Test Rewards -0.30478
wandb:              Test Loc Acc 11.4053
wandb:             Test Ent Loss 1359.81339
wandb:                     _step 10
wandb:                  _runtime 62
wandb:                _timestamp 1619118623
wandb: Run history:
wandb:   Train Pol Loss ‚ñà‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÑ‚ñÖ
wandb:    Train Rewards ‚ñÜ‚ñÜ‚ñÅ‚ñÜ‚ñá‚ñÇ‚ñÖ‚ñÑ‚ñá‚ñÜ‚ñà
wandb:    Train Loc Acc ‚ñÇ‚ñá‚ñÑ‚ñÖ‚ñÅ‚ñÖ‚ñà‚ñÑ‚ñá‚ñÑ‚ñà
wandb:   Train Ent Loss ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:    learning rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:    Test Pol Loss ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ
wandb:     Test Rewards ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñá‚ñÜ‚ñá‚ñà
wandb:     Test Loc Acc ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñà
wandb:    Test Ent Loss ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb:            _step ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà
wandb:         _runtime ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà
wandb:       _timestamp ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà
wandb: 
wandb: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced ae_iou_pg_ent05_lr1e03_50_aug_2_noR3: https://wandb.ai/amberberli/selfpaced/runs/2wli45id

./main-agent.sh: 153: ./main-agent.sh: --step_ag: not found
